---
title: "Showcase"
format: 
  html:
    toc: true
    toc-depth: 3
callout-appearance: simple
execute: 
  cache: true
  eval: true
  echo: true
  message: false
  warning: false
editor_options: 
  chunk_output_type: console
---

# Preparation
## Load necessary packages
```{r load packages}
library(academictwitteR) # Collecting the data
library(tidyverse) # Preparation of the data
library(quanteda) # Text mining
library(quanteda.textstats) # Text statistics
library(quanteda.textplots) # Visualisation of text data
library(here)
library(sjmisc)
library(lubridate)
library(ggthemes)
```

## Set personal bearer token
```{r set bearer}
personal_bearer_token <- "INSERT BEARER TOKEN HERE"
```


# Mining tweets: hashtag(s)
## Data collection
```{r mine tweets hashtag}
#| eval: false

get_all_tweets(
    query = "#Karneval", 
    start_tweets = "2022-11-11T00:00:00Z",
    end_tweets = "2022-11-13T12:00:00Z",
    file = "karneval",
    data_path = "data/raw_karneval/",
    n = 100000,
    bearer_token = personal_bearer_token
  )
```

### Read data from disc
```{r read tweets hashtag}
tweets_karneval <- bind_tweets(
  data_path = here("content/04-api_access-twitter/data/raw_karneval"),
  # data_path = "data/raw_karneval",
  output_format = "tidy") %>% 
    mutate(
    datetime = ymd_hms(created_at),
    date = date(datetime),
    hour = hour(datetime),
    min  = minute(datetime),
    hms  = hms::as_hms(datetime),
    hm   = hms::parse_hm(hms)
  )
  
```

## Data analysis
### Overview
```{r}
tweets_karneval %>% glimpse
```

### Tweets over time
```{r}
tweets_karneval %>% 
  ggplot(aes(hour)) +
  geom_bar() +
  facet_grid(cols = vars(date)) +
  theme_fivethirtyeight()
```




# Mining tweets: profile(s)
## Data collection
```{r}
#| eval: false

get_all_tweets(
    users = c("elonmusk"),
    start_tweets = "2020-11-11T00:00:00Z",
    end_tweets = "2022-11-13T12:00:00Z",
    file = "elonmusk",
    data_path = here("content/04-api_access-twitter/data/raw_elonmusk/"),
    n = 100000,
    bearer_token = personal_bearer_token
  )
```

### Read data from disc
```{r}
tweets_musk <- bind_tweets(
  data_path = here("content/04-api_access-twitter/data/raw_elonmusk"),
  # data_path = "data/raw_karneval",
  output_format = "tidy") %>% 
    mutate(
    datetime = ymd_hms(created_at),
    date = date(datetime),
    hour = hour(datetime),
    min  = minute(datetime),
    hms  = hms::as_hms(datetime),
    hm   = hms::parse_hm(hms)
  )
```

## Data analysis
### Overview
```{r}
tweets_musk %>% glimpse
```

### Tweets over time
```{r}
tweets_musk %>% 
  ggplot(aes(date)) +
  geom_bar() +
  theme_fivethirtyeight()
```

### Tweets with the most likes
```{r}
tweets_musk %>% 
  filter(is.na(sourcetweet_type)) %>% 
  arrange(-like_count) %>% 
  select(text, created_at, like_count) %>% 
  head(10)
```

### Tweets with the most retweets
```{r}
tweets_musk %>% 
  filter(is.na(sourcetweet_type)) %>% 
  arrange(-retweet_count) %>% 
  select(text, created_at, retweet_count) %>% 
  head(10)
```

### Proportion of tweets
```{r}
tweets_musk %>% 
  frq(sourcetweet_type)

```

### Languate of tweets
```{r}
tweets_musk %>% 
  frq(lang)
```


# Text mining
## Preprocessing
```{r}
remove_html <- "&amp;|&lt;|&gt;"

tweets_en <- tweets_musk %>% 
  filter(lang == "en",
         is.na(sourcetweet_type)) %>% 
  select(tweet_id, text, user_username) %>% 
  mutate(text = str_remove_all(text, remove_html))
```

```{r}
tweets_en_corpus <- corpus(tweets_en,
                           docid_field = "tweet_id",
                           text_field = "text")
```

```{r}
tweets_en_tokens <- 
  tokens(tweets_en_corpus,
         remove_punct = TRUE,
         remove_numbers = TRUE,
         remove_symbols = TRUE,
         remove_url = TRUE) %>% 
  tokens_tolower() %>% 
  tokens_remove(stopwords("english"))
```

```{r}
tweets_en_dfm <- dfm(tweets_en_tokens)
```

## Top Hashtags
```{r}
tag_dfm <- dfm_select(tweets_en_dfm, pattern = "#*")
toptag <- names(topfeatures(tag_dfm, 50))
head(toptag, 10)
```

## Top Mentions
```{r}
user_dfm <- dfm_select(tweets_en_dfm, pattern = "@*")
topuser <- names(topfeatures(user_dfm, 50))
head(topuser, 10)
```

## Exclude Hashtags & Metions
```{r}
tweets_en_clean <- tweets_en_dfm %>% 
  dfm_remove(pattern = "@*") %>% 
  dfm_remove(pattern = "#*")
```

```{r}
term_freq_en <- textstat_frequency(tweets_en_clean)
head(term_freq_en, n = 10)
```

```{r}
textplot_wordcloud(tweets_en_clean, max_words = 50)
```




