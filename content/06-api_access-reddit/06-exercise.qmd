---
title: "Showcase"
subtitle: "Focus on 4CAT"
format: 
  html:
    toc: true
    toc-depth: 4
execute: 
  cache: true
  eval: true
  echo: true
  message: false
  warning: false
highlight-style: atom-one
bibliography: references.bib
csl: ../apa.csl
---

```{r Setup local OSF environment}
#| echo: false
#| eval: false
#| message: false

# Load packages
pacman::p_load(
  pacman,
  here, osfr, fs, 
  tidyverse)

# Get custom functions
source(here("functions/osf_dependencies.R"))

# Get custom paths
dirs <- osf_dependencies("06-api_access-reddit")

# Get data
osf_download(
  dirs$osf_data_path,
  path = here(dirs$local_data_path),
  recurse = TRUE,
  progress = TRUE
)
```

::: callout-tip
Open this showcase in other interactive and executable environments:

[![Binder RStudio](https://raw.githubusercontent.com/chrdrn/digital-behavioral-data/main/img/badge_binder-rstudio.svg)](https://mybinder.org/v2/gh/chrdrn/digital-behavior-data-binder/HEAD?urlpath=rstudio)
[![Binder Jupyter](https://raw.githubusercontent.com/chrdrn/digital-behavioral-data/main/img/badge-binder_jupyter.svg){alt="Binder"}](https://mybinder.org/v2/gh/chrdrn/digital-behavior-data-binder/HEAD)
[![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chrdrn/digital-behavior-data-binder/blob/main/session_06-showcase_reddit.ipynb) 

:::


## Background

Ths showcase has two different goals:

1.  Exemplary presentation of the collection of [<img src="https://raw.githubusercontent.com/FortAwesome/Font-Awesome/6.x/svgs/brands/reddit.svg" width="15" height="15"/>](https://www.reddit.com/) [Reddit](https://www.reddit.com/) data using the [RedditExtractoR](https://github.com/ivan-rivera/RedditExtractor) package
2.  Importing and analyzing the data collected with the 🐈🐈 [**4CAT**](https://github.com/digitalmethodsinitiative/4cat) 🐈🐈 [@peeters2022] tool.

## Data collection with `RedditExtractor`

[Reddit Extractor](https://github.com/ivan-rivera/RedditExtractor) is an R package for extracting data out of [Reddit](https://www.reddit.com/). It allows you to:

-   find subreddits based on a search query
-   find a user and their Reddit history
-   find URLs to threads of interest and retrieve comments out of these threads

::: callout-important
## Disclaimer

Unfortunately, the functions of the `RedditExtractoR` package can **NOT** be executed during the Markdown creation process and must be reproduced "live".

Therefore, there will be no output for the next two paragraphs.
:::

### Example: Find subreddits

Similar to the example from the seminar, the function `find_subreddits` identifies all subreddits that contain the keyword news either in their name or in their attributes.

```{r}
#| eval: false

library(tidyverse)
library(RedditExtractoR)

# Get list of subreddits
news <- find_subreddits("news")

# Quick preview of the dataset
news %>% glimpse()

# Arrange subreddits by subscribers
news %>% 
  arrange(-subscribers) %>% 
  tibble() %>% head()
```

### Example: Find thread URLs

```{r}
#| eval: false

# Get list of top thread urls
news_top_urls <- find_thread_urls(
  subreddit = "news", 
  sort_by = "top", 
  period = "month"
)

# Quick preview of dataset
news_top_urls %>% glimpse()
news_top_urls %>% tibble()
```

## Analysis of collected 🐈🐈 4CAT 🐈🐈 data

A detailed description about the collection of the data (in the form of a concrete application example) can be found in the slides of the associated session.

```{r fix dependencies}
#| echo: false

pacman::p_load(
  here, 
  tidyverse)
```

### Load data into local environment

```{r}
# load packages
library(readr)
library(here)

# get data from github
musk <- read_csv(
    here("content/06-api_access-reddit/data.local/4cat-reddit_news-musk_complete.csv"))

musk_entities <- read_csv(
  here("content/06-api_access-reddit/data.local/4cat-reddit_news-musk-named_entities.csv"))

# quick preview
musk %>% glimpse()
musk_entities %>% glimpse()
```

### Messages including 'musk' over time

::: callout-important
## Tip

The following graphics (and especially their labels) may appear very small. To view the graphics in their original size, right-click on the images and select "Open image/graphic in new tab".
:::

#### Total

```{r}
#| fig-width: 16
#| fig-height: 9

library(lubridate)
library(sjPlot)

# Display 
musk %>% 
  mutate(date  = as.factor(date(timestamp))) %>% 
  plot_frq(
    date,
    title = "Post including 'musk' on Reddit") +
  labs(subtitle = "Subreddits 'news' & 'worldnews' between 14-11 and 26-11-2022")
```

#### By subreddit

```{r}
#| fig-width: 16
#| fig-height: 9

library(magrittr)

musk %>% 
  mutate(
    date  = as.factor(date(timestamp)),
    across(subreddit, as.factor)
    ) %$% 
  plot_grpfrq(
    date,
    subreddit,
    title = "Post including 'musk' on Reddit") +
  labs(subtitle = "Between 14-11 and 26-11-2022")
```
