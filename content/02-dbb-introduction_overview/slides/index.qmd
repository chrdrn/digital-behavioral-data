---
title: "Einführung & Überblick"
title-slide-attributes:
  # data-background-image: ../../background_title-dimmed_red_light.png
  data-background-color: "#04316a"
subtitle: "Digital behavioral data"
author: 
  - name: Christoph Adrian 
    url: https://twitter.com/chrdrn
    affiliation: Lehrstuhl für Kommunikationswissenschaft
    affiliation-url: https://www.kowi.rw.fau.de/person/christoph-adrian/
date: 03 11 2022
date-format: "DD.MM.YYYY"
format:
  revealjs:
    theme: ../../slidetheme.scss
    template-partials:
      - title-slide.html
    slide-number: true
    chalkboard:
      buttons: false
    preview-links: auto
    logo: ../../logo.png
    footer: "[Digital Behavioral Data](https://chrdrn.github.io/digital-behavioral-data/)"
comments:
  hypothesis: 
    theme: clean
execute:
  echo: true
bibliography: references.bib
csl: ../../apa.csl
---

## Seminarplan {.smaller}

| Sitzung             | Datum                        | Thema                                           | Referent\*Innen                                    |
|------------------|------------------|------------------|-------------------|
| ~~1~~               | ~~26.10.2022~~               | ~~Kick-Off Session~~                            | ~~Christoph Adrian~~                               |
| [**2**]{.smallcaps} | [**02.11.2022**]{.smallcaps} | [**DBD: Einführung und Überblick**]{.smallcaps} | [**Christoph Adrian**]{.smallcaps}                 |
| 3                   | 09.11.2022                   | DBD: Datenerhebung                              | Christoph Adrian                                   |
| 4                   | 16.11.2022                   | API-Access (I): *Twitter*                       | Falk                                               |
| 5                   | 23.11.2022                   | API-Access (II): *YouTube*                      | Denisov                                            |
| 6                   | 30.11.2022                   | API-Access (II): *Reddit*                       | Landauer                                           |
| 7                   | 07.12.2022                   | Webscraping: *TikTok*                           | Brand & Kocher                                     |
| 8                   | 14.12.2022                   | ESM: *m-path*                                   | Dörr                                               |
|                     |                              | *WEIHNACHTSPAUSE*                               |                                                    |
| 9                   | 12.01.2023                   | Data Donations                                  |                                                    |
| 10                  | 19.01.2023                   | Mock-Up-Virtual Environments                    |                                                    |
| 11                  | 26.01.2023                   | Open Science                                    |                                                    |
| 12                  | 02.02.2023                   | ***Guest Lecture: Linking DBD & Survey data***  | [Johannes Breuer](https://www.johannesbreuer.com/) |
| 13                  | 09.02.2023                   | Semesterabschluss & Evaluation                  | Christoph Adrian                                   |

# Organisation & Koordination {background-color="#E6002E"}

Fragen, MS Teams & alternativer Seminarplan

## Kursmaterialien etc.

#### Kurze Einführung in Teams

![](images/ms_teams.png){fig-align="center"}

## Vorschlag: Alternativer Seminarplan {.smaller}

| Sitzung             | Datum                        | Thema                                           | Referent\*Innen                                    |
|------------------|------------------|------------------|-------------------|
| ~~1~~               | ~~26.10.2022~~               | ~~Kick-Off Session~~                            | ~~Christoph Adrian~~                               |
| [**2**]{.smallcaps} | [**02.11.2022**]{.smallcaps} | [**DBD: Einführung und Überblick**]{.smallcaps} | [**Christoph Adrian**]{.smallcaps}                 |
| 3                   | 09.11.2022                   | DBD: Datenerhebung                              | Christoph Adrian                                   |
| 4                   | 16.11.2022                   | API-Access (I): *Twitter*                       | Falk                                               |
| 5                   | 23.11.2022                   | API-Access (II): *YouTube*                      | Denisov                                            |
| 6                   | 30.11.2022                   | API-Access (II): *Reddit*                       | Landauer                                           |
| 7                   | 07.12.2022                   | Webscraping: *TikTok*                           | Brand & Kocher                                     |
| ***8***             | ***14.12.2022***             | ***Exkurs: DBD Analyse mit R***                 | ***Christoph Adrian***                             |
|                     |                              | *WEIHNACHTSPAUSE*                               |                                                    |
| ***9***             | ***12.01.2023***             | ***ESM: m-path***                               | ***Dörr***                                         |
| ***10***            | ***19.01.2023***             | ***TBD***                                       | ***Hofmann & Wierzbicki***                         |
| 11                  | 26.01.2023                   | Puffer                                          |                                                    |
| 12                  | 02.02.2023                   | ***Guest Lecture: Linking DBD & Survey data***  | [Johannes Breuer](https://www.johannesbreuer.com/) |
| 13                  | 09.02.2023                   | Semesterabschluss & Evaluation                  | Christoph Adrian                                   |

# Was kann mit DBD untersucht werden? {background-color="#E6002E"}

Meinungen, Verhalten und Nutzung digitaler Technologien

## DBD - Was ist das eigentlich?

#### Rückblick auf Definition nach @weller2021

-   ... fasst eine **Vielzahl von möglichen Datenquellen** zusammen, die verschiedene Arten von **Aktivitäten aufzeichnen**

-   ... können dabei helfen, **Meinungen, Verhalten und Merkmale der menschlichen Nutzung digitaler Technologien** zu erkennen

<br>

::: fragment
#### **Im Kontext dieses Seminars:**

-   Schwerpunkt **Soziale Medien** und **Mediennutzung**
-   **Computational Social Science** \[CSS\] zur Erhebung (& Auswertung)
:::

## Kein DBD ohne CSS {.smaller}

#### Exkurs: Computational Social Science

::: {.callout-tip appearance="minimal"}
## Definition von CSS

We define CSS as the development and application of computational methods to complex, typically large-scale, human (sometimes simulated) behavioral data." @lazer2020
:::

**ist ein Forschungsfeld, das**

-   rechnergestützte Methoden einsetzt

-   um Daten zu sammeln und zu analysieren, insbesondere große und digitale Verhaltensdaten,

-   um gesellschaftlich relevante Phänomene zu untersuchen.

**hilft dabei ...**

-   echte digitale Phänomene zu untersuchen

-   digitale Verhaltensdaten zu sammeln und vorzuverarbeiten

-   neue Methoden zur Analyse von großen Datensätzen

::: notes
CSS = neues Teilgebiet der Sozialwissenschaften oder neuer "Werkzeugkasten" zur Ergänzung der traditionellen sozialwissenschaftlichen Ansätze
:::

## Untersuchung von Verhaltensweisen

#### Kategorisierung verschiedener Verhaltensweisen

::: columns
::: {.column width="65%"}
![](images/dbd_matrix.png){fig-align="center"}
:::

::: {.column width="35%"}
<br>

**Einschränkungen**

-   Kategorisierung ist **Momentaufnahme** und erlaubt Überschneidungen der Kategorien

-   **Selektive Nutzung** von bestimmten digitalen Geräten
:::
:::

::: notes
-   Kategorien: Digital/Analog individual/social behavior

-   Einige inhärent digitale Verhalten (z.B. Web Searches) bei zunehmender Digitalisierung von analogen Verhalten (z.B. Collaborative Work)

-   Fehlen digitaler Spurendaten in all diesen Quadranten für bestimmte Personen und bestimmte Verhaltensweisen durch selektive Nutzung digitaler Geräte.
:::

## Untersuchung von Meinungen

Beispiel: Twitter Screenshots/Mining

-   Die Auswertung von Meinungen aus bestehenden digitalen Kommunikationsströmen kann zeitnaher sein als die Erstellung einer Umfrage. Sie sind eine wertvolle Quelle, insbesondere bei unvorhersehbaren Ereignissen. (z.B. Maßnahmen zu COVID-19)

TODO: Beispiel hier

## Verfügbarkeit durch Fortschritt

#### Am Beispiel der wachsenden Anzahl eingebauter Smartphone-Sensoren

![Graphik aus @struminskaya2020](images/dbd_smartphone_development.jpeg){alt="Aus @struminskaya2020" fig-align="center"}

## Warum Digital behavioral data?

-   Digitale Geräte oder Sensoren können sich besser an bestimmte Fakten besser erinnern als das menschliche Gedächtnis. (Beispiel: SocioPatterns.org)

-   Und oft sind Sensoren bereits in alltägliche Technik eingebaut Technologie eingebaut und produzieren digitale Verhaltensdaten als ein "Nebenprodukt". (Beispiel: Mobility Monitor)

-   Manchmal können digitale Verhaltensdaten die Untersuchung von Themen ermöglichen, für die es schwierig wäre, Studienteilnehmer zu rekrutieren sonst nicht möglich wäre. Sie werden oft ohne Anregung eines Forschers eines Forschers. (z.B. Messung des subjektiven Wohlbefindens)

-   Digitale Verhaltensdaten können auch mit Umfragedaten kombiniert werden. (BeispieL Breuer)

# DBD Rahmenbedingungen

Biases, methodologische Tücken und ethische Grenzen

## Choose your bias

#### DBD-Kernbereiche in Anlehnung an Aufteilung der [GESIS](https://www.gesis.org/institut/digitale-verhaltensdaten)

::: columns
::: {.column width="50%"}
![](/content/01-kick-off/slides/images/dbd_graph/dbd_pillars_3.png){fig-align="center"}
:::

::: {.column width="50%"}
Heute Schwerpunkt:

-   Konzeptuelle Herangehensweise

-   Bias
:::
:::

## Ambivalenz der Unaufdringlichkeit

#### basierend auf @keusch2021

-   Unterscheidung zwischen aufdringlichen (z.B. spezielle Research-App & Befragungen) & unaufdringlichen (z.B. Cookie & APIs) erhobenen Daten

-   Bewertung und Erwartung an Datensammlung ist abhängig vom Kontext (Amazon vs. Researchgate)

-   Dilema: Einerseits bereitwillige (oft unwissende) Abgabe der Daten an Konzerne, andererseits häufig Bedenken bezüglich Datenschutz & Privatsphäre bei wissenschaftlichen Studien

::: notes
Q: Gründe für Ablehnung: Nutzenorientierung?
:::

## The End of Theory?

#### Zur Wichtigkeit von konzipierte Messungen & Designs

> "Who knows why people do what they do? The point is they do it, and we can track and measure it with unprecedented fidelity. With enough data, the numbers speak for themselves."
>
> [@anderson2008]

Aber:

-   "Size alone does not necessarily make the data better" [@boyd2007]

-   "there are a lot of small data problems that occur in big data \[which\] don't disappear because you've got lots of the stuff. They get worse" [@harford2014]

Problem:

-   (Big) Data zunehmend Grundlage für politische Maßnahmen, die Gestaltung von Produkten und Dienstleistungen und für die automatisierte Entscheidungsfindung

## Let's talk about bias

Problem:

-   there is not enough agreement on a vocabulary or taxonomy of biases, methodological issues, and pitfalls of this type of research.

<!-- -->

-   the evidence of bias and of broader implications about potential threats to the validity of social data research is often implicit in the findings of prior work, rather than a primary focus of it.

-   Oftentimes, however, it is difficult to draw clear boundaries between the more normative connotations and the statistical sense of the term ---see Campolo et al. (2017) for a discussion on some of the competing meanings of the term "bias."

::: notes
term "bias" is used in its more statistical sense to refer to biases in social data and social data analyses
:::

## Ein Framework zur Minimierung von Bias

#### @olteanu2019

![](images/bias_framework_without_legend.png){fig-align="center"}

::: notes
Description:

-   Social data analysis starts with certain goals (section 2.1), such as understanding or influencing phenomena specific to social platforms (Type I) and/or phenomena beyond social platforms (Type II).

-   These goals require that research satisfies certain validity criteria, described earlier (section 2.2).

-   These criteria, in turn, can be compromised by a series of general biases and issues (section 3).

-   These challenges may depend on the characteristics of each data platform (section 4)---which are often not under the control of the researcher---and on the research designs choices made along a data processing pipeline (from sections 5 to 8)--which are often under the researcher control.

Pfeile zeigen an, wie sich Komponenten in unserem Rahmenwerk direkt auf andere auswirken

-   Erreichen bestimmter Ziele (Type I & II) bei der Analyse von Sozialdaten (Abschnitt 2.1) voraussetzt, dass die Forschung bestimmte Validitätskriterien erfüllt (Abschnitt 2.2),

-   die durch Verzerrungen und andere Probleme mit Sozialdaten beeinträchtigt werden können (Abschnitt 3)

-   Diese Verzerrungen und Probleme können an der Quelle der Daten auftreten (Abschnitt 4), oder sie können im Verlauf der Datenanalyse eingeführt werden (Abschnitte 5-8).
:::

## Worauf wirkt die Verzerrung? {.smaller}

#### Beispiele für Forschung von Typ I & II [@olteanu2019]

![](images/bias_framework_upper_box.png){fig-align="center" width="923"}

<br>

::: columns
::: {.column width="50%"}
##### Typ I:

-   Dynamik der Verbreitung von "Memes"
-   Steigerung der Attraktivität bzw. besonders Features
-   Verbesserung der Suchfunktion oder des Empfehlungssystems
:::

::: {.column width="50%"}
##### Typ II

-   Beschreibung des Einflusses sozialer Medien auf eine politische Wahl.

-   Nutzung sozialer Daten zur Verfolgung der Entwicklung ansteckender Krankheiten durch Analyse der von Social-Media-Nutzern online gemeldeten Symptomen
:::
:::

## Validität als Grundlage für "Aussagekraft" {.smaller}

#### Die verschiedenen Formen von Validität

**Interne Validität**

-   Does our analysis correctly lead from the measurements to the conclusions of the study?

**Externe Validität**

-   To what extent can research findings be generalized to other situations?

**Konstruktvaldität**

-   Do our measurements over our data measure what we think they measure?

::: notes
-   Type II: Nutzung sozialer Daten zur Beantwortung von Fragen und zur Ermittlung von Maßnahmen, die für Medien, Regierungen, Nichtregierungsorganisationen und Unternehmen relevant sind, oder zur Bearbeitung von Problemen aus Bereichen wie Gesundheit, Wirtschaft und Bildung..

-   Construct validity:

    -   Beispiel: If a hypothesis states that "self-esteem" increases with age, research tracking self-esteem over time from social media postings must ask whether its assessment of selfesteem from the postings actually measures self-esteem, or if instead it measures some other related or unrelated construct. In other words, we need to know whether the observed behaviors (such as words or phrases used in postings) are driven primarily by users' self-esteem vs. by community norms (section 4.2), system functionalities (section 4.1), or other reasons (section 3.3). Construct validity is specially important when the construct (self-esteem) is unobservable/latent and has to be operationalized via some observed attributes (words or phrases used)

-   Internal validity

    -   Does our analysis correctly lead from the measurements to the conclusions of the study?

    -   This survey covers subtle errors of this kind, such as biases that can be introduced through data cleaning procedures (section 6), the use of machine learned classifiers, mistaken assumptions about data distributions, and other inadvertent biases introduced through common analyses of social media (section 7).

    -   Example: An analysis of whether "self-esteem" increases with age may not be internally valid if text filtering operations accidentally remove terms expressing confidence (section 5.3); or if machine learned classifiers were inadvertently trained to recognize self-esteem only in younger people (section 7). Of course, while we do not dwell on them, researchers should also be aware of more blatant logical errors---e.g., comparing the self-esteem of today's younger population to the self-esteem of today's older population would not actually prove that selfesteem increases with age (section 3.6).

-   External validity:

    -   To what extent can research findings be generalized to other situations?

    -   For example, effects observed on a social platform may manifest differently on other platforms due to different functionalities, communities, or cultural norms (Wijnhoven and Bloemen, 2014; Malik and Pfeffer, 2016). The concept of external validity includes what is sometimes called ecological validity, which captures to what extent an artificial situation (constrained social media platform) properly reflects a broader real-world phenomenon (Ruths and Pfeffer, 2014). It also includes temporal validity, which captures to what extent constructs change over time (Howison et al., 2011) and may invalidate previous conclusions about societal and/or platform phenomena; e.g., see the case of Google Flu Trends (Lazer et al., 2014).

    -   Example: Even after we conclude a successful study of "selfesteem" in a longitudinal social media dataset collected from a given social media platform (section 4), its findings may not generalize to a broader setting as people who chose that particular platform may not be representative of the broader population (section 3.2); or perhaps their behaviors online are not representative of their behaviors in other settings (section 3.3).
:::

## Eine Frage der Datenqualität

Verschiedene Kriterien

## Im Fokus: Population bias {.smaller}

#### Wie wirken verschiedene Verzerrungen? {.smaller}

::: {.callout-important appearance="minimal"}
Systematic distortions in demographics or other user characteristics between a population of users represented in a dataset or on a platform and some target population.
:::

##### Auswirkungen:

-   kann die (Stichproben)-Repräsentativität beeinträchtigen\
    ➥ ⚠️externe Validität
-   besonders problematisch für Forschungsarbeiten des Typs II
-   kann sich auch auf die Leistung von Algorithmen auswirken, die Rückschlüsse auf die Nutzer ziehen\
    ➥ ⚠️interne Validität (Typ-I & Typ II)

##### Allgemeine Probleme:

-   Unterschiedliche Demographien (z.B. Geschlechts-, Alters- & Bildungsgruppen) neigen zu unterschiedlichen sozialen Plattformen und nutzen deren Mechanismen unterschiedlich

-   Proxies für Eigenschaften oder demografische Kriterien der Nutzenden sind unterschiedlich verlässlich

::: notes
Häufig ist der Zusammenhang von Untersuchungspopulation (z.B. in Deutschland lebende Erwachsene) zu Zielpopulation (Erwachsene auf Twitter, die angeben, in DE zu leben) unbekannt.

Beispiel "Auswirkungen"

-   Algorithmen: Schätzung der Geo-Location im Stadt-Land-Spektrum (z.B Johnson et al., 2017)

Beispiele "Probleme":

-   Signifikant mehr Twitter Nutzer (Mislove et al. ,2011), bei Pinterest tendenziell Frauen überrepräsentiert (Ottoni et al., 2013)

-   Unterschiedliche Twitter-Nutzung in DE (Fokus auf Hashtags) und KOR (Fokus auf Konversationen) (Hong et al., 2011).

-   Angabe von Geo-Location oder Profilinformationen in sozialen Netzwerken
:::

## Im Fokus: Behavioral bias {.smaller}

#### Wie wirken verschiedene Verzerrungen?

::: {.callout-important appearance="minimal"}
Systematic distortions in user behavior across platforms or contexts, or across users represented in different datasets.
:::

##### Auswirkungen:

-   Ergebnisse einer Studie von der gewählten Plattform oder dem Kontext abhängig\
    ➤ ⚠️externe Validität

-   nur Teilweise von population bias abhängig

-   bei (expliziten oder impliziten) Annahmen über die Verhaltensmuster der Nutzenden\
    ➤ ⚠️potentielle Effekte auf Untersuchung von Typ-I & Typ II

##### Allgemeine Probleme:

-   beeinflussen die Art und Weise, wie Nutzer miteinander interagieren

-   Auftreten von Selbstselektion und Reaktionsverzerrungen

-   Verzerrungen beim Konsumieren von Inhalten beeinflussen die Art und Weise, wie Nutzer Inhalte finden und mit ihnen interagieren, aufgrund von Unterschieden in ihren Interessen, ihrem Fachwissen und ihrem Informationsbedarfes

::: notes
Unterschiede in Bezug auf Nutzerpersönlichkeiten (Hughes et al., 2012), die Verbreitung von Nachrichten (Lerman und Ghosh, 2010) oder den Austausch von Inhalten (Ottoni et al., 2014)

Beispiel "Auswirkungen":

-   B. die Untersuchung der Bedürfnisse oder Interessen der Nutzenden

Beispiel "Probleme":

-   Gesonderte Diskussion von Verhalten, die sich auf die Erstellung von Inhalten durch die Nutzer auswirken ("content production bias") und solche, die sich auf die Verknüpfungsmuster zwischen Nutzern auswirken ("linking bias").

-   Drei weitere häufige Klassen von Verhaltensverzerrungen betreffen die Interaktionen zwischen Nutzern, die Interaktionen zwischen Nutzern und Inhalten und die Verzerrungen, die dazu führen, dass Nutzer in eine Studienpopulation aufgenommen oder von ihr ausgeschlossen werden.
:::

# Group Activity

Gruppendiskussion

## Verfügbarkeit vor Interesse

#### Zur Wichtigkeit von konzipierte Messungen & Designs

-   DBB sind häufig organische Daten, die zufällig gesammelt und dann von der Wissenschaft "recycelt" werden

    -   Zentrale Frage: Ist das ein Problem? Wenn ja, warum?

-   Repräsentativität vs. Stichprobenziehung

-   Kausalität vs. Korrelation

# Bis zur nächsten Sitzung! {background-color="#04316a"}

## Literatur

::: {#refs}
:::
