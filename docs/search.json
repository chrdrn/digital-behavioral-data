[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Digital Behavioral Data",
    "section": "",
    "text": "In this seminar, students will be introduced to working with digital behavioral data (DBD). DBD refers to digital traces of human behavior that are knowingly or unknowingly left in online environments (e.g., social media, messengers, entertainment media, or digital collaboration tools). These rich data are increasingly available to social scientific research in the public interest but can also be used to derive strategic insights for business decisions. Students will learn how to work with DBD alongside the entire research process, from data collection, preprocessing and analysis, to reporting and provision (e.g., via open science tools). Students will first get a comprehensive overview of the ways in which DBD can be collected (e.g., API scraping, usage logging, mock-up virtual environments, or data donations), as well as the requirements for data protection, research ethics, and data quality. Afterwards, students will practice and apply their newly gained knowledge in small projects on use cases from media and communication research. In doing so, they learn about key computational methods via which large digital behavioral datasets (e.g., texts, images, usage behavior logs) can be processed and analyzed. By completing this module, participants will get an up-to-date overview and practical insights into how to harness the potential of observational data traces to better understand media users’ behavior in digital environments."
  },
  {
    "objectID": "content/01-kick-off/01-slides.html",
    "href": "content/01-kick-off/01-slides.html",
    "title": "Slides",
    "section": "",
    "text": "If you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‘e’ button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "content/01-kick-off/slides/index.html",
    "href": "content/01-kick-off/slides/index.html",
    "title": "Kick-Off",
    "section": "",
    "text": "Christoph Adrian\n\nseit 2016: Research Assistant / PhD Candidate FAU\nM. Sc. Sozialökonomik (FAU)\nB.A. Sozialökonomik (FAU)\n\nForschungs- und Lehrschwerpunkte\n\nComputer-assisted and automated (corpus-based) content analysis (with R)\nSocial media research (Twitter)\nPotential influence of media use on attitude changes"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#und-nun-zu-ihnen",
    "href": "content/01-kick-off/slides/index.html#und-nun-zu-ihnen",
    "title": "Kick-Off",
    "section": "Und nun zu Ihnen!",
    "text": "Und nun zu Ihnen!\nVorstellungsrunde\n\nWie heißen Sie?\nWas und wo haben Sie im Bachelor studiert?\nWas studieren Sie aktuell?\nWelches soziale Netzwerk/Medium nutzen Sie aktuell am häufigsten?\nWelche Erwartungen haben Sie an das Seminar?"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#covid-19-lässt-grüßen",
    "href": "content/01-kick-off/slides/index.html#covid-19-lässt-grüßen",
    "title": "Kick-Off",
    "section": "COVID-19 lässt grüßen",
    "text": "COVID-19 lässt grüßen\nCorona-Regeln im Wintersemester\n\n\n\nUm sich und andere zu schützen bitte wir Sie herzlich:\nTragen Sie weiterhin eine FFP2- oder OP-Maske!\n\nCOVID-o-mat"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#was-verstehen-sie-unter-digital-behavioral-data",
    "href": "content/01-kick-off/slides/index.html#was-verstehen-sie-unter-digital-behavioral-data",
    "title": "Kick-Off",
    "section": "Was verstehen Sie unter Digital Behavioral Data?",
    "text": "Was verstehen Sie unter Digital Behavioral Data?\nInteraktive Session\n\n\nBitte scannen Sie den QR-Code oder nutzen Sie folgenden Link für die Teilnahme an einer kurzen Umfrage:\n\nhttps://www.menti.com/alxiy2f2n6oj\nTemporary Voting Code: 49 29 72 5"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#ergebnis",
    "href": "content/01-kick-off/slides/index.html#ergebnis",
    "title": "Kick-Off",
    "section": "Ergebnis",
    "text": "Ergebnis"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#ein-definitionsversuch-von-dbd",
    "href": "content/01-kick-off/slides/index.html#ein-definitionsversuch-von-dbd",
    "title": "Kick-Off",
    "section": "Ein Definitionsversuch von DBD",
    "text": "Ein Definitionsversuch von DBD\nnach Weller (2021)\n\n\n… fasst eine Vielzahl von möglichen Datenquellen zusammen, die verschiedene Arten von Aktivitäten aufzeichnen\n… können dabei helfen, Meinungen, Verhalten und Merkmale der menschlichen Nutzung digitaler Technologien zu erkennen"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#beispiel-covid-19-mobility-monitor",
    "href": "content/01-kick-off/slides/index.html#beispiel-covid-19-mobility-monitor",
    "title": "Kick-Off",
    "section": "Beispiel: COVID-19 Mobility Monitor",
    "text": "Beispiel: COVID-19 Mobility Monitor"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#beispiel-datenvolumen-einer-internet-minute",
    "href": "content/01-kick-off/slides/index.html#beispiel-datenvolumen-einer-internet-minute",
    "title": "Kick-Off",
    "section": "Beispiel: Datenvolumen einer Internet-Minute",
    "text": "Beispiel: Datenvolumen einer Internet-Minute"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#kernbereiche-von-dbd",
    "href": "content/01-kick-off/slides/index.html#kernbereiche-von-dbd",
    "title": "Kick-Off",
    "section": "Kernbereiche von DBD",
    "text": "Kernbereiche von DBD\nin Anlehnung an Aufteilung der GESIS\n\n\n\n\n\n\n\n\n\n\nUnterschiedliche Heraus- bzw. Anforderungen (je nach Bereich)\nSeminar legt Schwerpunkt auf Datenerhebung, mit kurzen Ausblick auf die anderen Bereiche"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#seminarplan",
    "href": "content/01-kick-off/slides/index.html#seminarplan",
    "title": "Kick-Off",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einführung und Überblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\n\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\n\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\n\n\n\n7\n07.12.2022\nWebscraping: TikTok\n\n\n\n8\n14.12.2022\nESM: m-path\n\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nData Donations\n\n\n\n10\n19.01.2023\nMock-Up-Virtual Environments\n\n\n\n11\n26.01.2023\nOpen Science\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#typische-session",
    "href": "content/01-kick-off/slides/index.html#typische-session",
    "title": "Kick-Off",
    "section": "Typische Session",
    "text": "Typische Session\nErst Präsentation, dann Vertiefung\n\n\nPräsentation (ca. 35-45 Min)\n\nUmfasst Ihre Präsentation (inkl. Zeit für Fragen und Diskussionen)\nOption auf weitere, offenere Diskussion im Plenum\n\n\nGroup Activity (ca. 45 - 55 Min)\n\nkleine Gruppenarbeiten zur Vertiefung\nvariiert abhängig vom Thema der jeweiligen Sitzung\nBeispiele:\n\nAnwendung von Tool/Methode mit anschließender kritschen Diskussion\nErstellung eines einfachen Forschungs- oder Analysedesign"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#different-tools-for-different-tasks",
    "href": "content/01-kick-off/slides/index.html#different-tools-for-different-tasks",
    "title": "Kick-Off",
    "section": "Different tools for different tasks",
    "text": "Different tools for different tasks\nOrganisation der Lehre auf einen Blick\n\nMS Teams: wichtige Ankündigungen, asynchrone Unterhaltungen & Fragen zum Kurs\nStudOn: Kursmaterialien, ggf. Beispieldatensätze und Präsentationsaufnahmen\nEmail: persönliche Fragen an Dozent\nZoom: ggf. für Sitzung & Sprechstunde"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#what-is-expected",
    "href": "content/01-kick-off/slides/index.html#what-is-expected",
    "title": "Kick-Off",
    "section": "What is expected",
    "text": "What is expected\nLeistungsanforderungen & Prüfungsleistungen\n\nRegelmäßige Teilnahme an den Sitzungen (max. 2 unentschuldigtes Fehlen)\nEigenständige Auf- und Vorbereitung von Pflichtlektüre (“bestehen”)\nPräsentation (50%)\nSeminarbericht (50%)"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#präsentation",
    "href": "content/01-kick-off/slides/index.html#präsentation",
    "title": "Kick-Off",
    "section": "Präsentation",
    "text": "Präsentation\nUmfang & Inhalt: max. 30 Min.\n\n~ 25 Min.: Zentrale Begriffe, Definitionen und Merkmale der jeweiligen Plattform, Methode und/oder des Tools inklusive kurzem Überblick über Forschung(-sfeld)\n~ 5 Min: Fragen & Diskussion\nZiel: Vorstellung Tool & Beispiel für Forschung(-sdesign)\n\nSprechstunde:\n\nEinreichung vollständiger Präsentationsentwurf mindestens eine Woche + 24 Stunden vor Ihrer Präsentation per E-Mail an christoph.adrian@fau.de\nAusführliches Feedback und Tipps zur Überarbeitung\n\nLiteratur:\n\nSiehe Syllabus & Teams/StudOn (PDFs werden bereitgestellt)"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#ein-kurzer-appell",
    "href": "content/01-kick-off/slides/index.html#ein-kurzer-appell",
    "title": "Kick-Off",
    "section": "Ein kurzer Appell",
    "text": "Ein kurzer Appell\nHinweis zu “Abbruch” bzw. Nicht-Erscheinen\n\nIhre Anmeldung bedeutet üblicherweise eine sehr intensive, aufwändige Betreuung für uns Lehrende\nÄrgerlicherweise gibt es Studierende, die sich anmelden und betreuen lassen, aber dann einfach irgendwann (teilweise sehr kurzfristig) “verschwinden”.\n\n⚠️ Bitte seien Sie sich folgender Dinge bewusst:\n\nDie „Prüfung” bzw. die „Prüfungszeit” bei einem Seminar beginnt mit der Bearbeitungszeit und damit mit der Ausgabe des Themas an die Kandidaten.\n24h Bedenkzeit / Rücktrittsrecht"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#lets-spin-the-wheel",
    "href": "content/01-kick-off/slides/index.html#lets-spin-the-wheel",
    "title": "Kick-Off",
    "section": "Let’s spin the wheel",
    "text": "Let’s spin the wheel\n\n\n\nSession\nDatum\nThema\n\n\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\n\n\n7\n07.12.2022\nWebscraping: TikTok\n\n\n8\n14.12.2022\nESM: m-path\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n9\n12.01.2023\nData Donations\n\n\n10\n19.01.2023\nMock-Up-Virtual Environments\n\n\n11\n26.01.2023\nOpen Science\n\n\n\n\nIn case of emergency: Wheel of Names"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#lets-spin-the-wheel-1",
    "href": "content/01-kick-off/slides/index.html#lets-spin-the-wheel-1",
    "title": "Kick-Off",
    "section": "Let’s spin the wheel",
    "text": "Let’s spin the wheel\n\n\n\nSession\nDatum\nThema\n\n\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\n\n\n7\n07.12.2022\nWebscraping: TikTok\n\n\n8\n14.12.2022\nESM: m-path\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n9\n12.01.2023\nData Donations\n\n\n10\n19.01.2023\nMock-Up-Virtual Environments\n\n\n11\n26.01.2023\nOpen Science\n\n\n\n\nIn case of emergency: Wheel of Names"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#lektüre-zwischen-den-sitzungen",
    "href": "content/01-kick-off/slides/index.html#lektüre-zwischen-den-sitzungen",
    "title": "Kick-Off",
    "section": "Lektüre zwischen den Sitzungen",
    "text": "Lektüre zwischen den Sitzungen\nPflichtlektüre\n\npro Woche ein wissenschaftlicher Text als Grundlage für das Thema (Sitzungen 4 - 11)\n\nEinreichung von Fragen zum Text in Teams (spätestens Dienstag Abend)\n\ngilt für alle Kursteilnehmer*Innen\nmind. 1 Verständnisfrage zum Text\nmind. 1 Diskussionsfrage zum Text bzw. Thema insgesamt\nWo? -> in wöchentlicher Teams-Unterhaltung zur jeweligen Sitzung\nWhy? -> wird in der Sitzung genutzt; bereiten Sie Ihre Frage so vor, dass Sie sie in der Sitzung stellen & erklären können\n\nLiteratur:\n\nSiehe Syllabus & Teams/StudOn (PDFs werden bereitgestellt)"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#seminararbeit",
    "href": "content/01-kick-off/slides/index.html#seminararbeit",
    "title": "Kick-Off",
    "section": "Seminararbeit",
    "text": "Seminararbeit\nUmfang & Inhalt (ausführliche Infos im Syllabus)\n\n3500 - 4000 Wörter\nAnfertigung einer Projektskizze für eine wissenschaftliche Arbeit\nVerwendung von mindestens eine der vorgestellten Methoden/Tools\nSozialwissenschaftlicher Fokus\n\n(vorläufige) Deadline: 03.03.2023; 23:59"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#before-we-meet-again",
    "href": "content/01-kick-off/slides/index.html#before-we-meet-again",
    "title": "Kick-Off",
    "section": "Before we meet again",
    "text": "Before we meet again\nHinweise und offene Fragen\n\nGenerell: ausführliche Informationen im Syllabus!\nKursmaterialien: MS Teams vs. StudOn?\nWhy no English?\nIhre Fragen?"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html",
    "href": "content/02-dbb-introduction_overview/index.html",
    "title": "Einführung und Überblick",
    "section": "",
    "text": "seit 2016: Research Assistant / PhD Candidate FAU\nM. Sc. Sozialökonomik (FAU)\nB.A. Sozialökonomik (FAU)\n\n\n\n\n\nComputer-assisted and automated (corpus-based) content analysis (with R)\nSocial media research (Twitter)\nPotential influence of media use on attitude changes"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#und-nun-zu-ihnen",
    "href": "content/02-dbb-introduction_overview/index.html#und-nun-zu-ihnen",
    "title": "Einführung und Überblick",
    "section": "Und nun zu Ihnen!",
    "text": "Und nun zu Ihnen!\n\nVorstellungsrunde\n\nWie heißen Sie?\nWas und wo haben Sie im Bachelor studiert?\nWelches soziale Netzwerk/Medium nutzen Sie aktuell am häufigsten?\nWelche Erwartungen haben Sie an das Seminar?"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#computation-social-science",
    "href": "content/02-dbb-introduction_overview/index.html#computation-social-science",
    "title": "Einführung und Überblick",
    "section": "Computation Social Science",
    "text": "Computation Social Science\n\n\n\nSie sind gefragt!\nWas verstehen Sie unter Computation Social Science?\nScannen Sie bitten den QR-Code oder besuchen Sie den Link\n\n\n\nLink: https://www.menti.com/alv6himtf4x7"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#alles-beginnt-mit-css",
    "href": "content/02-dbb-introduction_overview/index.html#alles-beginnt-mit-css",
    "title": "Einführung und Überblick",
    "section": "Alles beginnt mit CSS",
    "text": "Alles beginnt mit CSS"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#inwiefern-hilft-uns-css",
    "href": "content/02-dbb-introduction_overview/index.html#inwiefern-hilft-uns-css",
    "title": "Einführung und Überblick",
    "section": "Inwiefern hilft uns CSS?",
    "text": "Inwiefern hilft uns CSS?\nBeispiel: Typische Fragebogenitems in Surveys\n\nWie häufig sprechen Sie mit Ihren Freund*Innen am Smartphone?\nWie viele Stunden verbringen Sie außerhalb Ihrer Wohnung?\nWie häufig haben Sie sich in den letzten 14 Tage mit Freund*Innen getroffen\n\n\nProblem:\n\n🍀 Bestenfalls gute Schätzung\n💩Schlechtestenfalls falsche Erinnerung"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#digital-behavioral-data-als-teil-der-antwort",
    "href": "content/02-dbb-introduction_overview/index.html#digital-behavioral-data-als-teil-der-antwort",
    "title": "Einführung und Überblick",
    "section": "Digital Behavioral Data als (Teil) der Antwort",
    "text": "Digital Behavioral Data als (Teil) der Antwort\nDigitale (smarte) Geräte und Sensoren können sich besser an bestimmte Fakten “erinnern” als das menschliche Gedächnis\nBeispiel: Socio Patterns - RFID Sensoren zu Messung von Face-to-Face Interaktionen"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#digital-behavioral-data-als-teil-der-antwort-1",
    "href": "content/02-dbb-introduction_overview/index.html#digital-behavioral-data-als-teil-der-antwort-1",
    "title": "Einführung und Überblick",
    "section": "Digital Behavioral Data als (Teil) der Antwort",
    "text": "Digital Behavioral Data als (Teil) der Antwort\nHäufig sind Sensoren bereits in alltägliche Technologie eingebaut und produzieren digitale Verhaltensdaten als ein “Nebenprodukt”.\nBeispiel: COVID-19 Mobiliy Monitor"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#digital-behavioral-data",
    "href": "content/02-dbb-introduction_overview/index.html#digital-behavioral-data",
    "title": "Einführung und Überblick",
    "section": "Digital Behavioral Data",
    "text": "Digital Behavioral Data\n\nDefinition\nGESIS -Schema"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#grundidee-des-seminars",
    "href": "content/02-dbb-introduction_overview/index.html#grundidee-des-seminars",
    "title": "Einführung und Überblick",
    "section": "Grundidee des Seminars",
    "text": "Grundidee des Seminars\n\nFokus auf Konzeption & Datenerhebung\nAusblick auf Datenverarbeitung und -analyse\nLernziele"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#seminarplan",
    "href": "content/02-dbb-introduction_overview/index.html#seminarplan",
    "title": "Einführung und Überblick",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\n\n\n\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n20.10.2022\nPlanspielwoche\n\n\n\n2\n27.10.2022\nKick-Off Session\nC. Adrian\n\n\n3\n03.11.2022\nDBD: Einführung und Überblick\nC. Adrian\n\n\n4\n10.11.2022\nDBD: Datenerhebung\nC. Adrian\n\n\n5\n17.11.2022\nAPI-Access (I): Twitter\n\n\n\n6\n24.11.2022\nAPI-Access (II): YouTube\n\n\n\n7\n01.12.2022\nAPI-Access (II): Reddit\n\n\n\n8\n08.12.2022\nWebscraping: TikTok\n\n\n\n9\n15.12.2022\nESM: m-path\n\n\n\n\n\nWeihnachtspause\n\n\n\n10\n12.01.2023\nData Donations\n\n\n\n11\n19.01.2023\nMock-Up-Virtual Environments\n\n\n\n12\n26.01.2023\nOpen Science\n\n\n\n13\n02.02.2023\nGuest Lecture\n\n\n\n14\n09.02.2023\nSemesterabschluss & Evaluation\nC. Adrian"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#organisation-der-lehre-auf-einen-blick",
    "href": "content/02-dbb-introduction_overview/index.html#organisation-der-lehre-auf-einen-blick",
    "title": "Einführung und Überblick",
    "section": "Organisation der Lehre auf einen Blick",
    "text": "Organisation der Lehre auf einen Blick\n\nStudOn: Kursmaterialien\nMail: wichtige Ankündigungen durch Dozent & persönliche Fragen an Dozenten"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#leistungsanforderungen-prüfungsleistungen",
    "href": "content/02-dbb-introduction_overview/index.html#leistungsanforderungen-prüfungsleistungen",
    "title": "Einführung und Überblick",
    "section": "Leistungsanforderungen & Prüfungsleistungen",
    "text": "Leistungsanforderungen & Prüfungsleistungen\n\nRegelmäßige Teilnahme an den Sitzungen\nPräsentation\nDiskussionbeitrag\nSeminarbericht"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#aufteilung-präsentationsthemen",
    "href": "content/02-dbb-introduction_overview/index.html#aufteilung-präsentationsthemen",
    "title": "Einführung und Überblick",
    "section": "Aufteilung Präsentationsthemen",
    "text": "Aufteilung Präsentationsthemen"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#präsentationsvorbereitung",
    "href": "content/02-dbb-introduction_overview/index.html#präsentationsvorbereitung",
    "title": "Einführung und Überblick",
    "section": "Präsentationsvorbereitung",
    "text": "Präsentationsvorbereitung\n\nLiteratur\nSprechstunde\nEinreichung vollständiger Präsentationsentwurf\nUmfang & Inhalt"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#seminarbericht",
    "href": "content/02-dbb-introduction_overview/index.html#seminarbericht",
    "title": "Einführung und Überblick",
    "section": "Seminarbericht",
    "text": "Seminarbericht\n\nFormalia\nDetails\nDeadline"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#hinweise-und-offene-frage",
    "href": "content/02-dbb-introduction_overview/index.html#hinweise-und-offene-frage",
    "title": "Einführung und Überblick",
    "section": "Hinweise und offene Frage",
    "text": "Hinweise und offene Frage\n\nUnderstand the importance of effect sizes\nHow to formulate a smallest effect size of interest\nKnow when you don’t have enough information"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#quellen",
    "href": "content/02-dbb-introduction_overview/index.html#quellen",
    "title": "Einführung und Überblick",
    "section": "Quellen",
    "text": "Quellen"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#materials",
    "href": "content/02-dbb-introduction_overview/index.html#materials",
    "title": "Einführung und Überblick",
    "section": "Materials",
    "text": "Materials\n\nEverything is up on: https://github.com/niklasjohannes/power-workshop\nJust download everything as a zip file (Code -> Zip)\nRendered to follow along here: https://niklasjohannes.github.io/power-workshop/\nThere, you’ll also find instructions on how to download R, RStudio, and GPower\nFor discussions we use Discord:"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/index.html#stealing-stuff",
    "href": "content/02-dbb-introduction_overview/index.html#stealing-stuff",
    "title": "Einführung und Überblick",
    "section": "Stealing stuff",
    "text": "Stealing stuff\nI cite all my sources, but relied heavily on the following:\n\nJulian Quandt’s power simulation tutorials\nCourses by Daniel Lakens (textbook)\nTutorial by Ariel Muldoon\nBen Staton on Monte Carlo methods\nR for Data Science"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#herzlich-willkommen",
    "href": "content/01-kick-off/slides/index.html#herzlich-willkommen",
    "title": "Kick-Off",
    "section": "Herzlich willkommen!",
    "text": "Herzlich willkommen!\nVorstellungsrunde\nChristoph Adrian\n\nseit 2016: Research Assistant / PhD Candidate FAU\nM. Sc. Sozialökonomik (FAU)\nB.A. Sozialökonomik (FAU)\n\nForschungs- und Lehrschwerpunkte\n\nComputer-assisted and automated (corpus-based) content analysis (with R)\nSocial media research (Twitter)\nPotential influence of media use on attitude changes"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#literatur",
    "href": "content/01-kick-off/slides/index.html#literatur",
    "title": "Kick-Off",
    "section": "Literatur",
    "text": "Literatur\n\n\nWeller, K. (2021). A short introduction to computational social science and digital behavioral data. https://www.gesis.org/fileadmin/user_upload/MeettheExperts/GESIS_Meettheexperts_Introductioncss.pdf\n\n\n\n\n\nDigital Behavioral Data"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#please-state-your-preference",
    "href": "content/01-kick-off/slides/index.html#please-state-your-preference",
    "title": "Kick-Off",
    "section": "Please state your preference",
    "text": "Please state your preference\nVergabe der Präsentationsthemen\n\n\nBitte scannen Sie den QR-Code oder nutzen Sie folgenden Link und wählen Sie Ihr favorisiertes Thema aus\n\nhttps://www.menti.com/alj8fncx1zz4\nTemporary Voting Code: 7312 2522"
  },
  {
    "objectID": "index.html#students-will",
    "href": "index.html#students-will",
    "title": "Digital Behavioral Data",
    "section": "Students will",
    "text": "Students will\n\noverview and understand central opportunities of DBD and accompanying challenges for data collection and preprocessing\nevaluate the strengths and weaknesses of different ways of collecting DBD\nget to know and understand central requirements for data protection, research ethics, and data quality\nget to know and overview key computational social science methods to analyze DBD\npractice and apply knowledge on DBD, statistics, and data analysis in small projects of their own"
  },
  {
    "objectID": "index.html#recommended-prerequisites",
    "href": "index.html#recommended-prerequisites",
    "title": "Digital Behavioral Data",
    "section": "Recommended prerequisites",
    "text": "Recommended prerequisites\n\nInterest in social scientific perspectives on media, communication, and digital technologies.\nBasic knowledge of working with statistical software such as Stata, R, Python, or SPSS is required.\nStudents are recommended, but not required, to also visit the lecture Data Science: Foundations, Tools, Applications in Socio-Economics and Marketing."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Digital Behavioral Data",
    "section": "Schedule",
    "text": "Schedule\nBelow is the scheudle for the current semester.\n\n\n\n\n\n\n\n\nSession\nDatum\nTopic\n\n\n\n\n1\n26.10.2022\nKick-Off Session\n\n\n2\n02.11.2022\nDBD: Introduction & Overview\n\n\n3\n09.11.2022\nDBD: Data collection process in focus\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\n\n\n7\n07.12.2022\nWebscraping: TikTok\n\n\n8\n14.12.2022\nESM: m-path\n\n\n-\n-\nCHRISTMAS BREAK\n\n\n9\n12.01.2023\nData Donations\n\n\n10\n19.01.2023\nMock-Up-Virtual Environments\n\n\n11\n26.01.2023\nOpen Science\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\n\n\n13\n09.02.2023\nClosing Session: Recap, Evaluation & Discussion"
  },
  {
    "objectID": "index.html#copyright",
    "href": "index.html#copyright",
    "title": "Digital Behavioral Data",
    "section": "Copyright",
    "text": "Copyright\nThis content is licensed under a GPL-3.0 License."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#seminarplan",
    "href": "content/02-dbb-introduction_overview/slides/index.html#seminarplan",
    "title": "Einführung & Überblick",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einführung und Überblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nESM: m-path\nDörr\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nData Donations\n\n\n\n10\n19.01.2023\nMock-Up-Virtual Environments\n\n\n\n11\n26.01.2023\nOpen Science\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#alternativer-seminarplan",
    "href": "content/02-dbb-introduction_overview/slides/index.html#alternativer-seminarplan",
    "title": "Einführung & Überblick",
    "section": "“Alternativer” Seminarplan",
    "text": "“Alternativer” Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einführung und Überblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nExkurs: DBD Analyse mit R\nChristoph Adrian\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nESM: m-path\nDörr\n\n\n10\n19.01.2023\nTBD\nHofmann & Wierzbicki\n\n\n11\n26.01.2023\nPuffer\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#und-nun-zu-ihnen",
    "href": "content/02-dbb-introduction_overview/slides/index.html#und-nun-zu-ihnen",
    "title": "Einführung & Überblick",
    "section": "Und nun zu Ihnen!",
    "text": "Und nun zu Ihnen!\n\n\n\nDigital Behavioral Data\n\n\n\nWeller, Katrin. 2021. “A Short Introduction to Computational Social Science and Digital Behavioral Data,” June. https://www.gesis.org/fileadmin/user_upload/MeettheExperts/GESIS_Meettheexperts_Introductioncss.pdf."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#test",
    "href": "content/02-dbb-introduction_overview/slides/index.html#test",
    "title": "Einführung & Überblick",
    "section": "Test",
    "text": "Test\nChristoph Adrian\n\nseit 2016: Research Assistant / PhD Candidate FAU\nM. Sc. Sozialökonomik (FAU)\nB.A. Sozialökonomik (FAU)\n\nForschungs- und Lehrschwerpunkte\n\nComputer-assisted and automated (corpus-based) content analysis (with R)\nSocial media research (Twitter)\nPotential influence of media use on attitude changes"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#kurze-rekapitulation-der-letzten-sitzung",
    "href": "content/02-dbb-introduction_overview/slides/index.html#kurze-rekapitulation-der-letzten-sitzung",
    "title": "Einführung & Überblick",
    "section": "Kurze Rekapitulation der letzten Sitzung",
    "text": "Kurze Rekapitulation der letzten Sitzung\nWas sind Digital behavior data?\n\n\n\n\n\n\n\n\nWeller (2021)\n… fasst eine Vielzahl von möglichen Datenquellen zusammen, die verschiedene Arten von Aktivitäten aufzeichnen\n… können dabei helfen, Meinungen, Verhalten und Merkmale der menschlichen Nutzung digitaler Technologien zu erkennen"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#seminarplan-alternative",
    "href": "content/02-dbb-introduction_overview/slides/index.html#seminarplan-alternative",
    "title": "Einführung & Überblick",
    "section": "Seminarplan Alternative",
    "text": "Seminarplan Alternative\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einführung und Überblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nExkurs: DBD Analyse mit R\nChristoph Adrian\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nESM: m-path\nDörr\n\n\n10\n19.01.2023\nTBD\nHofmann & Wierzbicki\n\n\n11\n26.01.2023\nPuffer\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#warum-digital-behavioral-data",
    "href": "content/02-dbb-introduction_overview/slides/index.html#warum-digital-behavioral-data",
    "title": "Einführung & Überblick",
    "section": "Warum Digital behavioral data?",
    "text": "Warum Digital behavioral data?\n\nDigitale Geräte oder Sensoren können sich besser an bestimmte Fakten besser erinnern als das menschliche Gedächtnis. (Beispiel: SocioPatterns.org)\nUnd oft sind Sensoren bereits in alltägliche Technik eingebaut Technologie eingebaut und produzieren digitale Verhaltensdaten als ein “Nebenprodukt”. (Beispiel: Mobility Monitor)\nManchmal können digitale Verhaltensdaten die Untersuchung von Themen ermöglichen, für die es schwierig wäre, Studienteilnehmer zu rekrutieren sonst nicht möglich wäre. Sie werden oft ohne Anregung eines Forschers eines Forschers. (z.B. Messung des subjektiven Wohlbefindens)\nDigitale Verhaltensdaten können auch mit Umfragedaten kombiniert werden. (BeispieL Breuer)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#keine-dbd-ohne-css",
    "href": "content/02-dbb-introduction_overview/slides/index.html#keine-dbd-ohne-css",
    "title": "Einführung & Überblick",
    "section": "Keine DBD ohne CSS",
    "text": "Keine DBD ohne CSS\nCSS als Grundlage für DBD"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#was-kann-untersucht-werden",
    "href": "content/02-dbb-introduction_overview/slides/index.html#was-kann-untersucht-werden",
    "title": "Einführung & Überblick",
    "section": "Was kann untersucht werden?",
    "text": "Was kann untersucht werden?\nVerschiede Phänoemene"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#literatur",
    "href": "content/02-dbb-introduction_overview/slides/index.html#literatur",
    "title": "Einführung & Überblick",
    "section": "Literatur",
    "text": "Literatur\n\n\nAnderson, C. (2008). The end of theory: The data deluge makes the scientific method obsolete. Wired. https://www.wired.com/2008/06/pb-theory/\n\n\nboyd, danah m., & Ellison, N. B. (2007). Social Network Sites: Definition, History, and Scholarship. Journal of Computer-Mediated Communication, 13(1), 210–230. https://doi.org/10.1111/j.1083-6101.2007.00393.x\n\n\nEngel, U., Quan-Haase, A., Liu, S. X., & Lyberg, L. (2021). Digital trace data (1st ed., pp. 100–118). Routledge. https://doi.org/10.4324/9781003024583-8\n\n\nHarford, T. (2014). Big data: A big mistake? Significance, 11(5), 14–19. https://doi.org/10.1111/j.1740-9713.2014.00778.x\n\n\nLazer, D. M. J., Pentland, A., Watts, D. J., Aral, S., Athey, S., Contractor, N., Freelon, D., Gonzalez-Bailon, S., King, G., Margetts, H., Nelson, A., Salganik, M. J., Strohmaier, M., Vespignani, A., & Wagner, C. (2020). Computational social science: Obstacles and opportunities. Science, 369(6507), 1060–1062. https://doi.org/10.1126/science.aaz8170\n\n\nOlteanu, A., Castillo, C., Diaz, F., & Kıcıman, E. (2019). Social data: Biases, methodological pitfalls, and ethical boundaries. Frontiers in Big Data, 2, 13. https://doi.org/10.3389/fdata.2019.00013\n\n\nStruminskaya, B., Lugtig, P., Keusch, F., & Höhne, J. K. (2020). Augmenting Surveys With Data From Sensors and Apps: Opportunities and Challenges. Social Science Computer Review, 089443932097995. https://doi.org/10.1177/0894439320979951\n\n\nWeller, K. (2021). A short introduction to computational social science and digital behavioral data. https://www.gesis.org/fileadmin/user_upload/MeettheExperts/GESIS_Meettheexperts_Introductioncss.pdf\n\n\n\n\n\nDigital Behavioral Data"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#was-kann-untersucht-werden-1",
    "href": "content/02-dbb-introduction_overview/slides/index.html#was-kann-untersucht-werden-1",
    "title": "Einführung & Überblick",
    "section": "Was kann untersucht werden?",
    "text": "Was kann untersucht werden?\nVerschiede Phänoemene"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#zunehmende-verfügbarkeit-durch-technologischen-fortschritt",
    "href": "content/02-dbb-introduction_overview/slides/index.html#zunehmende-verfügbarkeit-durch-technologischen-fortschritt",
    "title": "Einführung & Überblick",
    "section": "Zunehmende Verfügbarkeit durch technologischen Fortschritt",
    "text": "Zunehmende Verfügbarkeit durch technologischen Fortschritt\nQUelle"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#verfügbarkeit-durch-fortschritt",
    "href": "content/02-dbb-introduction_overview/slides/index.html#verfügbarkeit-durch-fortschritt",
    "title": "Einführung & Überblick",
    "section": "Verfügbarkeit durch Fortschritt",
    "text": "Verfügbarkeit durch Fortschritt\nAm Beispiel der wachsenden Anzahl eingebauter Smartphone-Sensoren\n\nGraphik aus Struminskaya et al. (2020)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ver",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ver",
    "title": "Einführung & Überblick",
    "section": "Ver",
    "text": "Ver\nKategorisierung verschiedener Verhaltensweisen\n\n\n\n\n\n\n\n\n\nEinschränkungen\n\nKategorisierung ist Momentaufnahme und erlaubt Überschneidungen der Kategorien\nSelektive Nutzung von bestimmten digitalen Geräten\n\n\n\n\n\nKategorien: Digital/Analog individual/social behavior\nEinige inhärent digitale Verhalten (z.B. Web Searches) bei zunehmender Digitalisierung von analogen Verhalten (z.B. Collaborative Work)\nFehlen digitaler Spurendaten in all diesen Quadranten für bestimmte Personen und bestimmte Verhaltensweisen durch selektive Nutzung digitaler Geräte."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#der-vorteil-der-unaufdringlichkeit",
    "href": "content/02-dbb-introduction_overview/slides/index.html#der-vorteil-der-unaufdringlichkeit",
    "title": "Einführung & Überblick",
    "section": "Der Vorteil der Unaufdringlichkeit",
    "text": "Der Vorteil der Unaufdringlichkeit\nUntersuchung von Meinungen\n\nDie Auswertung von Meinungen aus bestehenden digitalen Kommunikationsströmen kann zeitnaher sein als die Erstellung einer Umfrage. Sie sind eine wertvolle Quelle, insbesondere bei unvorhersehbaren Ereignissen. (z.B. Maßnahmen zu COVID-19)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#kurzer-rückblick",
    "href": "content/02-dbb-introduction_overview/slides/index.html#kurzer-rückblick",
    "title": "Einführung & Überblick",
    "section": "Kurzer Rückblick",
    "text": "Kurzer Rückblick\nWas sind Digital behavior data?\n\n\n\n\n\n\n\n\nWeller (2021)\n… fasst eine Vielzahl von möglichen Datenquellen zusammen, die verschiedene Arten von Aktivitäten aufzeichnen\n… können dabei helfen, Meinungen, Verhalten und Merkmale der menschlichen Nutzung digitaler Technologien zu erkennen"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#untersuchung-von-verhaltensweisen",
    "href": "content/02-dbb-introduction_overview/slides/index.html#untersuchung-von-verhaltensweisen",
    "title": "Einführung & Überblick",
    "section": "Untersuchung von Verhaltensweisen",
    "text": "Untersuchung von Verhaltensweisen\nKategorisierung verschiedener Verhaltensweisen\n\n\n\n\n\n\n\n\n\nEinschränkungen\n\nKategorisierung ist Momentaufnahme und erlaubt Überschneidungen der Kategorien\nSelektive Nutzung von bestimmten digitalen Geräten\n\n\n\n\n\nKategorien: Digital/Analog individual/social behavior\nEinige inhärent digitale Verhalten (z.B. Web Searches) bei zunehmender Digitalisierung von analogen Verhalten (z.B. Collaborative Work)\nFehlen digitaler Spurendaten in all diesen Quadranten für bestimmte Personen und bestimmte Verhaltensweisen durch selektive Nutzung digitaler Geräte."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#kursmaterialien-etc.",
    "href": "content/02-dbb-introduction_overview/slides/index.html#kursmaterialien-etc.",
    "title": "Einführung & Überblick",
    "section": "Kursmaterialien etc.",
    "text": "Kursmaterialien etc.\nKurze Einführung in Teams"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#vorschlag-alternativer-seminarplan",
    "href": "content/02-dbb-introduction_overview/slides/index.html#vorschlag-alternativer-seminarplan",
    "title": "Einführung & Überblick",
    "section": "Vorschlag: Alternativer Seminarplan",
    "text": "Vorschlag: Alternativer Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einführung und Überblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nExkurs: DBD Analyse mit R\nChristoph Adrian\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nESM: m-path\nDörr\n\n\n10\n19.01.2023\nTBD\nHofmann & Wierzbicki\n\n\n11\n26.01.2023\nPuffer\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#dbd---was-ist-das-eigentlich",
    "href": "content/02-dbb-introduction_overview/slides/index.html#dbd---was-ist-das-eigentlich",
    "title": "Einführung & Überblick",
    "section": "DBD - Was ist das eigentlich?",
    "text": "DBD - Was ist das eigentlich?\nRückblick auf Definition nach Weller (2021)\n\n… fasst eine Vielzahl von möglichen Datenquellen zusammen, die verschiedene Arten von Aktivitäten aufzeichnen\n… können dabei helfen, Meinungen, Verhalten und Merkmale der menschlichen Nutzung digitaler Technologien zu erkennen\n\n\n\n\nIm Kontext dieses Seminars:\n\nSchwerpunkt Soziale Medien und Mediennutzung\nComputational Social Science [CSS] zur Erhebung (& Auswertung)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#was-ist-das-eigentlich",
    "href": "content/02-dbb-introduction_overview/slides/index.html#was-ist-das-eigentlich",
    "title": "Einführung & Überblick",
    "section": "Was ist das eigentlich?",
    "text": "Was ist das eigentlich?\nRückblick auf Definition (nach Weller (2021))\nDigital behavioral data …\n\n… fasst eine Vielzahl von möglichen Datenquellen zusammen, die verschiedene Arten von Aktivitäten aufzeichnen\n… können dabei helfen, Meinungen, Verhalten und Merkmale der menschlichen Nutzung digitaler Technologien zu erkennen\n\nIm Kontext dieses Seminars:\n\nSchwerpunkt “Soziale Medien”"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#fokus-auf-die-rahmenbedingungen",
    "href": "content/02-dbb-introduction_overview/slides/index.html#fokus-auf-die-rahmenbedingungen",
    "title": "Einführung & Überblick",
    "section": "Fokus auf die Rahmenbedingungen",
    "text": "Fokus auf die Rahmenbedingungen\nDBD-Kernbereiche in Anlehnung an Aufteilung der GESIS\n\n\n\n\n\n\n\n\nHeute Schwerpunkt:"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#kein-dbd-ohne-css",
    "href": "content/02-dbb-introduction_overview/slides/index.html#kein-dbd-ohne-css",
    "title": "Einführung & Überblick",
    "section": "Kein DBD ohne CSS",
    "text": "Kein DBD ohne CSS\nExkurs: Computational Social Science\n\n\n\nDefinition von CSS\n\n\nWe define CSS as the development and application of computational methods to complex, typically large-scale, human (sometimes simulated) behavioral data.” Lazer et al. (2020)\n\n\n\nist ein Forschungsfeld, das\n\nrechnergestützte Methoden einsetzt\num Daten zu sammeln und zu analysieren, insbesondere große und digitale Verhaltensdaten,\num gesellschaftlich relevante Phänomene zu untersuchen.\n\nhilft dabei …\n\nechte digitale Phänomene zu untersuchen\ndigitale Verhaltensdaten zu sammeln und vorzuverarbeiten\nneue Methoden zur Analyse von großen Datensätzen\n\n\nCSS = neues Teilgebiet der Sozialwissenschaften oder neuer “Werkzeugkasten” zur Ergänzung der traditionellen sozialwissenschaftlichen Ansätze"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#untersuchung-von-meinungen",
    "href": "content/02-dbb-introduction_overview/slides/index.html#untersuchung-von-meinungen",
    "title": "Einführung & Überblick",
    "section": "Untersuchung von Meinungen",
    "text": "Untersuchung von Meinungen\nBeispiel: Twitter Screenshots/Mining\n\nDie Auswertung von Meinungen aus bestehenden digitalen Kommunikationsströmen kann zeitnaher sein als die Erstellung einer Umfrage. Sie sind eine wertvolle Quelle, insbesondere bei unvorhersehbaren Ereignissen. (z.B. Maßnahmen zu COVID-19)\n\nTODO: Beispiel hier"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ambivalenz-der-unaufdringlichkeit",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ambivalenz-der-unaufdringlichkeit",
    "title": "Einführung & Überblick",
    "section": "Ambivalenz der Unaufdringlichkeit",
    "text": "Ambivalenz der Unaufdringlichkeit\nbasierend auf Engel et al. (2021)\n\nUnterscheidung zwischen aufdringlichen (z.B. spezielle Research-App & Befragungen) & unaufdringlichen (z.B. Cookie & APIs) erhobenen Daten\nBewertung und Erwartung an Datensammlung ist abhängig vom Kontext (Amazon vs. Researchgate)\nDilema: Einerseits bereitwillige (oft unwissende) Abgabe der Daten an Konzerne, andererseits häufig Bedenken bezüglich Datenschutz & Privatsphäre bei wissenschaftlichen Studien\n\n\nQ: Gründe für Ablehnung: Nutzenorientierung?"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#choose-your-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#choose-your-bias",
    "title": "Einführung & Überblick",
    "section": "Choose your bias",
    "text": "Choose your bias\nDBD-Kernbereiche in Anlehnung an Aufteilung der GESIS\n\n\n\n\n\n\n\n\nHeute Schwerpunkt:\n\nKonzeptuelle Herangehensweise\nBias"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#verfügbarkeit-vor-interesse",
    "href": "content/02-dbb-introduction_overview/slides/index.html#verfügbarkeit-vor-interesse",
    "title": "Einführung & Überblick",
    "section": "Verfügbarkeit vor Interesse",
    "text": "Verfügbarkeit vor Interesse\nZur Wichtigkeit von konzipierte Messungen & Designs\n\nDBB sind häufig organische Daten, die zufällig gesammelt und dann von der Wissenschaft “recycelt” werden\n\nZentrale Frage: Ist das ein Problem? Wenn ja, warum?\n\nRepräsentativität vs. Stichprobenziehung\nKausalität vs. Korrelation"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#the-end-of-theory",
    "href": "content/02-dbb-introduction_overview/slides/index.html#the-end-of-theory",
    "title": "Einführung & Überblick",
    "section": "The End of Theory",
    "text": "The End of Theory\nZur Wichtigkeit von konzipierte Messungen & Designs\n\n\n\n“Who knows why people do what they do? The point is they do it, and we can track and measure it with unprecedented fidelity. With enough data, the numbers speak for themselves.” (Anderson, 2008)\n\n\n\n“Size alone does not necessarily make the data better” (boyd & Ellison, 2007)\n\n\n“there are a lot of small data problems that occur in big data [which] don’t disappear because you’ve got lots of the stuff. They get worse” (Harford, 2014)\n\n\n\nProblem\n\n(Big) Data zunehmend Grundlage für politische Maßnahmen, die Gestaltung von Produkten und Dienstleistungen und für die automatisierte Entscheidungsfindung"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#lets-talk-about-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#lets-talk-about-bias",
    "title": "Einführung & Überblick",
    "section": "Let’s talk about bias",
    "text": "Let’s talk about bias\nProblem:\n\nthere is not enough agreement on a vocabulary or taxonomy of biases, methodological issues, and pitfalls of this type of research.\nthe evidence of bias and of broader implications about potential threats to the validity of social data research is often implicit in the findings of prior work, rather than a primary focus of it.\nOftentimes, however, it is difficult to draw clear boundaries between the more normative connotations and the statistical sense of the term —see Campolo et al. (2017) for a discussion on some of the competing meanings of the term “bias.”\n\n\nterm “bias” is used in its more statistical sense to refer to biases in social data and social data analyses"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ein-framework-zur-fehlervermeidung",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ein-framework-zur-fehlervermeidung",
    "title": "Einführung & Überblick",
    "section": "Ein Framework zur Fehlervermeidung",
    "text": "Ein Framework zur Fehlervermeidung\nvon Olteanu et al. (2019)\n\n\nDescription:\n\nSocial data analysis starts with certain goals (section 2.1), such as understanding or influencing phenomena specific to social platforms (Type I) and/or phenomena beyond social platforms (Type II).\nThese goals require that research satisfies certain validity criteria, described earlier (section 2.2).\nThese criteria, in turn, can be compromised by a series of general biases and issues (section 3).\nThese challenges may depend on the characteristics of each data platform (section 4)—which are often not under the control of the researcher—and on the research designs choices made along a data processing pipeline (from sections 5 to 8)–which are often under the researcher control.\n\nPfeile zeigen an, wie sich Komponenten in unserem Rahmenwerk direkt auf andere auswirken\n\nErreichen bestimmter Ziele (Type I & II) bei der Analyse von Sozialdaten (Abschnitt 2.1) voraussetzt, dass die Forschung bestimmte Validitätskriterien erfüllt (Abschnitt 2.2),\ndie durch Verzerrungen und andere Probleme mit Sozialdaten beeinträchtigt werden können (Abschnitt 3)\nDiese Verzerrungen und Probleme können an der Quelle der Daten auftreten (Abschnitt 4), oder sie können im Verlauf der Datenanalyse eingeführt werden (Abschnitte 5-8)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#was-wird-vom-bias-beeinflusst",
    "href": "content/02-dbb-introduction_overview/slides/index.html#was-wird-vom-bias-beeinflusst",
    "title": "Einführung & Überblick",
    "section": "Was wird vom Bias beeinflusst?",
    "text": "Was wird vom Bias beeinflusst?\nValidität als Grundlage für “Aussagekraft”\n\n\n\nType I: research on maximizing the spread of “memes,” on making social software more engaging, and on improving the search engine or the recommendation system of a platform.\nType II: seek to use social data to answer questions and identify interventions relevant to media, governments, non-governmental organizations, and business, or to work on problems from domains such as health, economics, and education.\nConstruct validity:\n\nDo our measurements over our data measure what we think they measure?\nBeispiel: If a hypothesis states that “self-esteem” increases with age, research tracking self-esteem over time from social media postings must ask whether its assessment of selfesteem from the postings actually measures self-esteem, or if instead it measures some other related or unrelated construct. In other words, we need to know whether the observed behaviors (such as words or phrases used in postings) are driven primarily by users’ self-esteem vs. by community norms (section 4.2), system functionalities (section 4.1), or other reasons (section 3.3). Construct validity is specially important when the construct (self-esteem) is unobservable/latent and has to be operationalized via some observed attributes (words or phrases used)\n\nInternal validity\n\nDoes our analysis correctly lead from the measurements to the conclusions of the study?\nThis survey covers subtle errors of this kind, such as biases that can be introduced through data cleaning procedures (section 6), the use of machine learned classifiers, mistaken assumptions about data distributions, and other inadvertent biases introduced through common analyses of social media (section 7).\nExample: An analysis of whether “self-esteem” increases with age may not be internally valid if text filtering operations accidentally remove terms expressing confidence (section 5.3); or if machine learned classifiers were inadvertently trained to recognize self-esteem only in younger people (section 7). Of course, while we do not dwell on them, researchers should also be aware of more blatant logical errors—e.g., comparing the self-esteem of today’s younger population to the self-esteem of today’s older population would not actually prove that selfesteem increases with age (section 3.6).\n\nExternal validity:\n\nTo what extent can research findings be generalized to other situations?\nFor example, effects observed on a social platform may manifest differently on other platforms due to different functionalities, communities, or cultural norms (Wijnhoven and Bloemen, 2014; Malik and Pfeffer, 2016). The concept of external validity includes what is sometimes called ecological validity, which captures to what extent an artificial situation (constrained social media platform) properly reflects a broader real-world phenomenon (Ruths and Pfeffer, 2014). It also includes temporal validity, which captures to what extent constructs change over time (Howison et al., 2011) and may invalidate previous conclusions about societal and/or platform phenomena; e.g., see the case of Google Flu Trends (Lazer et al., 2014).\nExample: Even after we conclude a successful study of “selfesteem” in a longitudinal social media dataset collected from a given social media platform (section 4), its findings may not generalize to a broader setting as people who chose that particular platform may not be representative of the broader population (section 3.2); or perhaps their behaviors online are not representative of their behaviors in other settings (section 3.3)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#eine-frage-der-datenqualität",
    "href": "content/02-dbb-introduction_overview/slides/index.html#eine-frage-der-datenqualität",
    "title": "Einführung & Überblick",
    "section": "Eine Frage der Datenqualität",
    "text": "Eine Frage der Datenqualität\nVerschiedene Kriterien"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#verschiedene-biases-im-überblick",
    "href": "content/02-dbb-introduction_overview/slides/index.html#verschiedene-biases-im-überblick",
    "title": "Einführung & Überblick",
    "section": "Verschiedene Biases im Überblick",
    "text": "Verschiedene Biases im Überblick\n\n\nPopulation bias\nContent bias\nLinking bias\nTemporal bias\nRedundancy\n\n\n\n\n\nDefinition\n\n\nA systematic distortion in the sampled data that compromises its representativeness\n\n\n\nHerausforderungen:\n\nRepräsentativität"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#verschiedene-biases-im-überblick-test-1",
    "href": "content/02-dbb-introduction_overview/slides/index.html#verschiedene-biases-im-überblick-test-1",
    "title": "Einführung & Überblick",
    "section": "Verschiedene Biases im Überblick (TEST 1)",
    "text": "Verschiedene Biases im Überblick (TEST 1)\n\n\nData bias\nPopulation bias\nContent bias\nLinking bias\nTemporal bias\nRedundancy\n\n\n\n\n\nDefinition\n\n\nA systematic distortion in the sampled data that compromises its representativeness\n\n\n\nIssues:\n\nSampling"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#verschiedene-biases-im-überblick-test-2",
    "href": "content/02-dbb-introduction_overview/slides/index.html#verschiedene-biases-im-überblick-test-2",
    "title": "Einführung & Überblick",
    "section": "Verschiedene Biases im Überblick (TEST 2)",
    "text": "Verschiedene Biases im Überblick (TEST 2)\n\n\nTyp:\n\nData\nPopulation\nContent\nLinking\nTemporal\nRedundancy\n\n\n\n\n\nDefinition “data bias”\n\n\nA systematic distortion in the sampled data that compromises its representativeness\n\n\n\nIssues:\n\nSampling"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#data-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#data-bias",
    "title": "Einführung & Überblick",
    "section": "Data bias",
    "text": "Data bias\nPopulation bias\nContent bias\nLinking bias\nTemporal bias\nRedundancy bias"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#verschiedene-biases-im-überblick-1",
    "href": "content/02-dbb-introduction_overview/slides/index.html#verschiedene-biases-im-überblick-1",
    "title": "Einführung & Überblick",
    "section": "Verschiedene Biases im Überblick",
    "text": "Verschiedene Biases im Überblick\n\n\nData bias\nPopulation bias\nContent bias\nLinking bias\nTemporal bias\nRedundancy\n\n\n\n\n\nDefinition\n\n\nSystematic distortions in demographics or other user characteristics between a population of users represented in a dataset or on a platform and some target population.\n\n\n\nAuswirkungen:\n\nmay affect the representativeness of a data sample and, as a result, may compromise the ecological/external validity of research.\nparticularly problematic for research of type II (section 2.1), where conclusions about society are sought from social data, such as studies of public opinion.\ncan also impact the performance of algorithms that make inferences about users (Johnson et al., 2017), further compromising the internal validity of both type I and type II research.\n\nAllgemeine Probleme:\n\nDifferent user demographics tend to be drawn to different social platforms.\nDifferent user demographics use platform mechanisms differently\nProxies for user traits or demographic criteria vary in reliabi"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#header-1",
    "href": "content/02-dbb-introduction_overview/slides/index.html#header-1",
    "title": "Einführung & Überblick",
    "section": "HEader 1",
    "text": "HEader 1\nIm Fokus: population bias\n\n\n\nSystematic distortions in demographics or other user characteristics between a population of users represented in a dataset or on a platform and some target population.\n\n\n\nAuswirkungen:\n\nkann die (Stichproben)-Repräsentativität beeinträchtigen\n➥ ⚠️externe Validität\nbesonders problematisch für Forschungsarbeiten des Typs II\nkann sich auch auf die Leistung von Algorithmen auswirken, die Rückschlüsse auf die Nutzer ziehen\n➥ ⚠️interne Validität (Typ-I & Typ II)\n\nAllgemeine Probleme:\n\nUnterschiedliche Demographien (z.B. Geschlechts-, Alters- & Bildungsgruppen) neigen zu unterschiedlichen sozialen Plattformen und nutzen deren Mechanismen unterschiedlich\nProxies für Eigenschaften oder demografische Kriterien der Nutzenden sind unterschiedlich verlässlich\n\n\nHäufig ist der Zusammenhang von Untersuchungspopulation (z.B. in Deutschland lebende Erwachsene) zu Zielpopulation (Erwachsene auf Twitter, die angeben, in DE zu leben) unbekannt.\nBeispiel “Auswirkungen”\n\nAlgorithmen: Schätzung der Geo-Location im Stadt-Land-Spektrum (z.B Johnson et al., 2017)\n\nBeispiele “Probleme”:\n\nSignifikant mehr Twitter Nutzer (Mislove et al. ,2011), bei Pinterest tendenziell Frauen überrepräsentiert (Ottoni et al., 2013)\nUnterschiedliche Twitter-Nutzung in DE (Fokus auf Hashtags) und KOR (Fokus auf Konversationen) (Hong et al., 2011).\nAngabe von Geo-Location oder Profilinformationen in sozialen Netzwerken"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#header-2",
    "href": "content/02-dbb-introduction_overview/slides/index.html#header-2",
    "title": "Einführung & Überblick",
    "section": "HEader 2",
    "text": "HEader 2\nIm Fokus: behavioral bias\n\n\n\nSystematic distortions in user behavior across platforms or contexts, or across users represented in different datasets.\n\n\n\nAuswirkungen:\n\nErgebnisse einer Studie von der gewählten Plattform oder dem Kontext abhängig\n➤ ⚠️externe Validität\nnur Teilweise von population bias abhängig\nbei (expliziten oder impliziten) Annahmen über die Verhaltensmuster der Nutzenden\n➤ ⚠️potentielle Effekte auf Untersuchung von Typ-I & Typ II\n\nAllgemeine Probleme:\n\nbeeinflussen die Art und Weise, wie Nutzer miteinander interagieren\nAuftreten von Selbstselektion und Reaktionsverzerrungen\nVerzerrungen beim Konsumieren von Inhalten beeinflussen die Art und Weise, wie Nutzer Inhalte finden und mit ihnen interagieren, aufgrund von Unterschieden in ihren Interessen, ihrem Fachwissen und ihrem Informationsbedarf\nkönnen aufgrund von Verhaltensverzerrungen auftreten\nContent consumption biases affect how users find and interact with content, due to differences in their interests, expertise, and information needs\nSelf-selection and response bias may occur due to behavioral biases\n\n\nUnterschiede in Bezug auf Nutzerpersönlichkeiten (Hughes et al., 2012), die Verbreitung von Nachrichten (Lerman und Ghosh, 2010) oder den Austausch von Inhalten (Ottoni et al., 2014)\nBeispiel “Auswirkungen”:\n\n\nB. die Untersuchung der Bedürfnisse oder Interessen der Nutzenden\n\n\nBeispiel “Probleme”:\n\nGesonderte Diskussion von Verhalten, die sich auf die Erstellung von Inhalten durch die Nutzer auswirken (“content production bias”) und solche, die sich auf die Verknüpfungsmuster zwischen Nutzern auswirken (“linking bias”).\nDrei weitere häufige Klassen von Verhaltensverzerrungen betreffen die Interaktionen zwischen Nutzern, die Interaktionen zwischen Nutzern und Inhalten und die Verzerrungen, die dazu führen, dass Nutzer in eine Studienpopulation aufgenommen oder von ihr ausgeschlossen werden."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ein-framework-zur-minimierung-von-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ein-framework-zur-minimierung-von-bias",
    "title": "Einführung & Überblick",
    "section": "Ein Framework zur Minimierung von Bias",
    "text": "Ein Framework zur Minimierung von Bias\nOlteanu et al. (2019)\n\n\nDescription:\n\nSocial data analysis starts with certain goals (section 2.1), such as understanding or influencing phenomena specific to social platforms (Type I) and/or phenomena beyond social platforms (Type II).\nThese goals require that research satisfies certain validity criteria, described earlier (section 2.2).\nThese criteria, in turn, can be compromised by a series of general biases and issues (section 3).\nThese challenges may depend on the characteristics of each data platform (section 4)—which are often not under the control of the researcher—and on the research designs choices made along a data processing pipeline (from sections 5 to 8)–which are often under the researcher control.\n\nPfeile zeigen an, wie sich Komponenten in unserem Rahmenwerk direkt auf andere auswirken\n\nErreichen bestimmter Ziele (Type I & II) bei der Analyse von Sozialdaten (Abschnitt 2.1) voraussetzt, dass die Forschung bestimmte Validitätskriterien erfüllt (Abschnitt 2.2),\ndie durch Verzerrungen und andere Probleme mit Sozialdaten beeinträchtigt werden können (Abschnitt 3)\nDiese Verzerrungen und Probleme können an der Quelle der Daten auftreten (Abschnitt 4), oder sie können im Verlauf der Datenanalyse eingeführt werden (Abschnitte 5-8)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#validität-als-grundlage-für-aussagekraft",
    "href": "content/02-dbb-introduction_overview/slides/index.html#validität-als-grundlage-für-aussagekraft",
    "title": "Einführung & Überblick",
    "section": "Validität als Grundlage für “Aussagekraft”",
    "text": "Validität als Grundlage für “Aussagekraft”\nDie verschiedenen Formen von Validität\nInterne Validität\n\nDoes our analysis correctly lead from the measurements to the conclusions of the study?\n\nExterne Validität\n\nTo what extent can research findings be generalized to other situations?\n\nKonstruktvaldität\n\nDo our measurements over our data measure what we think they measure?\n\n\n\nType II: Nutzung sozialer Daten zur Beantwortung von Fragen und zur Ermittlung von Maßnahmen, die für Medien, Regierungen, Nichtregierungsorganisationen und Unternehmen relevant sind, oder zur Bearbeitung von Problemen aus Bereichen wie Gesundheit, Wirtschaft und Bildung..\nConstruct validity:\n\nBeispiel: If a hypothesis states that “self-esteem” increases with age, research tracking self-esteem over time from social media postings must ask whether its assessment of selfesteem from the postings actually measures self-esteem, or if instead it measures some other related or unrelated construct. In other words, we need to know whether the observed behaviors (such as words or phrases used in postings) are driven primarily by users’ self-esteem vs. by community norms (section 4.2), system functionalities (section 4.1), or other reasons (section 3.3). Construct validity is specially important when the construct (self-esteem) is unobservable/latent and has to be operationalized via some observed attributes (words or phrases used)\n\nInternal validity\n\nDoes our analysis correctly lead from the measurements to the conclusions of the study?\nThis survey covers subtle errors of this kind, such as biases that can be introduced through data cleaning procedures (section 6), the use of machine learned classifiers, mistaken assumptions about data distributions, and other inadvertent biases introduced through common analyses of social media (section 7).\nExample: An analysis of whether “self-esteem” increases with age may not be internally valid if text filtering operations accidentally remove terms expressing confidence (section 5.3); or if machine learned classifiers were inadvertently trained to recognize self-esteem only in younger people (section 7). Of course, while we do not dwell on them, researchers should also be aware of more blatant logical errors—e.g., comparing the self-esteem of today’s younger population to the self-esteem of today’s older population would not actually prove that selfesteem increases with age (section 3.6).\n\nExternal validity:\n\nTo what extent can research findings be generalized to other situations?\nFor example, effects observed on a social platform may manifest differently on other platforms due to different functionalities, communities, or cultural norms (Wijnhoven and Bloemen, 2014; Malik and Pfeffer, 2016). The concept of external validity includes what is sometimes called ecological validity, which captures to what extent an artificial situation (constrained social media platform) properly reflects a broader real-world phenomenon (Ruths and Pfeffer, 2014). It also includes temporal validity, which captures to what extent constructs change over time (Howison et al., 2011) and may invalidate previous conclusions about societal and/or platform phenomena; e.g., see the case of Google Flu Trends (Lazer et al., 2014).\nExample: Even after we conclude a successful study of “selfesteem” in a longitudinal social media dataset collected from a given social media platform (section 4), its findings may not generalize to a broader setting as people who chose that particular platform may not be representative of the broader population (section 3.2); or perhaps their behaviors online are not representative of their behaviors in other settings (section 3.3)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#worauf-wirkt-die-verzerrung",
    "href": "content/02-dbb-introduction_overview/slides/index.html#worauf-wirkt-die-verzerrung",
    "title": "Einführung & Überblick",
    "section": "Worauf wirkt die Verzerrung?",
    "text": "Worauf wirkt die Verzerrung?\nBeispiele für Forschung von Typ I & II (Olteanu et al., 2019)\n\n\nTyp I: understand/influence phenomena specific to social platforms\n\nDynamik der Verbreitung von “Memes”\nSteigerung der Attraktivität bzw. besonders Features\nVerbesserung der Suchfunktion oder des Empfehlungssystems\n\nTyp II: understand/influence phenomena beyond social platforms\n\nBeschreibung des Einflusses sozialer Medien auf eine politische Wahl.\nNutzung sozialer Daten zur Verfolgung der Entwicklung ansteckender Krankheiten durch Analyse der von Social-Media-Nutzern online gemeldeten Symptomen"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#verzerrung-durch-die-bevölkerungsstruktur",
    "href": "content/02-dbb-introduction_overview/slides/index.html#verzerrung-durch-die-bevölkerungsstruktur",
    "title": "Einführung & Überblick",
    "section": "Verzerrung durch die Bevölkerungsstruktur",
    "text": "Verzerrung durch die Bevölkerungsstruktur\nIm Fokus: population bias\n\n\n\nSystematic distortions in demographics or other user characteristics between a population of users represented in a dataset or on a platform and some target population.\n\n\n\nAuswirkungen:\n\nkann die (Stichproben)-Repräsentativität beeinträchtigen\n➥ ⚠️externe Validität\nbesonders problematisch für Forschungsarbeiten des Typs II\nkann sich auch auf die Leistung von Algorithmen auswirken, die Rückschlüsse auf die Nutzer ziehen\n➥ ⚠️interne Validität (Typ-I & Typ II)\n\nAllgemeine Probleme:\n\nUnterschiedliche Demographien (z.B. Geschlechts-, Alters- & Bildungsgruppen) neigen zu unterschiedlichen sozialen Plattformen und nutzen deren Mechanismen unterschiedlich\nProxies für Eigenschaften oder demografische Kriterien der Nutzenden sind unterschiedlich verlässlich\n\n\nHäufig ist der Zusammenhang von Untersuchungspopulation (z.B. in Deutschland lebende Erwachsene) zu Zielpopulation (Erwachsene auf Twitter, die angeben, in DE zu leben) unbekannt.\nBeispiel “Auswirkungen”\n\nAlgorithmen: Schätzung der Geo-Location im Stadt-Land-Spektrum (z.B Johnson et al., 2017)\n\nBeispiele “Probleme”:\n\nSignifikant mehr Twitter Nutzer (Mislove et al. ,2011), bei Pinterest tendenziell Frauen überrepräsentiert (Ottoni et al., 2013)\nUnterschiedliche Twitter-Nutzung in DE (Fokus auf Hashtags) und KOR (Fokus auf Konversationen) (Hong et al., 2011).\nAngabe von Geo-Location oder Profilinformationen in sozialen Netzwerken"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#verzerrung-durch-die-bevölkerungsstruktur-1",
    "href": "content/02-dbb-introduction_overview/slides/index.html#verzerrung-durch-die-bevölkerungsstruktur-1",
    "title": "Einführung & Überblick",
    "section": "Verzerrung durch die Bevölkerungsstruktur",
    "text": "Verzerrung durch die Bevölkerungsstruktur\n\n\n\n\nSystematic distortions in demographics or other user characteristics between a population of users represented in a dataset or on a platform and some target population.\n\n\n\nAuswirkungen:\n\nkann die (Stichproben)-Repräsentativität beeinträchtigen\n➥ ⚠️externe Validität\nbesonders problematisch für Forschungsarbeiten des Typs II\nkann sich auch auf die Leistung von Algorithmen auswirken, die Rückschlüsse auf die Nutzer ziehen\n➥ ⚠️interne Validität (Typ-I & Typ II)\n\nAllgemeine Probleme:\n\nUnterschiedliche Demographien (z.B. Geschlechts-, Alters- & Bildungsgruppen) neigen zu unterschiedlichen sozialen Plattformen und nutzen deren Mechanismen unterschiedlich\nProxies für Eigenschaften oder demografische Kriterien der Nutzenden sind unterschiedlich verlässlich\n\nHäufig ist der Zusammenhang von Untersuchungspopulation (z.B. in Deutschland lebende Erwachsene) zu Zielpopulation (Erwachsene auf Twitter, die angeben, in DE zu leben) unbekannt.\nBeispiel “Auswirkungen”\n\nAlgorithmen: Schätzung der Geo-Location im Stadt-Land-Spektrum (z.B Johnson et al., 2017)\n\nBeispiele “Probleme”:\n\nSignifikant mehr Twitter Nutzer (Mislove et al. ,2011), bei Pinterest tendenziell Frauen überrepräsentiert (Ottoni et al., 2013)\nUnterschiedliche Twitter-Nutzung in DE (Fokus auf Hashtags) und KOR (Fokus auf Konversationen) (Hong et al., 2011).\nAngabe von Geo-Location oder Profilinformationen in sozialen Netzwerken"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#verzerrung-durch-verhaltensmuster",
    "href": "content/02-dbb-introduction_overview/slides/index.html#verzerrung-durch-verhaltensmuster",
    "title": "Einführung & Überblick",
    "section": "Verzerrung durch Verhaltensmuster",
    "text": "Verzerrung durch Verhaltensmuster\nIm Fokus: behavioral bias\n\n\n\nSystematic distortions in user behavior across platforms or contexts, or across users represented in different datasets.\n\n\n\nAuswirkungen:\n\nErgebnisse einer Studie von der gewählten Plattform oder dem Kontext abhängig\n➤ ⚠️externe Validität\nnur Teilweise von population bias abhängig\nbei (expliziten oder impliziten) Annahmen über die Verhaltensmuster der Nutzenden\n➤ ⚠️potentielle Effekte auf Untersuchung von Typ-I & Typ II\n\nAllgemeine Probleme:\n\nbeeinflussen die Art und Weise, wie Nutzer miteinander interagieren\nAuftreten von Selbstselektion und Reaktionsverzerrungen\nVerzerrungen beim Konsumieren von Inhalten beeinflussen die Art und Weise, wie Nutzer Inhalte finden und mit ihnen interagieren, aufgrund von Unterschieden in ihren Interessen, ihrem Fachwissen und ihrem Informationsbedarf\nkönnen aufgrund von Verhaltensverzerrungen auftreten\nContent consumption biases affect how users find and interact with content, due to differences in their interests, expertise, and information needs\nSelf-selection and response bias may occur due to behavioral biases\n\n\nUnterschiede in Bezug auf Nutzerpersönlichkeiten (Hughes et al., 2012), die Verbreitung von Nachrichten (Lerman und Ghosh, 2010) oder den Austausch von Inhalten (Ottoni et al., 2014)\nBeispiel “Auswirkungen”:\n\n\nB. die Untersuchung der Bedürfnisse oder Interessen der Nutzenden\n\n\nBeispiel “Probleme”:\n\nGesonderte Diskussion von Verhalten, die sich auf die Erstellung von Inhalten durch die Nutzer auswirken (“content production bias”) und solche, die sich auf die Verknüpfungsmuster zwischen Nutzern auswirken (“linking bias”).\nDrei weitere häufige Klassen von Verhaltensverzerrungen betreffen die Interaktionen zwischen Nutzern, die Interaktionen zwischen Nutzern und Inhalten und die Verzerrungen, die dazu führen, dass Nutzer in eine Studienpopulation aufgenommen oder von ihr ausgeschlossen werden."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-population-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-population-bias",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: Population Bias",
    "text": "Im Fokus: Population Bias\n\n\n\nDefinition (Population biases). Systematic distortions in demographics or other user characteristics between a population of users represented in a dataset or on a platform and some target population.\n\n\n\nPotentielle Probleme\nUnterschiedliche Demographien (z.B. Geschlechts-, Alters- & Bildungsgruppen) neigen zu unterschiedlichen sozialen Plattformen und nutzen deren Mechanismen unterschiedlich\n\nSignifikant mehr Twitter Nutzer (Mislove et al. ,2011), bei Pinterest tendenziell Frauen überrepräsentiert (Ottoni et al., 2013)\nUnterschiedliche Twitter-Nutzung in DE (Fokus auf Hashtags) und KOR (Fokus auf Konversationen) (Hong et al., 2011).\n\nProxies für Eigenschaften oder demografische Kriterien der Nutzenden sind unterschiedlich verlässlich\n\nAngabe über Alumni-Status einer bestimmten Gruppe von Universitäten als Quelle für Verzerrung bei Meinung junger Hochschulabsolvent*innen zu einem neuen Gesetz (Ruths und Pfeffer, 2014).\n\n\nHäufig ist der Zusammenhang von Untersuchungspopulation (z.B. in Deutschland lebende Erwachsene) zu Zielpopulation (Erwachsene auf Twitter, die angeben, in DE zu leben) unbekannt.\nBeispiel “Auswirkungen”\n\nkann die (Stichproben)-Repräsentativität beeinträchtigen\n➥ ⚠️externe Validität\nbesonders problematisch für Forschungsarbeiten des Typs II\nkann sich auch auf die Leistung von Algorithmen auswirken, die Rückschlüsse auf die Nutzer ziehen\n➥ ⚠️interne Validität (Typ-I & Typ II)\n\nSchätzung der Geo-Location im Stadt-Land-Spektrum (z.B Johnson et al., 2017)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-behavioral-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-behavioral-bias",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: Behavioral Bias",
    "text": "Im Fokus: Behavioral Bias\n\n\n\nSystematic distortions in user behavior across platforms or contexts, or across users represented in different datasets.\n\n\n\nAllgemeine Probleme:\n\nbeeinflussen die Art und Weise, wie Nutzer miteinander interagieren\nAuftreten von Selbstselektion und Reaktionsverzerrungen\n\nResponse Bias\n\nVerzerrungen beim Konsumieren von Inhalten beeinflussen die Art und Weise, wie Nutzer Inhalte finden und mit ihnen interagieren, aufgrund von Unterschieden in ihren Interessen, ihrem Fachwissen und ihrem Informationsbedarfes\n\n\nUnterschiede in Bezug auf Nutzerpersönlichkeiten (Hughes et al., 2012), die Verbreitung von Nachrichten (Lerman und Ghosh, 2010) oder den Austausch von Inhalten (Ottoni et al., 2014)\nAuswirkungen:\n\nErgebnisse einer Studie von der gewählten Plattform oder dem Kontext abhängig\n➤ ⚠️externe Validität\nnur Teilweise von population bias abhängig\nbei (expliziten oder impliziten) Annahmen über die Verhaltensmuster der Nutzenden\n➤ ⚠️potentielle Effekte auf Untersuchung von Typ-I & Typ II (z.B. Untersuchung der Bedürfnisse oder Interessen der Nutzenden)\n\nBeispiel “Probleme”:\n\nGesonderte Diskussion von Verhalten, die sich auf die Erstellung von Inhalten durch die Nutzer auswirken (“content production bias”) und solche, die sich auf die Verknüpfungsmuster zwischen Nutzern auswirken (“linking bias”).\nDrei weitere häufige Klassen von Verhaltensverzerrungen betreffen die Interaktionen zwischen Nutzern, die Interaktionen zwischen Nutzern und Inhalten und die Verzerrungen, die dazu führen, dass Nutzer in eine Studienpopulation aufgenommen oder von ihr ausgeschlossen werden."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-behavioral-bias-1",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-behavioral-bias-1",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: Behavioral Bias",
    "text": "Im Fokus: Behavioral Bias\nWie wirken verschiedene Verzerrungen?\n\n\n\nSystematic distortions in user behavior across platforms or contexts, or across users represented in different datasets.\n\n\n\nAllgemeine Probleme:\n\nbeeinflussen die Art und Weise, wie Nutzer miteinander interagieren\nAuftreten von Selbstselektion und Reaktionsverzerrungen\n\nResponse Bias\n\nVerzerrungen beim Konsumieren von Inhalten beeinflussen die Art und Weise, wie Nutzer Inhalte finden und mit ihnen interagieren, aufgrund von Unterschieden in ihren Interessen, ihrem Fachwissen und ihrem Informationsbedarfes\n\n\nUnterschiede in Bezug auf Nutzerpersönlichkeiten (Hughes et al., 2012), die Verbreitung von Nachrichten (Lerman und Ghosh, 2010) oder den Austausch von Inhalten (Ottoni et al., 2014)\nAuswirkungen:\n\nErgebnisse einer Studie von der gewählten Plattform oder dem Kontext abhängig\n➤ ⚠️externe Validität\nnur Teilweise von population bias abhängig\nbei (expliziten oder impliziten) Annahmen über die Verhaltensmuster der Nutzenden\n➤ ⚠️potentielle Effekte auf Untersuchung von Typ-I & Typ II (z.B. Untersuchung der Bedürfnisse oder Interessen der Nutzenden)\n\nBeispiel “Probleme”:\n\nGesonderte Diskussion von Verhalten, die sich auf die Erstellung von Inhalten durch die Nutzer auswirken (“content production bias”) und solche, die sich auf die Verknüpfungsmuster zwischen Nutzern auswirken (“linking bias”).\nDrei weitere häufige Klassen von Verhaltensverzerrungen betreffen die Interaktionen zwischen Nutzern, die Interaktionen zwischen Nutzern und Inhalten und die Verzerrungen, die dazu führen, dass Nutzer in eine Studienpopulation aufgenommen oder von ihr ausgeschlossen werden."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-content-production-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-content-production-biases",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: Content Production Biases",
    "text": "Im Fokus: Content Production Biases\n\n\n\nBehavioral biases that are expressed as lexical, syntactic, semantic, and structural differences in the content generated by users.\n\n\n\nPotentielle Probleme:\nDer Gebrauch der Sprache(n) variiert zwischen und innerhalb von Ländern und Bevölkerungsgruppen\n\nMocanu et al. (2013): saisonale Schwankungen in der sprachlichen Zusammensetzung zwischen verschiedenen Gebiete (Länder, Regionen, Nachbarschaften etc.)\nSprachgebrauchsvariationen je nach Geschlecht, Alter, regionaler Herkunft und politischer Orientierung auf Twitter (Rao et al. (2010)), sowie zwischen ethnischen Gruppen (Blodgett et al., 2016).\n\nKontextbedingte Faktoren (z.B. zwischenmenschliche Beziehungen) beeinflussen die Art und Weise, wie Benutzer sprechen.\n\nBurke et al. (2013) zeigen, wie Mütter und Väter die Sprache unterschiedlich verwenden, wenn sie mit ihren Töchtern und Söhnen sprechen, und umgekehrt.\nAußerdem zeigen Schwartz et al. (2015), dass die zeitliche Ausrichtung von Botschaften (Betonung der Vergangenheit, Gegenwart oder Zukunft) von Faktoren wie Offenheit für neue Erfahrungen, Anzahl der Freunde, Lebenszufriedenheit oder Depression beeinflusst werden kann.\n\nDie Inhalte von bekannten oder “erfahrenen” Nutzern unterscheiden sich von denen der normalen Nutzer.\n\nBhattacharya et al. (2014) fanden beispielsweise heraus, dass “Experten”-Nutzer auf Twitter dazu neigen, hauptsächlich Inhalte zu ihrem Fachgebiet zu erstellen,\nZafar et al. (2015) zeigen, wie die Konzentration der Stichprobe von Inhalten auf “Experten”-Nutzer die resultierende Stichprobe in Richtung vertrauenswürdigerer und hochwertigerer Inhalte verzerrt.\n\nUnterschiedliche Bevölkerungsgruppen haben unterschiedliche Neigungen, über bestimmte Themen zu sprechen.\n\nSo stellten Diaz et al. (2016) bei der Auswahl politischer Tweets während der US-Wahlen 2012 fest, dass die Nutzerpopulation eher auf Washington, DC, ausgerichtet war, während Olteanu et al. (2016) feststellten, dass Afroamerikaner eher den Twitter-Hashtag #BlackLivesMatter (über eine große Bewegung zur Rassengleichheit in den USA) verwendeten.\n\n\nUnterschiede bei nutzergenerierten Inhalten, insbesondere bei Texten, zwischen und innerhalb von demografischen Gruppen"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-linking-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-linking-bias",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: Linking Bias",
    "text": "Im Fokus: Linking Bias\n\n\n\nBehavioral biases that are expressed as differences in the attributes of networks obtained from user connections, interactions or activity.\n\n\n\nAllgemeine Probleme:\nNetzattribute beeinflussen das Verhalten und die Wahrnehmung der Nutzer und umgekehrt.\n\nKıcıman (2010) fand Unterschiede im Verhalten, die mit der Anzahl der Follower der Nutzer korrelieren, während Dong et al. (2016) altersspezifische Distanzen in sozialen Netzwerken (“Grad der Trennung”) feststellten, wobei jüngere Menschen besser vernetzt sind als ältere Generationen.\nDarüber hinaus kann Homophilie - die Tendenz ähnlicher Menschen, miteinander zu interagieren und sich zu verbinden (McPherson et al., 2001) - die Wahrnehmung der vernetzten Nutzer systematisch verzerren, was zu einer Unter- oder Überschätzung der Prävalenz von Nutzereigenschaften innerhalb einer Population führt (Lerman et al., 2016).\nIn sozialen Datensätzen können Verzerrungen bei der Verknüpfung durch die Art der Datenerhebung und -erfassung sowie durch die Definition von Verknüpfungen noch verstärkt werden, was sich auf die beobachteten Eigenschaften einer Vielzahl netzwerkbasierter Nutzerattribute auswirkt, wie z. B. ihre Zentralität innerhalb eines sozialen Netzwerks (Choudhury et al., 2010; González-Bailón et al., 2014b)\n\nVerhaltensbasierte und verbindungsbasierte soziale Verbindungen sind unterschiedlich.\n\nUnterschiedliche Graphenkonstruktionsmethoden können zu unterschiedlichen strukturellen Grapheneigenschaften in den verschiedenen Arten von Netzwerken führen, die aus sozialen Daten konstruiert werden können (Cha et al., 2010).\nWilson et al. (2009) untersuchten die Unterschiede zwischen sozialen Netzwerken, die auf expliziten und impliziten Verbindungen zwischen Nutzern basieren, und zeigten, dass das auf expliziten Verbindungen basierende Netzwerk deutlich dichter war als das auf Nutzerinteraktionen basierende.\n\n\nDie Bildung sozialer Online-Netzwerke hängt auch von Faktoren außerhalb der sozialen Plattformen ab\n\nDie Geografie wurde mit den Eigenschaften sozialer Online-Netzwerke in Verbindung gebracht (Poblete et al., 2011; Scellato et al., 2011), wobei die Wahrscheinlichkeit einer sozialen Verbindung mit der Entfernung zwischen den Nutzern abnimmt, was Auswirkungen auf die Informationsverbreitung hat (Volkovich et al., 2012).\nDarüber hinaus beeinflussen die Art und die Dynamik der Offline-Beziehungen die Neigung der Nutzer, soziale Bindungen einzugehen und online zu interagieren (Subrahmanyam et al., 2008; Gilbert und Karahalios, 2009).\n\n\n\nSozialen Netzwerke, die aus beobachteten Mustern in Datensätzen (re)konstruiert werden, können sich grundlegend von den zugrunde liegenden (Offline-)Netzwerken unterscheiden (Schoenebeck, 2013a)\n➤ ⚠️externe Validität ➤ ⚠️ Typ-II & teilweise Typ-I (Fälle, in denen die Interaktions- oder Verknüpfungsmuster der Nutzer mit der Zeit oder dem Kontext variieren)\nwirken sich beispielsweise auf die Untersuchung der Struktur und Entwicklung sozialer Netzwerke, des sozialen Einflusses und von Phänomenen der Informationsverbreitung aus (Wilson et al., 2009; Cha et al., 2010; Bakshy et al., 2012)\nAuf sozialen Plattformen können sie auch zu systematisch verzerrten Wahrnehmungen über Nutzer oder Inhalte führen (Lerman et al., 2016)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-temporal-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-temporal-biases",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: Temporal Biases",
    "text": "Im Fokus: Temporal Biases\n\n\n\nSystematic distortions across user populations or behaviors over time.\n\n\n\nAllgemeine Probleme:\nBevölkerungsgruppen, Verhaltensweisen und Systeme verändern sich mit der Zeit.\n\nSalganik (2017) beschreibt drei Arten von zeitlichen Schwankungen (die er als Drifts bezeichnet): Populationsdrift, Verhaltensdrift und Systemdrift. Studien sowohl zu Facebook (Lampe et al., 2008) als auch zu Twitter (Liu et al., 2014) haben Hinweise auf solche Schwankungen gefunden.\nSelbst die demografische Zusammensetzung der Nutzer und ihre Beteiligung an einem bestimmten Thema (Guerra et al., 2014; Diaz et al., 2016) oder ihre Interaktionsmuster (Viswanath et al., 2009) sind häufig nicht stationär.\nOft gibt es komplexe Wechselwirkungen zwischen Verhaltenstrends auf einer Plattform (z. B. bei der Verwendung von Sprache) und der Zusammensetzung von Online-Communities und den Lebenszyklen der Nutzer (Danescu-Niculescu-Mizil et al., 2013), was bedeutet, dass Veränderungen manchmal auf mehreren Ebenen stattfinden.\nSo gibt es beispielsweise Schwankungen in Bezug darauf, wann und wie lange sich die Nutzer auf bestimmte Themen konzentrieren, was durch aktuelle Trends, saisonale oder periodische Aktivitäten oder sogar durch Lärm ausgelöst werden kann (Radinsky et al., 2012).\n\nSaisonale und periodische Phänomene.\n\nBei der Analyse geografisch verorteter Tweets fanden Kıcıman et al. (2014) heraus, dass unterschiedliche zeitliche Kontexte (Tag vs. Nacht, Wochentag vs. Wochenende) die Form der abgeleiteten Nachbarschaftsgrenzen verändern.\nGrinberg et al. (2013) fanden heraus, dass Foursquare-Check-Ins für mehrere Kategorien klare wöchentliche Muster aufweisen, während Golder und Macy (2011) Zusammenhänge zwischen der Stimmung von Tweets und Schlafzyklen und Saisonalität beobachteten.\n\nPlötzlich auftretende Phänomene wirken sich auf Populationen, Verhaltensweisen und Plattformen aus.\n\nBeispiele hierfür sind plötzlich auftretende Datenmuster (z. B. ein Anstieg oder Rückgang der Aktivität) aufgrund externer Ereignisse (z. B. ein Erdbeben oder ein Unfall) oder Plattformänderungen.\nMalik und Pfeffer (2016) zeigen, wie die Einführung einer neuen Plattformfunktion zu einem plötzlichen Anstieg der Aktivität führte,\nWährend reale Ereignisse wie Krisensituationen zu kurzzeitigen Aktivitätsspitzen führen können (Crawford und Finn, 2014).\n\nDie zeitliche Granularität kann zu feinkörnig sein, um langfristige Phänomene zu beobachten.\n\nBeispiele sind Phänomene, die relativ konstante Muster aufweisen oder sich über lange Zeiträume entwickeln (Richardson, 2008; Crawford und Finn, 2014). Während soziale Datensätze, die sich auf reale Ereignisse beziehen, oft um Aktivitätsspitzen herum definiert werden, können verschiedene Ereignisse unterschiedliche zeitliche Fingerabdrücke haben, die in solchen Datensätzen möglicherweise nicht erfasst werden (z. B. können Katastrophen längerfristige Auswirkungen haben als Sportereignisse). Die zeitlichen Fingerabdrücke von langwierigen Situationen wie Kriegen können auch durch mehrere Spitzen gekennzeichnet sein. Andere haben festgestellt, dass langfristige Suchprotokolle (im Gegensatz zu kurzfristigen, zeitlich begrenzten Suchinformationen) einen besseren Einblick in die Entwicklung der Interessen und Bedürfnisse der Nutzer oder in die Entwicklung ihrer Erfahrungen bieten (Richardson, 2008; Fourney et al., 2015).\n\nDie zeitliche Granularität kann zu grobkörnig sein, um kurzlebige Phänomene zu beobachten.\n\nDies ist wichtig, wenn es darum geht, kurzzeitige Auswirkungen einer Erfahrung oder kleinere Phänomene auf einer Granularität von z. B. Stunden oder Minuten zu erfassen. Fourney et al. (2015) heben die sich verändernden Bedürfnisse und Erfahrungen schwangerer Nutzerinnen hervor und zeigen, dass die Art und Weise, wie die Zeitleisten der Nutzerinnen ausgerichtet und abgeschnitten werden, die von ihnen erfassten Muster beeinflussen kann. Außerdem können sich einige der in sozialen Daten beobachteten Muster und Korrelationen weiterentwickeln oder nur von kurzer Dauer sein (Starnini et al., 2016).\n\nDatensätze verfallen und verlieren mit der Zeit an Nutzen.\n\nSoziale Daten verfallen mit der Zeit, da Nutzer ihre Inhalte und Konten löschen (Liu et al., 2014; Gillespie, 2015), und die Nutzungsbedingungen der APIs von Plattformen verhindern die Freigabe von Datensätzen, während sie gesammelt werden. Dies macht es oft unpraktisch, Datensätze im Laufe der Zeit vollständig zu rekonstruieren, was erhebliche Lücken hinterlässt (“Swiss Cheese”-Verfall) (Bagdouri und Oard, 2015). Maddock et al. (2015) fanden heraus, dass von den Tweets, die während der Bombenanschläge in Boston 2013 gesammelt wurden, mehr als 13 % später nicht mehr verfügbar waren, während Almuhimedi et al. (2013) feststellten, dass etwa 2,4 % der Tweets, die während einer Woche im Jahr 2013 von etwa 300 Millionen Nutzern gepostet wurden, später gelöscht wurden (wobei etwa die Hälfte der Nutzer mindestens einen Tweet aus diesem Zeitraum löschte).\nEs gibt mehrere Mechanismen, die dazu führen, dass eine Nachricht später nicht mehr verfügbar ist (Liu et al., 2014): Sie wurde vom Nutzer ausdrücklich gelöscht; der Nutzer hat sein Konto auf “geschützt” oder privat gestellt; das Konto des Nutzers wurde von der Plattform gesperrt; oder der Nutzer hat sein gesamtes Konto deaktiviert. Oftmals ist jedoch unklar, warum bestimmte Beiträge entfernt wurden, und es kann schwierig sein, ihre Auswirkungen auf die Analyseergebnisse zu beurteilen.\n\n\nAuswirkunge:\n\n➤ ⚠️ eterne Validität\nBeeinträchtigen Verallgemeinerbarkeit von Beobachtungen im Laufe der Zeit ➤ ⚠️ Typ-I & Typ-II-Forschung problematisch\n\nProbleme:\n\nDie Art und Weise, wie man Datensätze entlang der zeitlichen Achsen aggregiert und abschneidet, wirkt sich darauf aus, welche Art von Mustern beobachtet werden und welche Forschungsfragen beantwortet werden können."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-redundancy",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-redundancy",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: Redundancy",
    "text": "Im Fokus: Redundancy\n\n\n\nSingle data items that appear in the data in multiple copies, which can be identical (duplicates), or almost identical (near duplicates).\n\n\n\nAllgemeine Probleme:\n\nLexikalische (z. B. Duplikate, erneute Tweets, erneut geteilte Inhalte) und semantische (z. B. Beinahe-Duplikate oder dieselbe Bedeutung, aber anders geschrieben) Redundanz macht oft einen erheblichen Teil der Inhalte aus (Baeza-Yates, 2013) und kann sowohl innerhalb als auch zwischen sozialen Datensätzen auftreten. Weitere Quellen für inhaltliche Redundanz sind häufig nicht-menschliche Konten (Abschnitt 4.4), wie z. B. ein und dieselbe Person, die von mehreren Konten oder Plattformen aus postet (z. B. Spam), mehrere Nutzer, die vom selben Konto aus posten (z. B. Konten von Organisationen), oder mehrere Personen, die denselben Inhalt posten oder erneut posten (z. B. das Posten von Zitaten, Memes oder anderen Arten von Inhalten). Dies kann manchmal die Ergebnisse verzerren, aber Redundanz kann auch ein Signal an sich sein, z. B. kann das erneute Posten ein Signal für Wichtigkeit sein.\n\n\nAuswirkunge:\n\nRedundanz kann, wenn sie nicht berücksichtigt wird, sowohl die interne als auch die ökologische/externe Validität der Forschung beeinträchtigen, und zwar sowohl in der Forschung vom Typ I als auch vom Typ II (Abschnitt 2.1). Sie kann sich negativ auf den Nutzen von Instrumenten auswirken (Radlinski et al., 2011) und die Quantifizierung von Phänomenen in den Daten verzerren.\n\nProbleme:\n\nDie Art und Weise, wie man Datensätze entlang der zeitlichen Achsen aggregiert und abschneidet, wirkt sich darauf aus, welche Art von Mustern beobachtet werden und welche Forschungsfragen beantwortet werden können."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#potentielle-probleme-mit-der-datenquelle-oder--herkunft",
    "href": "content/02-dbb-introduction_overview/slides/index.html#potentielle-probleme-mit-der-datenquelle-oder--herkunft",
    "title": "Einführung & Überblick",
    "section": "Potentielle Probleme mit der Datenquelle oder -herkunft",
    "text": "Potentielle Probleme mit der Datenquelle oder -herkunft\n\n\n\n\n\n\n\n\nÜberblick\n\nBiases, die auf das Design und die Möglichkeiten der Plattformen zurückzuführen sind (functional biases)\nVerhaltensnormen, die auf den einzelnen Plattformen bestehen oder sich herausbilden (normative biases).\nFaktoren, die außerhalb der sozialen Plattformen liegen, aber das Nutzerverhalten beeinflussen können (external biases)\nVorhandensein von nicht-individuellen Konten ein (non-individuals)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-functional-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-functional-biases",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: Functional Biases",
    "text": "Im Fokus: Functional Biases\nProbleme mit der Datenquelle oder -herkunft\n\n\n\nBiases that are a result of platform-specific mechanisms or affordances, that is, the possible actions within each system or environment.\n\n\n\nAllgemeine Probleme:\n\nPlattformspezifisches Design und Funktionen prägen das Nutzerverhalten.\nAlgorithmen, die für die Organisation und das Ranking von Inhalten verwendet werden, beeinflussen das Nutzerverhalten.\nDie Präsentation von Inhalten beeinflusst das Nutzerverhalten.\n\n\nHintergrund: - Die Möglichkeiten von Plattformen werden häufig von geschäftlichen Erwägungen und Interessen bestimmt (Van Dijck, 2013a; Salganik, 2017) und von der Politik, den Annahmen und den Interessen derjenigen beeinflusst, die diese Plattformen entwickeln und aufbauen (Van Dijck, 2013a; West et al., 2019). Die Möglichkeiten und Funktionen der Plattformen werden manchmal absichtlich eingeführt, um die Nutzer zu bestimmten Verhaltensweisen zu bewegen (Thaler und Sunstein, 2008). Jede Plattform verwendet einzigartige, proprietäre und oft nicht dokumentierte plattformspezifische Algorithmen, um Inhalte (oder Nutzer) zu organisieren und zu fördern, was sich auf das Engagement und Verhalten der Nutzer auswirkt. Idealerweise sollte die Forschung soziale Datenproben von verschiedenen Plattformen verwenden, aber aufgrund der begrenzten Verfügbarkeit von Daten konzentriert sich ein Großteil der Forschung auf Daten von einigen wenigen Plattformen, vor allem Twitter. Die Verwendung von Twitter als eine Art “Modellorganismus” in der Social-Media-Forschung ist kritisiert worden (Tufekci, 2014).\nAuswirkunge: Funktionale Verzerrungen erschweren die Verallgemeinerung oder Übertragung von Schlussfolgerungen aus Forschungsstudien, da jede Plattform ihre eigenen strukturellen Unterschiede aufweist (Tufekci, 2014), was zu plattformspezifischen Phänomenen führen kann (Ruths und Pfeffer, 2014), die häufig übersehen werden. Die Tatsache, dass die meisten Forschungsarbeiten mit Daten von einer Handvoll Plattformen durchgeführt werden, verschärft dieses Problem noch. Funktionale Verzerrungen sind für die Forschung des Typs II (Abschnitt 2.1) problematisch und beeinträchtigen die externe/ökologische Validität der Sozialdatenforschung; und wenn sie sich z. B. im Laufe der Zeit ändern, können sie auch die Forschung des Typs I beeinträchtigen. Ihr Einfluss auf Verhaltens- und Adoptionsmuster ist jedoch oft subtil und lässt sich nur schwer von anderen Faktoren abgrenzen."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-normative-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-normative-biases",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: Normative Biases",
    "text": "Im Fokus: Normative Biases\nProbleme mit der Datenquelle oder -herkunft\n\n\n\nBiases that are a result of written or unwritten norms and expectations of acceptable patterns of behavior on a given online platform or medium\n\n\n\nAllgemeine Probleme:\n\nNormen werden durch die Einstellungen und Verhaltensweisen von Online-Gemeinschaften geprägt, die kontextabhängig sein können.\nDas Bewusstsein, von anderen beobachtet zu werden, wirkt sich auf das Nutzerverhalten aus.\nSoziale Konformität und “Herdentrieb” finden auf sozialen Plattformen statt, und solche Verhaltensmerkmale prägen das Nutzerverhalten.\n\n\nHintergrund: Plattformen zeichnen sich durch ihre Verhaltensnormen aus, in der Regel in Form von Erwartungen darüber, was eine akzeptable Nutzung darstellt. Diese Normen werden durch Faktoren wie das spezifische Wertversprechen jeder Plattform und die Zusammensetzung ihrer Nutzerbasis geprägt (Boyd und Ellison, 2007; Ruths und Pfeffer, 2014; Newell et al., 2016b). Sukumaran et al. (2011) zeigen beispielsweise, wie die Nutzer von Nachrichten-Websites sich beim Verfassen von Kommentaren an informelle, von anderen gesetzte Standards halten, wie Länge oder Anzahl der behandelten Aspekte.\nAuswirkunge: Wie funktionale Verzerrungen wirken sich auch normative Verzerrungen auf die ökologische/externe Validität der Forschung aus und sind für die Typ-II-Forschung (Abschnitt 2.1) problematisch, da die Forschungsergebnisse von den besonderen Normen der jeweiligen Plattform abhängen können. Sie können auch das Nutzerverhalten verzerren und neigen dazu, mit dem Kontext, der Zeit oder den verschiedenen Untergemeinschaften zu variieren, was ebenfalls die Forschung vom Typ I beeinträchtigt. Das Übersehen der Auswirkungen von Normen kann sich auf jede Sozialdatenanalyse auswirken, die das Nutzerverhalten untersucht oder Annahmen darüber trifft (Tufekci, 2014)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-external-sources-of-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-external-sources-of-bias",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: External Sources of Bias",
    "text": "Im Fokus: External Sources of Bias\nProbleme mit der Datenquelle oder -herkunft\n\n\n\nBiases resulting from factors outside the social platform, including considerations of socioeconomic status, ideological/religious/political leaning, education, personality, culture, social pressure, privacy concerns, and external events.\n\n\n\nAllgemeine Probleme:\n\nKulturelle Elemente und soziale Kontexte spiegeln sich in sozialen Datensätzen wider.\nWie andere Medien enthalten auch die sozialen Medien Fehlinformationen und Desinformationen.\nInhalte zu verschiedenen Themen werden unterschiedlich behandelt.\nEreignisse von großer Tragweite werden in den sozialen Medien widergespiegelt, unabhängig davon, ob sie vorhergesehen wurden oder nicht.\n\n\nHintergrund: Soziale Plattformen sind dem Einfluss einer Vielzahl von externen Faktoren ausgesetzt, die sowohl die demografische Zusammensetzung als auch das Verhalten ihrer Nutzer beeinflussen können.\nAuswirkunge: Externe Verzerrungen sind eine weit gefasste Kategorie, die sich auf die Konstrukt-, interne und externe Validität der Forschung auswirken und sowohl für Typ-I- als auch für Typ-II-Forschung problematisch sein können (Abschnitt 2.1). Im Allgemeinen können sich externe Faktoren auf verschiedene Qualitätsdimensionen sozialer Datensätze auswirken, einschließlich Erfassungsgrad und Repräsentativität, doch können sie auch subtil und leicht zu übersehen sein und die Zuverlässigkeit der aus diesen Datensätzen gezogenen Beobachtungen beeinträchtigen (Silvestri, 2010; Kícíman, 2012; Olteanu et al., 2015).\nProbleme: Wir befassen uns mit verschiedenen Arten von externen Faktoren wie dem sozialen und kulturellen Kontext, externen Ereignissen, semantischen Bereichen und Quellen.a"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-non-individual-accounts",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-non-individual-accounts",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: Non-individual Accounts",
    "text": "Im Fokus: Non-individual Accounts\nProbleme mit der Datenquelle oder -herkunft\n\n\n\nInteractions on social platforms that are produced by organizations or automated agents.\n\n\n\nZwei Typen von nicht-individuellen Konten:\n\nKonten von Organisationen\nBots\n\n\nAuswirkunge: Forscher gehen oft davon aus, dass jedes Konto ein Individuum ist; wenn dies nicht der Fall ist, kann die interne und externe Validität sowohl in der Typ-I- als auch in der Typ-II-Forschung beeinträchtigt werden (Abschnitt 2.1). Beispielsweise können Studien, die diese Datensätze verwenden, um Rückschlüsse auf die Prävalenz unterschiedlicher Meinungen in der Öffentlichkeit zu ziehen, besonders betroffen sein.\nProbleme: Wir befassen uns mit verschiedenen Arten von externen Faktoren wie dem sozialen und kulturellen Kontext, externen Ereignissen, semantischen Bereichen und Quellen.a"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#datenerfassung",
    "href": "content/02-dbb-introduction_overview/slides/index.html#datenerfassung",
    "title": "Einführung & Überblick",
    "section": "Datenerfassung",
    "text": "Datenerfassung\nPotentielle Probleme bei der Datenerhebung\nHintergrund\n\nDie Erfassung sozialer Daten wird häufig von sozialen Plattformen geregelt und hängt von den Daten ab, die sie erfassen und zur Verfügung stellen, von den Grenzen, die sie für den Zugang setzen können, und von der Art und Weise, wie der Zugang gewährt wird.\n\nHäufige Probleme:\n\nViele soziale Plattformen raten von der Datenerfassung durch Dritte ab.\nDer programmatische Zugang ist oft mit Einschränkungen verbunden.\nDie Plattform erfasst möglicherweise nicht alle relevanten Daten.\nDie Plattformen gewähren möglicherweise keinen Zugang zu allen erfassten Daten.\nStichprobenstrategien sind oft undurchsichtig"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#abfrage-von-daten",
    "href": "content/02-dbb-introduction_overview/slides/index.html#abfrage-von-daten",
    "title": "Einführung & Überblick",
    "section": "Abfrage von Daten",
    "text": "Abfrage von Daten\nPotentielle Probleme bei der Datenerhebung\nHintergrund\n\nDer Datenzugriff über APIs umfasst in der Regel eine Abfrage, die eine Reihe von Kriterien für die Auswahl, Einstufung und Rückgabe der angeforderten Daten angibt. Verschiedene APIs können unterschiedliche Arten von Abfragen unterstützen.\n\nHäufige Probleme:\n\nAPIs haben eine begrenzte Aussagekraft in Bezug auf den Informationsbedarf.\nDer Informationsbedarf kann auf unterschiedliche Weise operationalisiert (formuliert) werden.\nDie Wahl der Schlüsselwörter in stichwortbasierten Abfragen prägt die resultierenden Datensätze."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#filterung-von-daten",
    "href": "content/02-dbb-introduction_overview/slides/index.html#filterung-von-daten",
    "title": "Einführung & Überblick",
    "section": "Filterung von Daten",
    "text": "Filterung von Daten\nPotentielle Probleme bei der Datenerhebung\nHintergrund\n\nBei der Datenfilterung werden irrelevante Teile der Daten entfernt, was manchmal während der Datenerfassung aufgrund der begrenzten Ausdruckskraft einer API oder Abfragesprache nicht möglich ist. Der Schritt der Datenfilterung am Ende einer Datenerfassungspipeline wird häufig als Nachfilterung bezeichnet, da er nach der Erfassung oder Abfrage der Daten erfolgt (daher das Präfix “post-”).\n\nHäufige Probleme\n\nIn der Regel impliziert die Entscheidung, bestimmte Daten zu entfernen, die Annahme, dass sie für eine Studie nicht relevant sind. Dies ist hilfreich, wenn die Annahme zutrifft, und schädlich, wenn sie nicht zutrifft.\n\nAusreißer sind manchmal für die Datenanalyse von Bedeutung.\nTextfilterung kann bestimmte Analysen einschränken."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#potentielle-probleme-bei-der-datenverarbeitung",
    "href": "content/02-dbb-introduction_overview/slides/index.html#potentielle-probleme-bei-der-datenverarbeitung",
    "title": "Einführung & Überblick",
    "section": "Potentielle Probleme bei der Datenverarbeitung",
    "text": "Potentielle Probleme bei der Datenverarbeitung\nAnnahmen bei der Gestaltung von Datenverarbeitungspipelines können sich auf Datensätze auswirken und deren Inhalt, Struktur, Organisation oder Darstellung verändern (Barocas und Selbst, 2016; Poirier, 2018). Verzerrungen und Fehler können durch Vorgänge wie Bereinigung (Abschnitt 6.1), Anreicherung durch manuelle oder automatische Verfahren (Abschnitt 6.2) und Aggregation (Abschnitt 6.3) eingeführt werden.\nAuswirkungen: Schlechte Entscheidungen bei der Datenverarbeitung gefährden vor allem die interne Validität der Forschung, können aber auch die ökologische/externe Validität beeinträchtigen. So ist beispielsweise Crowdsourcing einer der vorherrschenden Mechanismen zur Anreicherung von Daten und zur Erstellung von “Ground Truth”- oder “Goldstandard”-Datensätzen, die dann für eine Vielzahl von Modellierungs- oder Lernaufgaben verwendet werden können. Es hat sich jedoch gezeigt, dass einige “Goldstandards” je nachdem, wer die Annotation vornimmt, variieren, was sich wiederum auf die Leistung der Algorithmen auswirken kann (Sen et al., 2015). Folglich können sie sowohl die Forschung des Typs I als auch des Typs II beeinträchtigen (Abschnitt 2.1)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#probleme-bei-der-datenbereinigung",
    "href": "content/02-dbb-introduction_overview/slides/index.html#probleme-bei-der-datenbereinigung",
    "title": "Einführung & Überblick",
    "section": "Probleme bei der Datenbereinigung",
    "text": "Probleme bei der Datenbereinigung\nPotentielle Probleme bei der Datenverarbeitung\nHintergrund\n\nMit der Datenbereinigung soll sichergestellt werden, dass die Daten das untersuchte Phänomen getreu wiedergeben (z. B. um die Konstruktvalidität zu gewährleisten). Sie zielt darauf ab, Fehler und Inkonsistenzen in den Daten zu erkennen und zu korrigieren, bis die “bereinigten” Daten Konsistenz- oder Validierungstests bestehen (Rahm und Do, 2000). Datenbereinigung ist nicht gleichbedeutend mit Datenfilterung: Während die Datenbereinigung die Entfernung bestimmter Datenelemente beinhalten kann, kann sie auch die Normalisierung von Daten durch Korrektur oder Ersetzung unvollständiger oder fehlender Werte umfassen.\n\nHäufige Probleme\n\nDatenbereinigungsverfahren können die Überzeugungen des Wissenschaftlers über ein Phänomen und das System im Allgemeinen in den Datensatz einbetten. Während gut begründete Änderungen die Validität eines Datensatzes verbessern, kann die Datenbereinigung zum Beispiel auch zu falschen oder irreführenden Datenmustern führen:\n\nDie Wahl der Datendarstellung und der Standardwerte kann zu Verzerrungen führen.\nDie Normalisierung von Text oder geografischen Referenzen kann zu Verzerrungen führen."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#probleme-bei-der-datenanreicherung",
    "href": "content/02-dbb-introduction_overview/slides/index.html#probleme-bei-der-datenanreicherung",
    "title": "Einführung & Überblick",
    "section": "Probleme bei der Datenanreicherung",
    "text": "Probleme bei der Datenanreicherung\nPotentielle Probleme bei der Datenverarbeitung\nHintergrund\n\nDie Datenanreicherung umfasst das Hinzufügen von Anmerkungen zu Datenelementen, die in der Analysephase verwendet werden können. Annotationen können von einfachen kategorischen Etiketten, die jedem Element zugeordnet sind, bis hin zu komplexeren Verarbeitungen wie Part-of-Speech-Tagging oder Dependency Parsing von Text reichen. Sie können entweder durch eine Form der (halb-)automatischen Klassifizierung oder durch menschliche Anmerkungen (z. B. Crowdsourcing, Umfragen) gewonnen werden.\n\nHäufige Probleme\n\nSowohl die manuelle als auch die automatische Annotation sind jedoch fehleranfällig (Cohen und Ruths, 2013) und können sowohl bestehende Verzerrungen verschärfen als auch neue Verzerrungen und Fehler einführen.\n\nDie manuelle Beschriftung kann zu subjektiven und verrauschten Angaben führen.\nDie automatische Beschriftung durch statistische oder maschinelle Lernmethoden führt zu Fehlern."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#probleme-bei-der-datenaggregation",
    "href": "content/02-dbb-introduction_overview/slides/index.html#probleme-bei-der-datenaggregation",
    "title": "Einführung & Überblick",
    "section": "Probleme bei der Datenaggregation",
    "text": "Probleme bei der Datenaggregation\nPotentielle Probleme bei der Datenverarbeitung\nHintergrund\n\nDie Datenaggregation wird durchgeführt, um Daten zu strukturieren, zu organisieren, darzustellen oder umzuwandeln; betrachten Sie Vorverarbeitungsheuristiken, die Daten aggregieren, um sie auf Kosten von Informationsverlusten besser handhabbar zu machen. Die Aggregation kann auch die Hervorhebung bestimmter Muster verringern oder verstärken (Olteanu et al., 2014b; Poirier, 2018).\n\nHäufige Probleme\n\nDie Art und Weise, wie diese Aggregationen vorgenommen werden, oder welche Informationen sie kompromittieren, kann zu unterschiedlichen Schlussfolgerungen führen. Bei der Aggregation nach geografischen Gesichtspunkten kann es tatsächlich zu einer Art “Gerrymandering” kommen, das zu sehr unterschiedlichen Ergebnissen führt.19 Bei der Betrachtung der Gesamthäufigkeit verschiedener Themen unter den Nutzern kann die Aggregation von Inhalten nach Nutzern den Interessen jedes Nutzers das gleiche Gewicht verleihen, während die Aggregation nach Themen den Inhalten hochaktiver Nutzer mehr Gewicht verleihen kann. Wenn die Daten entlang eines bestimmten Attributs organisiert sind (z. B. das Vorhandensein eines Schlüsselworts oder Hashtags) und es mehrere unabhängige Faktoren gibt, die dazu führen, dass das Attribut einen bestimmten Wert annimmt, ist die Analyse von Dateneinträgen mit diesem Wert gleichbedeutend mit einer Konditionierung auf diesen Wert und kann zu falschen Assoziationsmustern zwischen diesen Faktoren führen (Blyth, 1972; Tufekci, 2014)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#methodische-fallstricke-bei-der-analyse-von-daten",
    "href": "content/02-dbb-introduction_overview/slides/index.html#methodische-fallstricke-bei-der-analyse-von-daten",
    "title": "Einführung & Überblick",
    "section": "Methodische Fallstricke bei der Analyse von Daten",
    "text": "Methodische Fallstricke bei der Analyse von Daten\nDie Wahl einer Analysemethode spiegelt in der Regel die Erfahrung und den Blickwinkel eines Forschers wider und kann verschiedene Bedenken hervorrufen, wie z. B. (i) die Verwendung von Daten als Quelle für Hypothesen und nicht als Instrument zu deren Prüfung; (ii) die Anpassung der Forschungsagenda an die Datenverfügbarkeit, was zu Verzerrungen bei der Art der gestellten Fragen führen kann; oder (iii) das Testen mehrerer Hypothesen, bis ein signifikantes, positives Ergebnis gefunden wird. Zu Letzterem gehören Praktiken wie das “Feature Hunting” (Ruths und Pfeffer, 2014): das gierige Testen mehrerer Merkmale für Klassifizierungsaufgaben, bis dasjenige gefunden ist, das die besten Verbesserungen liefert, anstatt diese Merkmale auf der Grundlage von A-priori-Hypothesen auszuwählen.\nImplikationen. Eine wichtige Konsequenz ist die mangelnde Replizierbarkeit. Aufgrund von Unterschieden in der Analysemethodik, Messung und Datenerhebung konnten Liang und Fu (2015) beispielsweise 6 von 10 bekannten Thesen aus Social-Media-Studien nicht wiederholen. Generell kann die interne und externe Validität sowohl der Typ-I- als auch der Typ-II-Forschung durch die Wahl der Methoden beeinflusst werden, die bei der Analyse der Daten angewandt werden, um Nutzerpopulationen und -verhaltensweisen zu charakterisieren (Abschnitte 7.1-7.2), Schlussfolgerungen und Vorhersagen zu treffen (Abschnitt 7.3) und (kausale) Zusammenhänge zu ermitteln (Abschnitt 7.4)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#probleme-bei-der-auswertung-und-interpretation-der-ergebnisse",
    "href": "content/02-dbb-introduction_overview/slides/index.html#probleme-bei-der-auswertung-und-interpretation-der-ergebnisse",
    "title": "Einführung & Überblick",
    "section": "Probleme bei der Auswertung und Interpretation der Ergebnisse",
    "text": "Probleme bei der Auswertung und Interpretation der Ergebnisse\nEine letzte Möglichkeit, Verzerrungen zu berücksichtigen und die Zuverlässigkeit der Ergebnisse zu beurteilen, besteht bei der Bewertung und Interpretation der Leistung eines Instruments oder der Ergebnisse einer Studie. Ein guter Ausgangspunkt ist ein angemessenes Verständnis für die Art der verwendeten Daten. Rost et al. (2013) argumentieren beispielsweise, dass Daten, die explizit von Nutzern in sozialen Medien generiert werden, eher als kommunikativ denn als repräsentativ interpretiert werden sollten, da diese Daten oft eine Aufzeichnung der Kommunikation und nicht eine direkte Darstellung anderer (“realer”) Verhaltensweisen sind, was Fragen zur Konstrukt- und internen Validität aufwirft.\nImplikationen. Die Art und Weise, wie die Evaluation in einer Studie durchgeführt wird, kann zu verzerrten Schlussfolgerungen oder Ergebnissen führen, u. a. aufgrund der Auswahl der Messgrößen (Abschnitt 8.1) oder der Bewertung und Interpretation der Ergebnisse (Abschnitt 8.2), die beide die Konstruktvalidität gefährden können. Solche Probleme können auch Bedenken hinsichtlich der Reproduzierbarkeit einer Studie aufkommen lassen; und wenn Verzerrungen nicht berücksichtigt werden, kann das Versäumnis, potenzielle Einschränkungen ordnungsgemäß anzuerkennen (Abschnitt 8.3), wichtige Validitätsprobleme verbergen, die sowohl Typ-I- als auch Typ-II-Forschung betreffen können."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ethische-erwägungen",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ethische-erwägungen",
    "title": "Einführung & Überblick",
    "section": "Ethische Erwägungen",
    "text": "Ethische Erwägungen\nIn den vorangegangenen Abschnitten ging es um ethische Fragen, die Mittelstadt et al. (2016) als epistemische Bedenken bezeichnen (Abschnitte 3-8), wie etwa die Verwendung von nicht schlüssigen oder fehlgeleiteten Beweisen. Im Gegensatz dazu befasst sich dieser Abschnitt mit normativen Bedenken, die sich hauptsächlich auf die Folgen der Forschung beziehen.\nDie Forschung an Menschen ist in vielen Ländern gesetzlich geregelt, und da die Datenelemente in sozialen Datensätzen Menschen oder Gruppen von Menschen repräsentieren (Varshney, 2015; Diaz, 2016), handelt es sich bei der Forschung an sozialen Daten zweifellos um Forschung an Menschen (Metcalf und Crawford, 2016). Die Tatsache, dass soziale Daten häufig öffentlich zugänglich sind, bedeutet nicht, dass die damit durchgeführte Forschung ethisch vertretbar ist (Zimmer, 2010; Boyd und Crawford, 2012). Infolgedessen haben sowohl Wissenschaftler (Dwork und Mulligan, 2013; Barocas und Selbst, 2016) als auch Journalisten (Hill, 2014; Kirchner, 2015) darauf gedrängt, die Nutzung sozialer Daten stärker auf mögliche ethische Fallstricke hin zu überprüfen, wie etwa die Verletzung der Privatsphäre der Nutzer (Goroff, 2015) oder die Ermöglichung von rassischem, sozioökonomischem oder geschlechtsspezifischem Profiling (Barocas und Selbst, 2016).\nDerartige ethische Fragen wurden durch jüngste Fälle noch deutlicher, darunter das Facebook-Experiment zur Ansteckung (Anfang 2012 durchgeführt und Ende 2014 veröffentlicht), bei dem Forscher die sozialen Feeds von Nutzern so manipulierten, dass sie je nach den geäußerten Emotionen mehr oder weniger von bestimmten Inhalten enthielten (Kramer et al., 2014). Das Experiment wurde als ein Eingriff kritisiert, der den emotionalen Zustand von ahnungslosen Nutzern beeinflusste, die keine Zustimmung zur Teilnahme an der Studie gegeben hatten (Hutton und Henderson, 2015a). Ein weiteres Beispiel ist das Encore-Forschungsprojekt und die Messung der Internetzensur auf der ganzen Welt, bei der Webbrowser angewiesen wurden, zu versuchen, sensible Webinhalte ohne das Wissen oder die Zustimmung der Nutzer herunterzuladen (Burnett und Feamster, 2015), wodurch Menschen in einigen Ländern durch diese Zugriffsversuche möglicherweise gefährdet wurden. In einem beispiellosen Schritt beschloss das Programmkomitee (PC) der SIGCOMM 2015, das Encore-Forschungspapier unter der Bedingung zu akzeptieren, dass am Anfang des Papiers ein deutlicher Hinweis auf die ethischen Bedenken des PC platziert wird (Narayanan und Zevenbergen, 2015).\nIm nächsten Abschnitt (Abschnitt 9.1) wird ein zentrales Spannungsverhältnis in der Forschungsethik digitaler Daten dargestellt. Anschließend wird die Diskussion spezifischer ethischer Probleme in der Sozialdatenforschung im Hinblick auf drei grundlegende Kriterien gegliedert, die im Belmont-Bericht (Ryan et al., 1978), einem grundlegenden Werk zur Forschungsethik, vorgebracht wurden: Autonomie (Abschnitt 9.2), Wohltätigkeit (Abschnitt 9.3) und Gerechtigkeit (Abschnitt 9.4).24 Da unsere Behandlung des Themas absichtlich schematisch ist, kann der interessierte Leser weitere Informationen in verwandten Arbeiten von Grimmelmann (2015), Metcalf und Crawford (2016), Bowser und Tsai (2015), Benton et al. (2017) und Mittelstadt et al."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ein-schmaler-grat-forschungethik-bei-digitalen-daten",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ein-schmaler-grat-forschungethik-bei-digitalen-daten",
    "title": "Einführung & Überblick",
    "section": "Ein schmaler Grat: Forschungethik bei digitalen Daten",
    "text": "Ein schmaler Grat: Forschungethik bei digitalen Daten\nUm ethische Fragen im Zusammenhang mit sozialen Daten zu klären, müssen zwei extreme Sichtweisen miteinander in Einklang gebracht werden: 1) Die Sozialdatenforschung ähnelt klinischen Versuchen und anderen Experimenten am Menschen in ihrer Fähigkeit, Menschen zu schaden, und sollte daher auch als solche reguliert werden; und 2) die Sozialdatenforschung ähnelt der sonstigen Computerforschung, die sich traditionell auf Methoden, Algorithmen und den Aufbau von Systemen konzentriert, mit minimalen direkten Auswirkungen auf Menschen.\nDie Sozialdatenforschung unterscheidet sich von klinischen Versuchen.\nViele der traditionellen Verfahren zur Gewährleistung der Einhaltung ethischer Grundsätze in der Forschung am Menschen wurden im Zusammenhang mit klinischen Versuchen entwickelt, bei denen die Wirkung von Behandlungen an tatsächlichen Patienten getestet wird. Diese können schädliche, manchmal schwerwiegende und unumkehrbare unerwartete Auswirkungen haben. Im Gegensatz dazu sind die Schäden, die die üblichen Arten der Sozialdatenforschung verursachen können, oft anderer Natur, wie z. B. die Verletzung der Privatsphäre oder der Anblick verstörender Bilder. Ein speziell für die Sozialdatenforschung konzipiertes ethisches Genehmigungsverfahren, wie das von Bowser und Tsai (2015) vorgeschlagene, das Fragen enthält, die für soziale Medien spezifisch sind, oder die von Benton et al. (2017) skizzierten Praktiken könnten besser geeignet sein, um zu entscheiden, ob eine Forschungsaktivität stattfinden soll oder nicht und unter welchen Bedingungen.\nEthische Entscheidungen in der Sozialdatenforschung müssen gut überlegt sein.\nEthische Entscheidungen sind unter anderem deshalb schwierig, weil sie oft mehrere Werte betreffen, die miteinander in Konflikt stehen können. So kann die Datenanalyse beispielsweise erforderlich sein, um wichtige Dienste bereitzustellen, und es sollten Lösungen erwogen werden, die ein Gleichgewicht zwischen Datenschutz und Genauigkeit herstellen (Goroff, 2015). In anderen Fällen können Experimente erforderlich sein, um festzustellen, welche Maßnahmen oder Behandlungen angemessen sind - Meyer et al. (2019) stellten jedoch eine Abneigung gegen Experimente fest, wobei die Menschen die allgemeine Umsetzung von nicht getesteten Maßnahmen befürworten, aber randomisierte Experimente ablehnen, um zu testen, welche Maßnahme besser ist. Computerfachleute sind unterschiedlich gut darauf vorbereitet, diese Art von Problemen anzugehen. In der Regel lassen sich ethische Fragen am besten durch sachkundige Überlegungen und Gespräche klären. Aus diesem Grund sind die Genehmigung und Überwachung von Forschungsarbeiten durch institutionelle Prüfungsausschüsse (Institutional Review Boards, IRBs) so wichtig. IRBs legen gemeinsame Standards innerhalb einer Institution fest, bieten Forschern einen Rahmen, um kritisch über die Konsequenzen nachzudenken, und zeigen anderen, dass sorgfältige Entscheidungen für eine Studie getroffen wurden."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#achtung-der-individuellen-autonomie",
    "href": "content/02-dbb-introduction_overview/slides/index.html#achtung-der-individuellen-autonomie",
    "title": "Einführung & Überblick",
    "section": "Achtung der individuellen Autonomie",
    "text": "Achtung der individuellen Autonomie\nDer Respekt vor der Fähigkeit des Einzelnen, autonome Entscheidungen zu treffen, wird in der Forschung häufig durch die informierte Zustimmung zum Ausdruck gebracht. Die Einwilligung nach Aufklärung setzt voraus, dass (i) die Forscher den potenziellen Teilnehmern alle relevanten Informationen offenlegen; (ii) die potenziellen Teilnehmer in der Lage sind, diese Informationen zu bewerten; (iii) die potenziellen Teilnehmer freiwillig entscheiden können, ob sie teilnehmen wollen oder nicht; (iv) die Teilnehmer den Forschern ihre ausdrückliche Erlaubnis erteilen, häufig in schriftlicher Form; und (i) die Teilnehmer die Möglichkeit haben, ihre Einwilligung jederzeit zurückzuziehen.\nHäufige Probleme\n\nDie Zustimmung von Millionen von Nutzern einzuholen ist unpraktisch.\nDas öffentliche Teilen von Inhalten im Internet bedeutet nicht unbedingt eine Zustimmung zur Forschung.\nDie Nutzungsbedingungen sozialer Plattformen stellen möglicherweise keine informierte Zustimmung zur Forschung dar."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#wohltätigkeit-und-nicht-malefizierung",
    "href": "content/02-dbb-introduction_overview/slides/index.html#wohltätigkeit-und-nicht-malefizierung",
    "title": "Einführung & Überblick",
    "section": "Wohltätigkeit und Nicht-Malefizierung",
    "text": "Wohltätigkeit und Nicht-Malefizierung\nEin weiteres wichtiges ethisches Kriterium betrifft die Bewertung von Risiken und Nutzen; insbesondere sollte die Forschung von Nutzen sein und keinen Schaden verursachen (Non-Maleficence). Die Forscher sollten nicht nur über den Nutzen der Forschung nachdenken, sondern auch über die möglichen Arten von Schäden (Barocas et al., 2017), die betroffenen Gruppen und die Art und Weise, wie nachteilige Auswirkungen getestet werden können (Sweeney, 2013).\nHäufige Probleme\n\nDie Forschung zu sozialen Daten wird mit bestimmten Arten von Schäden in Verbindung gebracht, von denen die Verletzung der Privatsphäre vielleicht die offensichtlichste ist (Zimmer, 2010; Crawford und Finn, 2014).\nDaten über Einzelpersonen können ihnen schaden, wenn sie offengelegt werden.\nForschungsergebnisse können verwendet werden, um Schaden anzurichten.\n“Dual-Use”- und Sekundäranalysen sind in der Sozialdatenforschung immer häufiger anzutreffen."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#recht",
    "href": "content/02-dbb-introduction_overview/slides/index.html#recht",
    "title": "Einführung & Überblick",
    "section": "Recht",
    "text": "Recht\nEin Ideal der Gerechtigkeit in der Forschung besteht darin, dass Risiken und Nutzen gerecht verteilt werden, was voraussetzt, dass von Anfang an bekannt ist, wer durch die Forschung belastet wird und wer von den Ergebnissen profitieren wird.\nHäufige Probleme\n\nDie digitale Kluft kann das Forschungsdesign beeinflussen.\nAlgorithmen und Forschungsergebnisse können zu Diskriminierung führen.\nForschungsergebnisse sind möglicherweise nicht allgemein zugänglich.\nNicht alle Interessengruppen werden über die Verwendung von Forschungsergebnissen konsultiert."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#zusammenfassung-und-ausblick",
    "href": "content/02-dbb-introduction_overview/slides/index.html#zusammenfassung-und-ausblick",
    "title": "Einführung & Überblick",
    "section": "Zusammenfassung und Ausblick",
    "text": "Zusammenfassung und Ausblick\n\nEine zunehmende Skepsis gegenüber einfachen Antworten\nVom Aufwerfen von Bedenken über soziale Daten zum Umgang mit ihnen. 4 Empfehlungen:\nUnsere erste Empfehlung besteht darin, den Prozess, mit dem Datensätze und Modelle erstellt werden, detailliert zu dokumentieren und kritisch zu prüfen, wobei auch die von uns beschriebenen Verzerrungen berücksichtigt werden sollten.\nUnsere zweite Empfehlung besteht darin, Studien zu sozialen Daten auf verschiedene Plattformen, Themen, Zeitpunkte und Teilpopulationen auszuweiten, um festzustellen, wie sich die Ergebnisse beispielsweise in verschiedenen kulturellen, demografischen und verhaltensbezogenen Kontexten unterscheiden.Sandvig et al. (2014) argumentieren, dass eine genaue Prüfung auch dann erforderlich ist, wenn ein Social-Software-System die Bedürfnisse der Nutzer zu erfüllen scheint, da es “subtile Muster problematischen Verhaltens” geben kann, die schwer zu erkennen sind. So stellen Kulshrestha et al. (2017) einen Rahmen für die Prüfung von Suchsystemen auf Social-Media-Plattformen vor, indem sie zwischen verschiedenen Quellen von Verzerrungen (z. B. aufgrund von Inhalten oder Ranking-Algorithmen) unterscheiden. Für Audits ist manchmal der Zugang zu proprietären Systemen erforderlich, was eine ausdrückliche Genehmigung für solche Systeme erfordert, die wahrscheinlich verweigert wird, wenn das Ziel darin besteht, ihre Fehler aufzudecken oder zu veröffentlichen. Ein Reverse-Engineering dieser Systeme oder die Nutzung dieser Systeme in einer unvorhergesehenen Weise, um ihre Voreingenommenheit aufzudecken, kann in den USA nach dem Computer Fraud and Abuse Act (CFAA) illegal sein, was von einer Gruppe von Forschern vor Gericht angefochten wurde.\nDaher lautet unsere dritte Empfehlung, Transparenzmechanismen zu schaffen, die es ermöglichen, soziale Software zu überprüfen und Verzerrungen in sozialen Daten an der Quelle zu evaluieren (Abschnitt 4). Darüber hinaus gibt es auch immer mehr Bemühungen, die Grenzen sozialer Daten in Form von Leitlinien, Standards und neuen methodischen Ansätzen zu überwinden. Zu diesen Bemühungen gehört die Anwendung von Techniken aus der Kausalschlussliteratur, die zu robusteren Forschungsergebnissen führen können (Landeiro und Culotta, 2016; Proserpio et al., 2016), oder die Kalibrierung nicht repräsentativer Sozialdatenstichproben (Zagheni und Weber, 2015). Eine weitere Möglichkeit ist die Verwendung standardisierter Bewertungsprotokolle beim Testen neuer Instrumente oder Methoden (Diaz, 2014; Jurgens et al., 2015b).\nUnsere vierte Empfehlung lautet, die Forschung zu diesen Leitlinien, Standards, Methoden und Protokollen auszuweiten und ihre Übernahme zu fördern.\nSchließlich gibt es angesichts der Komplexität der inhärent kontextabhängigen, anwendungs- und bereichsabhängigen Verzerrungen und Probleme in sozialen Daten und Analysepipelines, die in diesem Papier behandelt werden, keine Einheitslösungen - bei der Bewertung und Bekämpfung von Verzerrungen ist Nuancierung entscheidend."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#agenda",
    "href": "content/02-dbb-introduction_overview/slides/index.html#agenda",
    "title": "Einführung & Überblick",
    "section": "Agenda",
    "text": "Agenda\n1. Organisation und Koordination\n2. A short (re-)introduction to DBD\n3. Biases, Methodological Pitfalls, and Ethical Boundaries"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#organisation-und-koordination",
    "href": "content/02-dbb-introduction_overview/slides/index.html#organisation-und-koordination",
    "title": "Einführung & Überblick",
    "section": "1. Organisation und Koordination",
    "text": "1. Organisation und Koordination"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#a-short-re-introduction-to-dbd",
    "href": "content/02-dbb-introduction_overview/slides/index.html#a-short-re-introduction-to-dbd",
    "title": "Einführung & Überblick",
    "section": "2. A short (re-)introduction to DBD",
    "text": "2. A short (re-)introduction to DBD"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#biases-methodological-pitfalls-and-ethical-boundaries",
    "href": "content/02-dbb-introduction_overview/slides/index.html#biases-methodological-pitfalls-and-ethical-boundaries",
    "title": "Einführung & Überblick",
    "section": "3. Biases, Methodological Pitfalls, and Ethical Boundaries",
    "text": "3. Biases, Methodological Pitfalls, and Ethical Boundaries"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#dbd-was-ist-das-eigentlich",
    "href": "content/02-dbb-introduction_overview/slides/index.html#dbd-was-ist-das-eigentlich",
    "title": "Einführung & Überblick",
    "section": "DBD – Was ist das eigentlich?",
    "text": "DBD – Was ist das eigentlich?\nRückblick auf Definition nach Weller (2021)\n\n… fasst eine Vielzahl von möglichen Datenquellen zusammen, die verschiedene Arten von Aktivitäten aufzeichnen (häufig sogar “nur” als Nebenprodukt)\n… können dabei helfen, Meinungen, Verhalten und Merkmale der menschlichen Nutzung digitaler Technologien zu erkennen\n\n\n\n\nIm Kontext dieses Seminars:\n\nSchwerpunkt: Nutzung und Inhalte von soziale Medien\nComputational Social Science [CSS] Verfahren, z.B. zur Erhebung, Verarbeitung, Auswertung und Präsentation"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ohne-css-keine-dbd",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ohne-css-keine-dbd",
    "title": "Einführung & Überblick",
    "section": "Ohne CSS keine DBD",
    "text": "Ohne CSS keine DBD\nZur Bedeutung von Computational Social Science\n\n\n\nDefinition von CSS\n\n\nWe define CSS as the development and application of computational methods to complex, typically large-scale, human (sometimes simulated) behavioral data.” Lazer et al. (2020)\n\n\n\nhilft dabei …\n\nechte digitale Phänomene zu untersuchen\ndigitale Verhaltensdaten zu sammeln und vorzuverarbeiten\nneue Methoden zur Analyse von großen Datensätzen anzuwenden\n\n\nCSS = neues Teilgebiet der Sozialwissenschaften oder neuer “Werkzeugkasten” zur Ergänzung der traditionellen sozialwissenschaftlichen Ansätze"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#und-was-können-wir-damit-untersuchen",
    "href": "content/02-dbb-introduction_overview/slides/index.html#und-was-können-wir-damit-untersuchen",
    "title": "Einführung & Überblick",
    "section": "Und was können wir damit untersuchen?",
    "text": "Und was können wir damit untersuchen?\nKategorisierung verschiedener Verhaltensweisen\n\n\n\n\n\n\n\n\n\nEinschränkungen\n\nKategorisierung ist Momentaufnahme und nicht überschneidungsfrei\nSelektive Nutzung von bestimmten digitalen Geräten\n\n\n\n\n\nKategorien: Digital/Analog individual/social behavior\nEinige inhärent digitale Verhalten (z.B. Web Searches) bei zunehmender Digitalisierung von analogen Verhalten (z.B. Collaborative Work)\nFehlen digitaler Spurendaten in all diesen Quadranten für bestimmte Personen und bestimmte Verhaltensweisen durch selektive Nutzung digitaler Geräte."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#verfügbarkeit-als-pluspunkt",
    "href": "content/02-dbb-introduction_overview/slides/index.html#verfügbarkeit-als-pluspunkt",
    "title": "Einführung & Überblick",
    "section": "Verfügbarkeit als Pluspunkt",
    "text": "Verfügbarkeit als Pluspunkt\nWertvolle Quelle bei sensiblen und unvorhersehbaren Themen\n\nMining von Meinungen aus bestehenden digitalen Kommunikationsströmen (z.B. Inhalte sozialer Medien) als wertvolle Quelle\n\nteilweise zeitnaher als die Erstellung einer Umfrage\nzusätzlicher Nutzen als “Archiv” bei unvorhersehbaren Ereignissen\n\nEinsatz bei Themen bzw. Untersuchungen,\n\nfür die es schwierig ist, Studienteilnehmer*innen zu rekrutieren\nbei denen Beobachtungen vorteilhafter sind als Befragungen"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#mehr-daten-durch-technologischen-fortschritt",
    "href": "content/02-dbb-introduction_overview/slides/index.html#mehr-daten-durch-technologischen-fortschritt",
    "title": "Einführung & Überblick",
    "section": "Mehr Daten durch technologischen Fortschritt",
    "text": "Mehr Daten durch technologischen Fortschritt\nBeispiel: Wachsenden Anzahl eingebauter Smartphone-Sensoren\n\n\nGraphik aus Struminskaya et al. (2020)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ein-plädoyer-für-dbd",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ein-plädoyer-für-dbd",
    "title": "Einführung & Überblick",
    "section": "Ein Plädoyer für DBD",
    "text": "Ein Plädoyer für DBD\nKurzes Zwischenfazit\n\nDigitale Geräte oder Sensoren können sich besser an bestimmte Fakten besser “erinnern” als das menschliche Gedächtnis.\nSensoren sind oft bereits in alltägliche Technik eingebaut Technologie eingebaut und produzieren digitale Verhaltensdaten als ein “Nebenprodukt”.\nUnaufdringliche Erfassung als potentieller Vorteil bzw. Entlastung für Teilnehmer*Innen\nKombination mit Umfragedaten möglich (und bereichernd!)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#wenn-der-vorteil-zum-nachteil-wird",
    "href": "content/02-dbb-introduction_overview/slides/index.html#wenn-der-vorteil-zum-nachteil-wird",
    "title": "Einführung & Überblick",
    "section": "Wenn der Vorteil zum Nachteil wird",
    "text": "Wenn der Vorteil zum Nachteil wird\nAmbivalenz der Unaufdringlichkeit Engel et al. (2021)\n\nUnterscheidung zwischen aufdringlichen (z.B. spezielle Research-App & Befragungen) & unaufdringlichen (z.B. Cookie & APIs) erhobenen Daten\nBewertung und Erwartung an Datensammlung ist abhängig vom Kontext (Amazon vs. Researchgate)\nDilema: Einerseits bereitwillige (oft unwissende) Abgabe der Daten an Konzerne, andererseits häufig Bedenken bezüglich Datenschutz & Privatsphäre bei wissenschaftlichen Studien\n\n\nQ: Gründe für Ablehnung: Nutzenorientierung?"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#we-need-to-talk-about-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#we-need-to-talk-about-biases",
    "title": "Einführung & Überblick",
    "section": "We need to talk about biases",
    "text": "We need to talk about biases\nSpezifische und allgemeine Herausfoderungen\n\n\nHerausforderungen in Bezug auf DBD-Forschung\n\nfehlender Konsens über ein Vokabular oder eine Taxonomie\nhäufig nur impliziter der Bezug\n\n\nGenerelle Herausforderung: bias ist einweit gefasster Begriff\n\nconformation bias und andere kognitive Voreingenommenheiten (Croskerry, 2002)\nsystemische, diskriminierende Ergebnisse (Friedman und Nissenbaum, 1996)\nsystemische Schäden (Barocas et al., 2017)\n\n\n\n\nterm “bias” is used in its more statistical sense to refer to biases in social data and social data analyses\nHerausforderungen in Bezug auf DBD-Forschung\n\nfehlender Konsenz über ein Vokabular oder eine Taxonomie von möglichen biases sowie methodischen Probleme und Fallstricke\nhäufig nur impliziter der Bezug zu potentiellen Quellen und/oder Auswirkungen von Verzerrung\n\nGenerelle Herausforderung\n\n“bias” ist einweit gefasster Begriff ist, der in vielen Disziplinen untersucht wurde und verschiedene Phänomene abbildet\n\nonformation bias und andere kognitive Voreingenommenheiten (Croskerry, 2002)\nsystemische, diskriminierende Ergebnisse (Friedman und Nissenbaum, 1996)\nsystemische Schäden (Barocas et al., 2017)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#know-your-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#know-your-bias",
    "title": "Einführung & Überblick",
    "section": "Know your bias!",
    "text": "Know your bias!\nEin Framework zur Minimierung von Bias (Olteanu et al., 2019)\n\n\nDescription:\n\nSocial data analysis starts with certain goals (section 2.1), such as understanding or influencing phenomena specific to social platforms (Type I) and/or phenomena beyond social platforms (Type II).\nThese goals require that research satisfies certain validity criteria, described earlier (section 2.2).\nThese criteria, in turn, can be compromised by a series of general biases and issues (section 3).\nThese challenges may depend on the characteristics of each data platform (section 4)—which are often not under the control of the researcher—and on the research designs choices made along a data processing pipeline (from sections 5 to 8)–which are often under the researcher control.\n\nPfeile zeigen an, wie sich Komponenten in unserem Rahmenwerk direkt auf andere auswirken\n\nErreichen bestimmter Ziele (Type I & II) bei der Analyse von Sozialdaten (Abschnitt 2.1) voraussetzt, dass die Forschung bestimmte Validitätskriterien erfüllt (Abschnitt 2.2),\ndie durch Verzerrungen und andere Probleme mit Sozialdaten beeinträchtigt werden können (Abschnitt 3)\nDiese Verzerrungen und Probleme können an der Quelle der Daten auftreten (Abschnitt 4), oder sie können im Verlauf der Datenanalyse eingeführt werden (Abschnitte 5-8)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#probleme-durch-unterschiedliche-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#probleme-durch-unterschiedliche-biases",
    "title": "Einführung & Überblick",
    "section": "Probleme durch unterschiedliche Biases",
    "text": "Probleme durch unterschiedliche Biases\nKonsequenzen von verschiedenen Einflüssen auf die Datenqualität\nDatenqualität ist ein vielschichtiges Konzept, typische Elemente sind Genauigkeit, Vollständigkeit, Konsistenz, Aktualität und Zugänglichkeit."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#zu-welchen-problemen-führen-verschiedene-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#zu-welchen-problemen-führen-verschiedene-biases",
    "title": "Einführung & Überblick",
    "section": "Zu welchen Problemen führen verschiedene Biases?",
    "text": "Zu welchen Problemen führen verschiedene Biases?\nEinflüsse von Biases auf Datenqualität\n\n\n\nUm diese Probleme in das umfassendere Konzept der Datenqualität einzuordnen, geben wir zunächst einen kurzen Überblick über bekannte Probleme der Datenqualität.\nDatenqualität ist ein vielschichtiges Konzept, typische Elemente sind Genauigkeit, Vollständigkeit, Konsistenz, Aktualität und Zugänglichkeit."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#datenqualität-data-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#datenqualität-data-bias",
    "title": "Einführung & Überblick",
    "section": "Datenqualität & data bias",
    "text": "Datenqualität & data bias\n\n\n\nDefinition (Data bias). A systematic distortion in the sampled data that compromises its representativeness.\n\n\n\nPotentielle Probleme\n\nSparsity: Häufig Heavy-Tail-Verteilung, was Analyse am “Kopf” (in Bezug auf häufige Elemente oder Phänomene) erleichtert, am “Schwanz” (wie seltene Elemente oder Phänomene) jedoch erschwert (Baeza-Yates, 2013).\nNoise: Unvollständige, beschädigte, unzuverlässige oder unglaubwürdige Inhalte (Naveed et al., 2011; Boyd und Crawford, 2012). ABER: Unterscheidung von “Noise” und “Signal” ist oft unklar und hängt von der Forschungsfrage ab (Salganik, 2017)\nOrganische vs gemessene Daten: Fragen zur Repräsentativität (vs. Stichprobenbeschreibung), Kausalität (vs. Korrelation) und Vorhersagegüte"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#datenqualität-data-bias-folie-1",
    "href": "content/02-dbb-introduction_overview/slides/index.html#datenqualität-data-bias-folie-1",
    "title": "Einführung & Überblick",
    "section": "Datenqualität & data bias (FOLIE 1)",
    "text": "Datenqualität & data bias (FOLIE 1)\n\n\n\nDefinition (Data bias). A systematic distortion in the sampled data that compromises its representativeness.\n\n\n\nPotentielle Probleme\n\nSparsity: Häufig Heavy-Tail-Verteilung, was Analyse am “Kopf” (in Bezug auf häufige Elemente oder Phänomene) erleichtert, am “Schwanz” (wie seltene Elemente oder Phänomene) jedoch erschwert (Baeza-Yates, 2013).\nNoise: Unvollständige, beschädigte, unzuverlässige oder unglaubwürdige Inhalte (Naveed et al., 2011; Boyd und Crawford, 2012). ABER: Unterscheidung von “Noise” und “Signal” ist oft unklar und hängt von der Forschungsfrage ab (Salganik, 2017)\nOrganische vs gemessene Daten: Fragen zur Repräsentativität (vs. Stichprobenbeschreibung), Kausalität (vs. Korrelation) und Vorhersagegüte"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#datenqualität-data-bias-folie-2",
    "href": "content/02-dbb-introduction_overview/slides/index.html#datenqualität-data-bias-folie-2",
    "title": "Einführung & Überblick",
    "section": "Datenqualität & data bias (FOLIE 2)",
    "text": "Datenqualität & data bias (FOLIE 2)\n\n\n\nDefinition (Data bias). A systematic distortion in the sampled data that compromises its representativeness.\n\n\n\nPotentielle Probleme\n\n\nSparsity: Häufig Heavy-Tail-Verteilung, was Analyse am “Kopf” (in Bezug auf häufige Elemente oder Phänomene) erleichtert, am “Schwanz” (wie seltene Elemente oder Phänomene) jedoch erschwert (Baeza-Yates, 2013).\n\nNoise: Unvollständige, beschädigte, unzuverlässige oder unglaubwürdige Inhalte (Naveed et al., 2011; Boyd und Crawford, 2012). ABER: Unterscheidung von “Noise” und “Signal” ist oft unklar und hängt von der Forschungsfrage ab (Salganik, 2017)\n\nOrganische vs gemessene Daten: Fragen zur Repräsentativität (vs. Stichprobenbeschreibung), Kausalität (vs. Korrelation) und Vorhersagegüte"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-behavioral-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-behavioral-biases",
    "title": "Einführung & Überblick",
    "section": "Im Fokus: Behavioral Biases",
    "text": "Im Fokus: Behavioral Biases\n\n\n\nDefinition (Behavioral biases). Systematic distortions in user behavior across platforms or contexts, or across users represented in different datasets.\n\n\n\nPotentielle Probleme\nBeeinflussung der Art und Weise, wie Nutzer*Innen miteinander interagieren\n\nWilson et al. (2009) zeigten, dass die Interaktionsmuster viel spärlicher sind als explizit erstellte soziale Verbindungen (20 % der Verbindungen 80 % der Interaktionen)\nBackstrom et al. (2011): einige Nutzer je nach ihrer Demografie stärker fokussiert sind als andere (z. B. neigen Frauen dazu, sich stärker auf ihre besten Freunde zu konzentrieren), während andere darauf hinweisen, dass die Interaktion der Nutzer von der Art der Beziehung, die sie teilen (Burke et al., 2013), und von gemeinsamen Eigenschaften (d. h. Homophilie) abhängt (McPherson et al., 2001).\n\nAuftreten von Selbstselektion und Reaktionsverzerrungen\n\nGong et al. (2016) zeigen, dass viele Nutzer trotz ihres Interesses an einem bestimmten Thema still bleiben. Dies kann entweder daran liegen, dass ihre Aktivitäten nicht sichtbar sind (z. B. kann ein Datensatz keine Personen enthalten, die Inhalte nur lesen, aber nicht schreiben), oder an einer Selbstzensur (z. B. Nichtteilen oder Löschen eines Beitrags) infolge von Faktoren wie Online-Belästigung, Bedenken hinsichtlich der Privatsphäre oder einer Art sozialer Auswirkungen (Wang et al., 2011; Das und Kramer, 2013; Matias et al., 2015).\nNutzer*Innen eher über extreme oder positive Erfahrungen als über gewöhnliche oder negative Erfahrungen (Kícíman, 2012; Guerra et al., 2014). (response bias)\nZhang et al. (2013) fanden heraus, dass etwa 75 % der Foursquare-Check-ins nicht mit der tatsächlichen Mobilität der Nutzer übereinstimmen, was auf die wettbewerbsorientierten, spielähnlichen Mechanismen von Foursquare zurückzuführen ist (Wang et al., 2016a).\nTasse et al. (2017) zeigen, dass einige Nutzer zwar nicht wissen, dass sie ihre Social-Media-Beiträge mit Geotags versehen, dass aber viele Nutzer Geotags bewusst verwenden, um z. B. zu zeigen, wo sie gewesen sind.\n\n\n\nUnterschiede in Bezug auf Nutzerpersönlichkeiten (Hughes et al., 2012), die Verbreitung von Nachrichten (Lerman und Ghosh, 2010) oder den Austausch von Inhalten (Ottoni et al., 2014)\nAuswirkungen:\n\nErgebnisse einer Studie von der gewählten Plattform oder dem Kontext abhängig\n➤ ⚠️externe Validität\nnur Teilweise von population bias abhängig\nbei (expliziten oder impliziten) Annahmen über die Verhaltensmuster der Nutzenden\n➤ ⚠️potentielle Effekte auf Untersuchung von Typ-I & Typ II (z.B. Untersuchung der Bedürfnisse oder Interessen der Nutzenden)\n\nBeispiel “Probleme”:\n\nGesonderte Diskussion von Verhalten, die sich auf die Erstellung von Inhalten durch die Nutzer auswirken (“content production bias”) und solche, die sich auf die Verknüpfungsmuster zwischen Nutzern auswirken (“linking bias”).\nDrei weitere häufige Klassen von Verhaltensverzerrungen betreffen die Interaktionen zwischen Nutzern, die Interaktionen zwischen Nutzern und Inhalten und die Verzerrungen, die dazu führen, dass Nutzer in eine Studienpopulation aufgenommen oder von ihr ausgeschlossen werden."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#sneak-preview",
    "href": "content/02-dbb-introduction_overview/slides/index.html#sneak-preview",
    "title": "Einführung & Überblick",
    "section": "Sneak Preview",
    "text": "Sneak Preview\nDatenerhebung im Fokus\n\n\n\nUm diese Probleme in das umfassendere Konzept der Datenqualität einzuordnen, geben wir zunächst einen kurzen Überblick über bekannte Probleme der Datenqualität.\nDatenqualität ist ein vielschichtiges Konzept, typische Elemente sind Genauigkeit, Vollständigkeit, Konsistenz, Aktualität und Zugänglichkeit."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ein-schritt-heraus-zum-blick-aufs-gesamte",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ein-schritt-heraus-zum-blick-aufs-gesamte",
    "title": "Einführung & Überblick",
    "section": "Ein Schritt heraus zum Blick aufs Gesamte",
    "text": "Ein Schritt heraus zum Blick aufs Gesamte\nEthische Erwägungen bei DBD-Forschung\nAus öffentlicher Zugänglich- bzw. Verfügbarkeit von Daten leitet sich nicht automatisch ethische Verwertbarkeit ab (Zimmer, 2010; Boyd und Crawford, 2012)\n\nVerletzung der Privatsphäre der Nutzer (Goroff, 2015)\nErmöglichung von rassischem, sozioökonomischem oder geschlechtsspezifischem Profiling (Barocas und Selbst, 2016).\n\nNegative Beispiele\n\nFacebook contagion experiment (2012-2014): Feeds von Nutzer*Innen so manipulierten, dass sie je nach den geäußerten Emotionen mehr oder weniger von bestimmten Inhalten enthielten (Kramer et al., 2014)\nEncore-Forschungsprojekt: Messung der Internetzensur auf der ganzen Welt, bei der Webbrowser angewiesen wurden, zu versuchen, sensible Webinhalte ohne das Wissen oder die Zustimmung der Nutzer herunterzuladen (Burnett und Feamster, 2015)\n\n\nHintergrund:\n\nEthische Fragen bisher epistemische Bedenken (Verwendung von nicht schlüssigen oder fehlgeleiteten Beweisen), jetzt normativ Bedenken (Folgen der Forschung)\n\n\n\nForschung grundsätzlich in vielen Ländern gesetztlich geregelt\n\nNegativbeispiele:\n\nFacebook contagion experiment: Das Experiment wurde als ein Eingriff kritisiert, der den emotionalen Zustand von ahnungslosen Nutzern beeinflusste, die keine Zustimmung zur Teilnahme an der Studie gegeben hatten (Hutton und Henderson, 2015a).\nEncore-Forschngsprojekt: Menschen in einigen Ländern durch diese Zugriffsversuche möglicherweise gefährdet wurden\n\nFolgende Abschnitte:\n\nzentrales Spannungsverhältnis in der Forschungsethik digitaler Daten dargestellt.\nAnschließend wird die Diskussion spezifischer ethischer Probleme in der Sozialdatenforschung im Hinblick auf drei grundlegende Kriterien gegliedert, die im Belmont-Bericht (Ryan et al., 1978), einem grundlegenden Werk zur Forschungsethik, vorgebracht wurden: Autonomie (Abschnitt 9.2), Wohltätigkeit (Abschnitt 9.3) und Gerechtigkeit (Abschnitt 9.4)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ein-schmaler-grat",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ein-schmaler-grat",
    "title": "Einführung & Überblick",
    "section": "Ein schmaler Grat",
    "text": "Ein schmaler Grat\nForschungethik bei digitalen Daten\nKombination zwei extremer Sichtweisen: Betrachtung der Forschung mit sozialen Daten als “klinische” Forschung oder als Computerforschung\n\nDie Sozialdatenforschung unterscheidet sich von klinischen Versuchen.\nEthische Entscheidungen in der Sozialdatenforschung müssen gut überlegt sein, da oft sind mehrere Werte betroffen, die miteinander in Konflikt stehen können\n\n\nHintergrund:\n\nDie Sozialdatenforschung ähnelt klinischen Versuchen und anderen Experimenten am Menschen in ihrer Fähigkeit, Menschen zu schaden, und sollte daher auch als solche reguliert werden\ndie Sozialdatenforschung ähnelt der sonstigen Computerforschung, die sich traditionell auf Methoden, Algorithmen und den Aufbau von Systemen konzentriert, mit minimalen direkten Auswirkungen auf Menschen.\n\nPunkt 2: Schäden, die die üblichen Arten der Sozialdatenforschung ( z. B. die Verletzung der Privatsphäre oder der Anblick verstörender Bilder)verursachen können, oft nicht mit Schäden von klinischen Versuchen gleichzusetzen\nPunkt 3: Datenanalyse beispielsweise erforderlich sein, um wichtige Dienste bereitzustellen, und es sollten Lösungen erwogen werden, die ein Gleichgewicht zwischen Datenschutz und Genauigkeit herstellen (Goroff, 2015)."
  }
]