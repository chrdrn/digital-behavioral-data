[
  {
    "objectID": "content/01-kick-off/01-slides.html",
    "href": "content/01-kick-off/01-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you find the slides for the kick-off session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‚Äòe‚Äô button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#herzlich-willkommen",
    "href": "content/01-kick-off/slides/index.html#herzlich-willkommen",
    "title": "Kick-Off",
    "section": "Herzlich willkommen!",
    "text": "Herzlich willkommen!\nVorstellungsrunde\nChristoph Adrian\n\nseit 2016: Research Assistant / PhD Candidate FAU\nM. Sc. Sozial√∂konomik (FAU)\nB.A. Sozial√∂konomik (FAU)\n\nForschungs- und Lehrschwerpunkte\n\nComputer-assisted and automated (corpus-based) content analysis (with R)\nSocial media research (Twitter)\nPotential influence of media use on attitude changes"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#und-nun-zu-ihnen",
    "href": "content/01-kick-off/slides/index.html#und-nun-zu-ihnen",
    "title": "Kick-Off",
    "section": "Und nun zu Ihnen!",
    "text": "Und nun zu Ihnen!\nVorstellungsrunde\n\nWie hei√üen Sie?\nWas und wo haben Sie im Bachelor studiert?\nWas studieren Sie aktuell?\nWelches soziale Netzwerk/Medium nutzen Sie aktuell am h√§ufigsten?\nWelche Erwartungen haben Sie an das Seminar?"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#covid-19-l√§sst-gr√º√üen",
    "href": "content/01-kick-off/slides/index.html#covid-19-l√§sst-gr√º√üen",
    "title": "Kick-Off",
    "section": "COVID-19 l√§sst gr√º√üen",
    "text": "COVID-19 l√§sst gr√º√üen\nCorona-Regeln im Wintersemester\n\n\n\nUm sich und andere zu sch√ºtzen bitte wir Sie herzlich:\nTragen Sie weiterhin eine FFP2- oder OP-Maske!\n\nCOVID-o-mat"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#was-verstehen-sie-unter-digital-behavioral-data",
    "href": "content/01-kick-off/slides/index.html#was-verstehen-sie-unter-digital-behavioral-data",
    "title": "Kick-Off",
    "section": "Was verstehen Sie unter Digital Behavioral Data?",
    "text": "Was verstehen Sie unter Digital Behavioral Data?\nInteraktive Session\n\n\nBitte scannen Sie den QR-Code oder nutzen Sie folgenden Link f√ºr die Teilnahme an einer kurzen Umfrage:\n\nhttps://www.menti.com/alxiy2f2n6oj\nTemporary Voting Code: 49 29 72 5"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#ergebnis",
    "href": "content/01-kick-off/slides/index.html#ergebnis",
    "title": "Kick-Off",
    "section": "Ergebnis",
    "text": "Ergebnis"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#ein-definitionsversuch-von-dbd",
    "href": "content/01-kick-off/slides/index.html#ein-definitionsversuch-von-dbd",
    "title": "Kick-Off",
    "section": "Ein Definitionsversuch von DBD",
    "text": "Ein Definitionsversuch von DBD\nnach Weller (2021)\n\n\n‚Ä¶ fasst eine Vielzahl von m√∂glichen Datenquellen zusammen, die verschiedene Arten von Aktivit√§ten aufzeichnen\n‚Ä¶ k√∂nnen dabei helfen, Meinungen, Verhalten und Merkmale der menschlichen Nutzung digitaler Technologien zu erkennen"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#beispiel-covid-19-mobility-monitor",
    "href": "content/01-kick-off/slides/index.html#beispiel-covid-19-mobility-monitor",
    "title": "Kick-Off",
    "section": "Beispiel: COVID-19 Mobility Monitor",
    "text": "Beispiel: COVID-19 Mobility Monitor"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#beispiel-datenvolumen-einer-internet-minute",
    "href": "content/01-kick-off/slides/index.html#beispiel-datenvolumen-einer-internet-minute",
    "title": "Kick-Off",
    "section": "Beispiel: Datenvolumen einer Internet-Minute",
    "text": "Beispiel: Datenvolumen einer Internet-Minute"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#kernbereiche-von-dbd",
    "href": "content/01-kick-off/slides/index.html#kernbereiche-von-dbd",
    "title": "Kick-Off",
    "section": "Kernbereiche von DBD",
    "text": "Kernbereiche von DBD\nin Anlehnung an Aufteilung der GESIS\n\n\n\n\n\n\n\n\n\n\nUnterschiedliche Heraus- bzw. Anforderungen (je nach Bereich)\nSeminar legt Schwerpunkt auf Datenerhebung, mit kurzen Ausblick auf die anderen Bereiche"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#seminarplan",
    "href": "content/01-kick-off/slides/index.html#seminarplan",
    "title": "Kick-Off",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einf√ºhrung und √úberblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\n\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\n\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\n\n\n\n7\n07.12.2022\nWebscraping: TikTok\n\n\n\n8\n14.12.2022\nESM: m-path\n\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nData Donations\n\n\n\n10\n19.01.2023\nMock-Up-Virtual Environments\n\n\n\n11\n26.01.2023\nOpen Science\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#typische-session",
    "href": "content/01-kick-off/slides/index.html#typische-session",
    "title": "Kick-Off",
    "section": "Typische Session",
    "text": "Typische Session\nErst Pr√§sentation, dann Vertiefung\n\n\nPr√§sentation (ca. 35-45 Min)\n\nUmfasst Ihre Pr√§sentation (inkl. Zeit f√ºr Fragen und Diskussionen)\nOption auf weitere, offenere Diskussion im Plenum\n\n\nGroup Activity (ca. 45 - 55 Min)\n\nkleine Gruppenarbeiten zur Vertiefung\nvariiert abh√§ngig vom Thema der jeweiligen Sitzung\nBeispiele:\n\nAnwendung von Tool/Methode mit anschlie√üender kritschen Diskussion\nErstellung eines einfachen Forschungs- oder Analysedesign"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#different-tools-for-different-tasks",
    "href": "content/01-kick-off/slides/index.html#different-tools-for-different-tasks",
    "title": "Kick-Off",
    "section": "Different tools for different tasks",
    "text": "Different tools for different tasks\nOrganisation der Lehre auf einen Blick\n\nMS Teams: wichtige Ank√ºndigungen, asynchrone Unterhaltungen & Fragen zum Kurs\nStudOn: Kursmaterialien, ggf. Beispieldatens√§tze und Pr√§sentationsaufnahmen\nEmail: pers√∂nliche Fragen an Dozent\nZoom: ggf. f√ºr Sitzung & Sprechstunde"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#what-is-expected",
    "href": "content/01-kick-off/slides/index.html#what-is-expected",
    "title": "Kick-Off",
    "section": "What is expected",
    "text": "What is expected\nLeistungsanforderungen & Pr√ºfungsleistungen\n\nRegelm√§√üige Teilnahme an den Sitzungen (max. 2 unentschuldigtes Fehlen)\nEigenst√§ndige Auf- und Vorbereitung von Pflichtlekt√ºre (‚Äúbestehen‚Äù)\nPr√§sentation (50%)\nSeminarbericht (50%)"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#pr√§sentation",
    "href": "content/01-kick-off/slides/index.html#pr√§sentation",
    "title": "Kick-Off",
    "section": "Pr√§sentation",
    "text": "Pr√§sentation\nUmfang & Inhalt: max. 30 Min.\n\n~ 25 Min.: Zentrale Begriffe, Definitionen und Merkmale der jeweiligen Plattform, Methode und/oder des Tools inklusive kurzem √úberblick √ºber Forschung(-sfeld)\n~ 5 Min: Fragen & Diskussion\nZiel: Vorstellung Tool & Beispiel f√ºr Forschung(-sdesign)\n\nSprechstunde:\n\nEinreichung vollst√§ndiger Pr√§sentationsentwurf mindestens eine Woche + 24 Stunden vor Ihrer Pr√§sentation per E-Mail an christoph.adrian@fau.de\nAusf√ºhrliches Feedback und Tipps zur √úberarbeitung\n\nLiteratur:\n\nSiehe Syllabus & Teams/StudOn (PDFs werden bereitgestellt)"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#ein-kurzer-appell",
    "href": "content/01-kick-off/slides/index.html#ein-kurzer-appell",
    "title": "Kick-Off",
    "section": "Ein kurzer Appell",
    "text": "Ein kurzer Appell\nHinweis zu ‚ÄúAbbruch‚Äù bzw. Nicht-Erscheinen\n\nIhre Anmeldung bedeutet √ºblicherweise eine sehr intensive, aufw√§ndige Betreuung f√ºr uns Lehrende\n√Ñrgerlicherweise gibt es Studierende, die sich anmelden und betreuen lassen, aber dann einfach irgendwann (teilweise sehr kurzfristig) ‚Äúverschwinden‚Äù.\n\n‚ö†Ô∏è Bitte seien Sie sich folgender Dinge bewusst:\n\nDie ‚ÄûPr√ºfung‚Äù bzw. die ‚ÄûPr√ºfungszeit‚Äù bei einem Seminar beginnt mit der Bearbeitungszeit und damit mit der Ausgabe des Themas an die Kandidaten.\n24h Bedenkzeit / R√ºcktrittsrecht"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#please-state-your-preference",
    "href": "content/01-kick-off/slides/index.html#please-state-your-preference",
    "title": "Kick-Off",
    "section": "Please state your preference",
    "text": "Please state your preference\nVergabe der Pr√§sentationsthemen\n\n\nBitte scannen Sie den QR-Code oder nutzen Sie folgenden Link und w√§hlen Sie Ihr favorisiertes Thema aus\n\nhttps://www.menti.com/alj8fncx1zz4\nTemporary Voting Code: 7312 2522"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#lets-spin-the-wheel",
    "href": "content/01-kick-off/slides/index.html#lets-spin-the-wheel",
    "title": "Kick-Off",
    "section": "Let‚Äôs spin the wheel",
    "text": "Let‚Äôs spin the wheel\n\n\n\nSession\nDatum\nThema\n\n\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\n\n\n7\n07.12.2022\nWebscraping: TikTok\n\n\n8\n14.12.2022\nESM: m-path\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n9\n12.01.2023\nData Donations\n\n\n10\n19.01.2023\nMock-Up-Virtual Environments\n\n\n11\n26.01.2023\nOpen Science\n\n\n\n\nIn case of emergency: Wheel of Names"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#lekt√ºre-zwischen-den-sitzungen",
    "href": "content/01-kick-off/slides/index.html#lekt√ºre-zwischen-den-sitzungen",
    "title": "Kick-Off",
    "section": "Lekt√ºre zwischen den Sitzungen",
    "text": "Lekt√ºre zwischen den Sitzungen\nPflichtlekt√ºre\n\npro Woche ein wissenschaftlicher Text als Grundlage f√ºr das Thema (Sitzungen 4 - 11)\n\nEinreichung von Fragen zum Text in Teams (sp√§testens Dienstag Abend)\n\ngilt f√ºr alle Kursteilnehmer*Innen\nmind. 1 Verst√§ndnisfrage zum Text\nmind. 1 Diskussionsfrage zum Text bzw. Thema insgesamt\nWo? -> in w√∂chentlicher Teams-Unterhaltung zur jeweligen Sitzung\nWhy? -> wird in der Sitzung genutzt; bereiten Sie Ihre Frage so vor, dass Sie sie in der Sitzung stellen & erkl√§ren k√∂nnen\n\nLiteratur:\n\nSiehe Syllabus & Teams/StudOn (PDFs werden bereitgestellt)"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#seminararbeit",
    "href": "content/01-kick-off/slides/index.html#seminararbeit",
    "title": "Kick-Off",
    "section": "Seminararbeit",
    "text": "Seminararbeit\nUmfang & Inhalt (ausf√ºhrliche Infos im Syllabus)\n\n3500 - 4000 W√∂rter\nAnfertigung einer Projektskizze f√ºr eine wissenschaftliche Arbeit\nVerwendung von mindestens eine der vorgestellten Methoden/Tools\nSozialwissenschaftlicher Fokus\n\n(vorl√§ufige) Deadline: 03.03.2023; 23:59"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#before-we-meet-again",
    "href": "content/01-kick-off/slides/index.html#before-we-meet-again",
    "title": "Kick-Off",
    "section": "Before we meet again",
    "text": "Before we meet again\nHinweise und offene Fragen\n\nGenerell: ausf√ºhrliche Informationen im Syllabus!\nKursmaterialien: MS Teams vs.¬†StudOn?\nWhy no English?\nIhre Fragen?"
  },
  {
    "objectID": "content/01-kick-off/slides/index.html#literatur",
    "href": "content/01-kick-off/slides/index.html#literatur",
    "title": "Kick-Off",
    "section": "Literatur",
    "text": "Literatur\n\n\nWeller, K. (2021). A short introduction to computational social science and digital behavioral data. https://www.gesis.org/fileadmin/user_upload/MeettheExperts/GESIS_Meettheexperts_Introductioncss.pdf\n\n\n\n\n\nDigital Behavioral Data"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/02-slides.html",
    "href": "content/02-dbb-introduction_overview/02-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you find the slides for the second session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‚Äòe‚Äô button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#seminarplan",
    "href": "content/02-dbb-introduction_overview/slides/index.html#seminarplan",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einf√ºhrung und √úberblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nESM: m-path\nD√∂rr\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nData Donations\n\n\n\n10\n19.01.2023\nMock-Up-Virtual Environments\n\n\n\n11\n26.01.2023\nOpen Science\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian\n\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#kursmaterialien-literatur-etc.",
    "href": "content/02-dbb-introduction_overview/slides/index.html#kursmaterialien-literatur-etc.",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Kursmaterialien, Literatur etc.",
    "text": "Kursmaterialien, Literatur etc.\nKurze Einf√ºhrung in Teams\n\n\n\nSiehe: Webpage zum Kurs\nSiehe: Syllabus"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#vorschlag-alternativer-seminarplan",
    "href": "content/02-dbb-introduction_overview/slides/index.html#vorschlag-alternativer-seminarplan",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Vorschlag: Alternativer Seminarplan",
    "text": "Vorschlag: Alternativer Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einf√ºhrung und √úberblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nExkurs: DBD Analyse mit R\nChristoph Adrian\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nESM: m-path\nD√∂rr\n\n\n10\n19.01.2023\nTBD\nHofmann & Wierzbicki\n\n\n11\n26.01.2023\nPuffer\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian\n\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#dbd-was-ist-das-eigentlich",
    "href": "content/02-dbb-introduction_overview/slides/index.html#dbd-was-ist-das-eigentlich",
    "title": "Einf√ºhrung & √úberblick",
    "section": "DBD ‚Äì Was ist das eigentlich?",
    "text": "DBD ‚Äì Was ist das eigentlich?\nR√ºckblick auf Definition nach Weller (2021)\n\n‚Ä¶ fasst eine Vielzahl von m√∂glichen Datenquellen zusammen, die verschiedene Arten von Aktivit√§ten aufzeichnen (h√§ufig sogar ‚Äúnur‚Äù als Nebenprodukt)\n‚Ä¶ k√∂nnen dabei helfen, Meinungen, Verhalten und Merkmale der menschlichen Nutzung digitaler Technologien zu erkennen\n\n\n\n\nIm Kontext dieses Seminars:\n\nSchwerpunkt: Nutzung und Inhalte von soziale Medien\nComputational Social Science [CSS] Verfahren, z.B. zur Erhebung, Verarbeitung, Auswertung und Pr√§sentation"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ohne-css-keine-dbd",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ohne-css-keine-dbd",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Ohne CSS keine DBD",
    "text": "Ohne CSS keine DBD\nKurzer Exkurs zur Bedeutung von Computational Social Science\n\n\n\nDefinition (Computational Social Science).\nWe define CSS as the development and application of computational methods to complex, typically large-scale, human (sometimes simulated) behavioral data.‚Äù (Lazer et al., 2020)\n\n\n\nhilft dabei ‚Ä¶\n\ngenuine digitale Ph√§nomene zu untersuchen\ndigitale Verhaltensdaten zu sammeln und vorzuverarbeiten\nneue Methoden zur Analyse von gro√üen Datens√§tzen anzuwenden\n\n\nCSS = neues Teilgebiet der Sozialwissenschaften oder neuer ‚ÄúWerkzeugkasten‚Äù zur Erg√§nzung der traditionellen sozialwissenschaftlichen Ans√§tze"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#und-was-k√∂nnen-wir-damit-untersuchen",
    "href": "content/02-dbb-introduction_overview/slides/index.html#und-was-k√∂nnen-wir-damit-untersuchen",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Und was k√∂nnen wir damit untersuchen?",
    "text": "Und was k√∂nnen wir damit untersuchen?\nBeispiele f√ºr & Kategorisierung von untersuchbaren Verhalten & Interaktionen\n\n\n\n\n\nQuelle: Engel et al. (2021)\n\n\n\n\nEinschr√§nkungen\n\nKategorisierung ist Momentaufnahme und nicht √ºberschneidungsfrei\nSelektive Nutzung von bestimmten digitalen Ger√§ten bzw. Funktionen\n\n\n\n\n\nKategorien: Digital/Analog individual/social behavior\nEinige inh√§rent digitale Verhalten (z.B. Web Searches) bei zunehmender Digitalisierung von analogen Verhalten (z.B. Collaborative Work)\nFehlen digitaler Spurendaten in all diesen Quadranten f√ºr bestimmte Personen und bestimmte Verhaltensweisen durch selektive Nutzung digitaler Ger√§te."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#verf√ºgbarkeit-als-pluspunkt",
    "href": "content/02-dbb-introduction_overview/slides/index.html#verf√ºgbarkeit-als-pluspunkt",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Verf√ºgbarkeit als Pluspunkt",
    "text": "Verf√ºgbarkeit als Pluspunkt\nDBD als wertvolle Quelle bei aktuellen, sensiblen & unvorhersehbaren Themen\n\nEinsatz besonders Vorteilhaft bei Themen bzw. Untersuchungen ‚Ä¶\n\n‚Ä¶ f√ºr die es schwierig ist, Studienteilnehmer*innen zu rekrutieren\n‚Ä¶ bei denen Beobachtungen vorteilhafter sind als Befragungen\n\nBeispiel: Streaming und/oder Mining von Inhalten aus bestehenden digitalen Kommunikationsstr√∂men\n\nZeitnaher als die Erstellung einer Umfrage\nZus√§tzlicher Nutzen als Archiv bei unvorhersehbaren Ereignissen\n\n\nüîî ‚Äì> Beispiele?\n\nMeinung zu Corona auf Basis von Tweets\nWell-being auf Basis von Instagram-Bildern & Texten"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#mehr-daten-durch-technologischen-fortschritt",
    "href": "content/02-dbb-introduction_overview/slides/index.html#mehr-daten-durch-technologischen-fortschritt",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Mehr Daten durch technologischen Fortschritt",
    "text": "Mehr Daten durch technologischen Fortschritt\nBeispiel: Wachsenden Anzahl eingebauter Smartphone-Sensoren\n\n\nGraphik aus Struminskaya et al. (2020)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#eine-kleine-lobeshymne-auf-dbd",
    "href": "content/02-dbb-introduction_overview/slides/index.html#eine-kleine-lobeshymne-auf-dbd",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Eine kleine Lobeshymne auf DBD",
    "text": "Eine kleine Lobeshymne auf DBD\nZwischenfazit\n\nDigitale Ger√§te oder Sensoren k√∂nnen sich besser an bestimmte Fakten besser ‚Äúerinnern‚Äù als das menschliche Ged√§chtnis.\nSensoren sind oft bereits in allt√§gliche Technologie eingebaut und produzieren digitale Verhaltensdaten als ein ‚ÄúNebenprodukt‚Äù.\nUnaufdringliche Erfassung als potentieller Vorteil bzw. Entlastung f√ºr Teilnehmer*Innen\nKombination mit Umfragedaten m√∂glich (und bereichernd!)\n\n\n\nAber:\nZur erfolgreichen Nutzung m√ºssen Forschungsziele & verf√ºgbare Daten in Einklang gebracht, m√∂gliche Biases und methodische Probleme ber√ºcksichttigt sowie die Datenqualit√§t evaluiert werden.\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#wenn-der-vorteil-zum-nachteil-wird",
    "href": "content/02-dbb-introduction_overview/slides/index.html#wenn-der-vorteil-zum-nachteil-wird",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Wenn der Vorteil zum Nachteil wird",
    "text": "Wenn der Vorteil zum Nachteil wird\nAmbivalenz der Unaufdringlichkeit (Engel et al., 2021)\n\nUnterscheidung zwischen aufdringlichen (z.B. spezielle Research-App & Befragungen) & unaufdringlichen (z.B. Cookies, Browserplugins & APIs) erhobenen Daten\nBewertung und Erwartung an Datensammlung ist abh√§ngig vom Kontext (z.B. Amazon vs.¬†Researchgate)\n\n\n\nDilema:\nEinerseits bereitwillige (oft unwissende) Abgabe der Daten an Konzerne, andererseits h√§ufig Bedenken bez√ºglich Datenschutz & Privatsph√§re bei wissenschaftlichen Studien\n\n\n\n‚ñ∂Ô∏è | üîî ‚Äì> Gr√ºnde f√ºr Ablehnung: Nutzenorientierung?"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#the-end-of-theory",
    "href": "content/02-dbb-introduction_overview/slides/index.html#the-end-of-theory",
    "title": "Einf√ºhrung & √úberblick",
    "section": "The End of Theory",
    "text": "The End of Theory\n\n\nZur Wichtigkeit von konzipierte Messungen & Designs\n\n\n‚ÄúWho knows why people do what they do? The point is they do it, and we can track and measure it with unprecedented fidelity. With enough data, the numbers speak for themselves.‚Äù (Anderson, 2008)\n\n\n\nWas denken Sie?\n\n\n\n‚ÄúSize alone does not necessarily make the data better‚Äù (boyd & Ellison, 2007)\n\n\n‚ÄúThere are a lot of small data problems that occur in big data [which] don‚Äôt disappear because you‚Äôve got lots of the stuff. They get worse.‚Äù (Harford, 2014)\n\n\n\n‚ñ∂Ô∏è | üîî"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#we-need-to-talk-about-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#we-need-to-talk-about-biases",
    "title": "Einf√ºhrung & √úberblick",
    "section": "We need to talk about biases",
    "text": "We need to talk about biases\nSpezifische und allgemeine Herausforderungen f√ºr die Forschung mit DBD\nHintergrund: (Big) Data ist zunehmend Grundlage f√ºr politische Ma√ünahmen, die Gestaltung von Produkten und Dienstleistungen und f√ºr die automatisierte Entscheidungsfindung\n\nHerausforderungen in Bezug auf DBD-Forschung: fehlender Konsens √ºber ein Vokabular oder eine Taxonomie, h√§ufig nur impliziter Bezug in der Forschung\nGenerelle Herausforderung: bias ist ein weit gefasster & in unterschiedlichen Disziplinen genutzter Begriff\n\n\n\n‚ñ∂Ô∏è\n‚Äúbias‚Äù hier im statistischen Sinne\nPunkt2:\n\nconformation bias und andere kognitive Voreingenommenheiten (Croskerry, 2002)\nsystemische, diskriminierende Ergebnisse (Friedman und Nissenbaum, 1996)\nsystemische Sch√§den (Barocas et al., 2017)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#know-your-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#know-your-bias",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Know your bias!",
    "text": "Know your bias!\nFramework zur Minimierung von Fehlern und Problemen (Olteanu et al., 2019)\n\n\nBeschreibung:\n\nDie Analyse sozialer Daten beginnt mit bestimmten Zielen (Abschnitt 2.1), wie dem Verst√§ndnis oder der Beeinflussung von Ph√§nomenen, die f√ºr soziale Plattformen spezifisch sind (Typ I) und/oder von Ph√§nomenen, die √ºber soziale Plattformen hinausgehen (Typ II).\nDiese Ziele erfordern, dass die Forschung bestimmte Validit√§tskriterien erf√ºllt, die weiter oben beschrieben wurden (Abschnitt 2.2).\nDiese Kriterien k√∂nnen ihrerseits durch eine Reihe von allgemeinen Verzerrungen und Problemen beeintr√§chtigt werden (Abschnitt 3).\nDiese Herausforderungen k√∂nnen von den Merkmalen der einzelnen Datenplattformen (Abschnitt 4) abh√§ngen - die oft nicht unter der Kontrolle des Forschers stehen - und von den Entscheidungen des Forschungsdesigns entlang einer Datenverarbeitungspipeline (Abschnitte 5 bis 8) - die oft unter der Kontrolle des Forschers stehen.\nPfeile zeigen an, wie sich Komponenten in unserem Rahmenwerk direkt auf andere auswirken"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#worauf-wirkt-die-verzerrung",
    "href": "content/02-dbb-introduction_overview/slides/index.html#worauf-wirkt-die-verzerrung",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Worauf wirkt die Verzerrung?",
    "text": "Worauf wirkt die Verzerrung?\nBeispiele f√ºr Forschung von Typ I & II (Olteanu et al., 2019)\n\n\nTyp I: understand/influence phenomena specific to social platforms\n\nDynamik der Verbreitung von ‚ÄúMemes‚Äù\nSteigerung der Attraktivit√§t bzw. besonders Features\nVerbesserung der Suchfunktion oder des Empfehlungssystems\n\nTyp II: understand/influence phenomena beyond social platforms\n\nBeschreibung des Einflusses sozialer Medien auf eine politische Wahl.\nNutzung sozialer Daten zur Verfolgung der Entwicklung ansteckender Krankheiten durch Analyse der von Social-Media-Nutzern online gemeldeten Symptomen"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#zu-welchen-problemen-f√ºhren-verschiedene-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#zu-welchen-problemen-f√ºhren-verschiedene-biases",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Zu welchen Problemen f√ºhren verschiedene Biases?",
    "text": "Zu welchen Problemen f√ºhren verschiedene Biases?\nEinfl√ºsse von Biases auf Datenqualit√§t\n\n\n\nUm diese Probleme in das umfassendere Konzept der Datenqualit√§t einzuordnen, geben wir zun√§chst einen kurzen √úberblick √ºber bekannte Probleme der Datenqualit√§t.\nDatenqualit√§t ist ein vielschichtiges Konzept, typische Elemente sind Genauigkeit, Vollst√§ndigkeit, Konsistenz, Aktualit√§t und Zug√§nglichkeit."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#datenqualit√§t-data-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#datenqualit√§t-data-bias",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Datenqualit√§t & data bias",
    "text": "Datenqualit√§t & data bias\n\n\n\nDefinition (Data bias).\nA systematic distortion in the sampled data that compromises its representativeness.\n\n\n\nPotentielle Probleme\n\nSparsity: H√§ufig Heavy-Tail-Verteilung, was Analyse am ‚ÄúKopf‚Äù (in Bezug auf h√§ufige Elemente oder Ph√§nomene) erleichtert, am ‚ÄúSchwanz‚Äù (wie seltene Elemente oder Ph√§nomene) jedoch erschwert (Baeza-Yates, 2013)\nNoise: Unvollst√§ndige, besch√§digte, unzuverl√§ssige oder unglaubw√ºrdige Inhalte (boyd & Crawford, 2012; Naveed et al., 2011)\n\nUnterscheidung von ‚ÄúNoise‚Äù und ‚ÄúSignal‚Äù ist oft unklar und h√§ngt von der Forschungsfrage ab (Salganik, 2018)\n\nOrganische vs gemessene Daten: Fragen zur Repr√§sentativit√§t (vs.¬†Stichprobenbeschreibung), Kausalit√§t (vs.¬†Korrelation) und Vorhersageg√ºte"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-population-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-population-bias",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Im Fokus: Population Bias",
    "text": "Im Fokus: Population Bias\n\n\n\nDefinition (Population biases).\nSystematic distortions in demographics or other user characteristics between a population of users represented in a dataset or on a platform and some target population.\n\n\n\nPotentielle Probleme\n\nUnterschiedliche Demographien (z.B. Geschlechts-, Alters- & Bildungsgruppen) neigen zu unterschiedlichen sozialen Plattformen1 und nutzen deren Mechanismen2 unterschiedlich\nProxies f√ºr Eigenschaften oder demografische Kriterien der Nutzenden sind unterschiedlich verl√§sslich3\n\n\nH√§ufig ist der Zusammenhang von Untersuchungspopulation (z.B. in Deutschland lebende Erwachsene) zu Zielpopulation (Erwachsene auf Twitter, die angeben, in DE zu leben) unbekannt.\nBeispiel ‚ÄúAuswirkungen‚Äù\n\nkann die (Stichproben)-Repr√§sentativit√§t beeintr√§chtigen\n‚û• ‚ö†Ô∏èexterne Validit√§t\nbesonders problematisch f√ºr Forschungsarbeiten des Typs II\nkann sich auch auf die Leistung von Algorithmen auswirken, die R√ºckschl√ºsse auf die Nutzer ziehen\n‚û• ‚ö†Ô∏èinterne Validit√§t (Typ-I & Typ II)\n\nSch√§tzung der Geo-Location im Stadt-Land-Spektrum (z.B Johnson et al., 2017)\n\n\n\nSignifikant mehr Twitter-Nutzer (Mislove et al.¬†,2011), bei Pinterest tendenziell Nutzerinnen √ºberrepr√§sentiert (Ottoni et al., 2013)Unterschiedliche Twitter-Nutzung in Deutschland (Fokus auf Hashtags) und Korea (Fokus auf Konversationen) (Hong et al., 2011)Angabe √ºber Alumni-Status einer bestimmten Gruppe von Universit√§ten als Quelle f√ºr Verzerrung bei Meinung junger Hochschulabsolvent*Innen zu einem neuen Gesetz (Ruths und Pfeffer, 2014)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-behavioral-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-behavioral-biases",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Im Fokus: Behavioral Biases",
    "text": "Im Fokus: Behavioral Biases\n\n\n\nDefinition (Behavioral biases).\nSystematic distortions in user behavior across platforms or contexts, or across users represented in different datasets.\n\n\n\nPotentielle Probleme\n\nBeeinflussung der Art und Weise, wie Nutzer*Innen miteinander interagieren1\nAuftreten von Selbstselektion2 und Reaktionsverzerrungen34\n\n\nUnterschiede in Bezug auf Nutzerpers√∂nlichkeiten (Hughes et al., 2012), die Verbreitung von Nachrichten (Lerman und Ghosh, 2010) oder den Austausch von Inhalten (Ottoni et al., 2014)\nAuswirkungen:\n\nErgebnisse einer Studie von der gew√§hlten Plattform oder dem Kontext abh√§ngig\n‚û§ ‚ö†Ô∏èexterne Validit√§t\nnur Teilweise von population bias abh√§ngig\nbei (expliziten oder impliziten) Annahmen √ºber die Verhaltensmuster der Nutzenden\n‚û§ ‚ö†Ô∏èpotentielle Effekte auf Untersuchung von Typ-I & Typ II (z.B. Untersuchung der Bed√ºrfnisse oder Interessen der Nutzenden)\n\nBeispiel ‚ÄúProbleme‚Äù:\n\nGesonderte Diskussion von Verhalten, die sich auf die Erstellung von Inhalten durch die Nutzer auswirken (‚Äúcontent production bias‚Äù) und solche, die sich auf die Verkn√ºpfungsmuster zwischen Nutzern auswirken (‚Äúlinking bias‚Äù).\nDrei weitere h√§ufige Klassen von Verhaltensverzerrungen betreffen die Interaktionen zwischen Nutzern, die Interaktionen zwischen Nutzern und Inhalten und die Verzerrungen, die dazu f√ºhren, dass Nutzer in eine Studienpopulation aufgenommen oder von ihr ausgeschlossen werden.\n\n\nInteraktionsmuster viel sp√§rlicher als explizit erstellte soziale Verbindungen (20 % der Verbindungen haben 80 % der Interaktionen) (Wilson et al., 2009)Passivit√§t trotz Interesse an bestimmten Themen (Gong et al., 2016), aber: Aktivit√§t nicht sichtbar oder Selbstzensur (Wang et al., 2011; Das und Kramer, 2013; Matias et al., 2015)?Nutzer*Innen reden eher √ºber extreme oder positive Erfahrungen als √ºber gew√∂hnliche oder negative Erfahrungen (K√≠c√≠man, 2012; Guerra et al., 2014). (response bias)75 % der Foursquare-Check-ins stimmen nicht mit der tats√§chlichen Mobilit√§t der Nutzer √ºbereinstimmen (Zhang et al., 2013)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-content-production-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-content-production-biases",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Im Fokus: Content Production Biases",
    "text": "Im Fokus: Content Production Biases\n\n\n\nDefinition (Content Production Biases)\nBehavioral biases that are expressed as lexical, syntactic, semantic, and structural differences in the content generated by users.\n\n\n\nPotentielle Probleme:\n\nDer Gebrauch der Sprache(n) variiert zwischen und innerhalb von L√§ndern und Bev√∂lkerungsgruppen.1\nKontextbedingte Faktoren (z.B. zwischenmenschliche Beziehungen) beeinflussen die Art und Weise, wie Benutzer sprechen.2\nDie Inhalte von bekannten oder ‚Äúerfahrenen‚Äù Nutzerinnenunterscheiden sich von denen der normalen Nutzer*innen.3\nUnterschiedliche Bev√∂lkerungsgruppen haben unterschiedliche Neigungen, √ºber bestimmte Themen zu sprechen.4\n\n\nUnterschiede bei nutzergenerierten Inhalten, insbesondere bei Texten, zwischen und innerhalb von demografischen Gruppen\nBeispiel 1: Sprachgebrauchsvariationen je nach Geschlecht, Alter, regionaler Herkunft und politischer Orientierung auf Twitter (Rao et al.¬†(2010)), sowie zwischen ethnischen Gruppen (Blodgett et al., 2016).\nBeispiel 2: Au√üerdem zeigen Schwartz et al.¬†(2015), dass die zeitliche Ausrichtung von Botschaften (Betonung der Vergangenheit, Gegenwart oder Zukunft) von Faktoren wie Offenheit f√ºr neue Erfahrungen, Anzahl der Freunde, Lebenszufriedenheit oder Depression beeinflusst werden kann.\nBeispiel 3: Zafar et al.¬†(2015) zeigen, wie die Konzentration der Stichprobe von Inhalten auf ‚ÄúExperten‚Äù-Nutzer die resultierende Stichprobe in Richtung vertrauensw√ºrdigerer und hochwertigerer Inhalte verzerrt.\n\nSaisonale Schwankungen in der sprachlichen Zusammensetzung zwischen verschiedenen Gebiete (L√§nder, Regionen, Nachbarschaften etc.) (Mocanu et al., 2013)M√ºtter und V√§ter verwenden auf Facebook jeweils unterschiedliche Ansprache f√ºr T√∂chter & S√∂hne, und umgekehrt. (Burke et al., 2013)‚ÄúExperten‚Äù-Nutzer auf Twitter neigen dazu, haupts√§chlich Inhalte zu ihrem Fachgebiet zu erstellen (Bhattacharya et al., 2014)Diaz et al.¬†(2016) bei der Auswahl politischer Tweets w√§hrend der US-Wahlen 2012 fest, dass die Nutzerpopulation eher auf Washington, DC, ausgerichtet war, w√§hrend Olteanu et al.¬†(2016) feststellten, dass Afroamerikaner eher den Twitter-Hashtag #BlackLivesMatter (√ºber eine gro√üe Bewegung zur Rassengleichheit in den USA) verwendeten."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-linking-bias",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-linking-bias",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Im Fokus: Linking Bias",
    "text": "Im Fokus: Linking Bias\n\n\n\nDefinition (Linking Bias)\nBehavioral biases that are expressed as differences in the attributes of networks obtained from user connections, interactions or activity.\n\n\n\nPotentielle Probleme:\n\nNetzattribute123 beeinflussen das Verhalten und die Wahrnehmung der Nutzer und umgekehrt\nVerhaltensbasierte und verbindungsbasierte4 soziale Verbindungen sind unterschiedlich.\nDie Bildung sozialer Online-Netzwerke h√§ngt auch von Faktoren56 au√üerhalb der sozialen Plattformen ab\n\n\n\nSozialen Netzwerke, die aus beobachteten Mustern in Datens√§tzen (re)konstruiert werden, k√∂nnen sich grundlegend von den zugrunde liegenden (Offline-)Netzwerken unterscheiden (Schoenebeck, 2013a)\n‚û§ ‚ö†Ô∏èexterne Validit√§t ‚û§ ‚ö†Ô∏è Typ-II & teilweise Typ-I (F√§lle, in denen die Interaktions- oder Verkn√ºpfungsmuster der Nutzer mit der Zeit oder dem Kontext variieren)\nwirken sich beispielsweise auf die Untersuchung der Struktur und Entwicklung sozialer Netzwerke, des sozialen Einflusses und von Ph√§nomenen der Informationsverbreitung aus (Wilson et al., 2009; Cha et al., 2010; Bakshy et al., 2012)\nAuf sozialen Plattformen k√∂nnen sie auch zu systematisch verzerrten Wahrnehmungen √ºber Nutzer oder Inhalte f√ºhren (Lerman et al., 2016).\n\n\nAnzahl der Follower der Nutzer*Innen (Kƒ±cƒ±man, 2010)Altersspezifische Distanzen in sozialen Netzwerken (Dong et al., 2016)Homophilie - die Tendenz √§hnlicher Menschen, miteinander zu interagieren und sich zu verbinden (McPherson et al., 2001)Auf expliziten Verbindungen basierende Netzwerk deutlich dichter war als das auf Nutzerinteraktionen basierende (Wilson et al., 2009)Geografie (Poblete et al., 2011; Scellato et al., 2011)Art und die Dynamik der Offline-Beziehungen die Neigung der Nutzer, soziale Bindungen einzugehen und online zu interagieren (Subrahmanyam et al., 2008; Gilbert und Karahalios, 2009)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-temporal-biases",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-temporal-biases",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Im Fokus: Temporal Biases",
    "text": "Im Fokus: Temporal Biases\n\n\n\nDefinition (Temporal Biases)\nSystematic distortions across user populations or behaviors over time.\n\n\n\nPotentielle Probleme:\n\nBev√∂lkerungsgruppen, Verhaltensweisen1 und Systeme ver√§ndern sich mit der Zeit2.\nSaisonale und periodische Ph√§nomene34.\nPl√∂tzlich auftretende Ph√§nomene (z.B. Anstieg oder R√ºckgang von besteimmten Aktivit√§ten5 oder externe Ereignisse wie z.B. Katastrophen) wirken sich auf Populationen, Verhaltensweisen und Plattformen aus.\nDie zeitliche Granularit√§t kann zu feink√∂rnig sein, um langfristige Ph√§nomene zu beobachten, und zu grobk√∂rnig sein, um kurzlebige Ph√§nomene zu beobachten.\nDatens√§tze verfallen und verlieren mit der Zeit an Nutzen6.\n\n\nAuswirkunge:\n\n‚û§ ‚ö†Ô∏è eterne Validit√§t\nBeeintr√§chtigen Verallgemeinerbarkeit von Beobachtungen im Laufe der Zeit ‚û§ ‚ö†Ô∏è Typ-I & Typ-II-Forschung problematisch\n\nProbleme:\n\nDie Art und Weise, wie man Datens√§tze entlang der zeitlichen Achsen aggregiert und abschneidet, wirkt sich darauf aus, welche Art von Mustern beobachtet werden und welche Forschungsfragen beantwortet werden k√∂nnen.\n\n\nSchwankungen in Bezug darauf, wann und wie lange sich die Nutzer*Innen auf bestimmte Themen konzentrieren, was durch aktuelle Trends, saisonale oder periodische Aktivit√§ten oder sogar durch L√§rm ausgel√∂st werden kann (Radinsky et al., 2012).Drei Arten von zeitlichen Schwankungen: Populationsdrift, Verhaltensdrift und Systemdrift.(Salganik, 2017)Unterschiedliche zeitliche Kontexte (Tag vs.¬†Nacht, Wochentag vs.¬†Wochenende) ver√§ndert die Form der abgeleiteten Nachbarschaftsgrenzen eografisch verorteter Tweets (Kƒ±cƒ±man et al., 2014).Zusammenh√§nge zwischen der Stimmung von Tweets und Schlafzyklen und Saisonalit√§t (Golder und Macy, 2011)Einf√ºhrung einer neuen Plattformfunktion resutliert in pl√∂tzlichen Anstieg der Aktivit√§t (Malik und Pfeffer, 2016)Nutzer ihre Inhalte und Konten l√∂schen (Liu et al., 2014; Gillespie, 2015)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-redundancy",
    "href": "content/02-dbb-introduction_overview/slides/index.html#im-fokus-redundancy",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Im Fokus: Redundancy",
    "text": "Im Fokus: Redundancy\n\n\n\nDefinition (Redundancy)\nSingle data items that appear in the data in multiple copies, which can be identical (duplicates), or almost identical (near duplicates).\n\n\n\nPotentielle Probleme:\n\nLexikalische (z. B. Duplikate, erneute Tweets, erneut geteilte Inhalte) und semantische (z. B. Beinahe-Duplikate oder dieselbe Bedeutung, aber anders geschrieben) Redundanz macht oft einen erheblichen Teil der Inhalte aus und kann sowohl innerhalb als auch zwischen Datens√§tzen auftreten.\nWeitere Quellen f√ºr inhaltliche Redundanz sind h√§ufig nicht-menschliche Konten, wie z.B.\n\nein und dieselbe Person, die von mehreren Konten oder Plattformen aus postet (z. B. Spam),\nmehrere Nutzer, die vom selben Konto aus posten (z. B. Konten von Organisationen),\nmehrere Personen, die denselben Inhalt posten oder erneut posten (z. B. das Posten von Zitaten, Memes oder anderen Arten von Inhalten).\n\n\n\nAuswirkunge:\n\nRedundanz kann, wenn sie nicht ber√ºcksichtigt wird, sowohl die interne als auch die √∂kologische/externe Validit√§t der Forschung beeintr√§chtigen, und zwar sowohl in der Forschung vom Typ I als auch vom Typ II (Abschnitt 2.1). Sie kann sich negativ auf den Nutzen von Instrumenten auswirken (Radlinski et al., 2011) und die Quantifizierung von Ph√§nomenen in den Daten verzerren.\n\nProbleme:\n\nDie Art und Weise, wie man Datens√§tze entlang der zeitlichen Achsen aggregiert und abschneidet, wirkt sich darauf aus, welche Art von Mustern beobachtet werden und welche Forschungsfragen beantwortet werden k√∂nnen.\nDies kann manchmal die Ergebnisse verzerren, aber Redundanz kann auch ein Signal an sich sein, z. B. kann das erneute Posten ein Signal f√ºr Wichtigkeit sein."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#sneak-preview-in-die-n√§chste-sitzung",
    "href": "content/02-dbb-introduction_overview/slides/index.html#sneak-preview-in-die-n√§chste-sitzung",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Sneak Preview in die n√§chste Sitzung",
    "text": "Sneak Preview in die n√§chste Sitzung\nDatenerhebung im Fokus\n\n\n\nUm diese Probleme in das umfassendere Konzept der Datenqualit√§t einzuordnen, geben wir zun√§chst einen kurzen √úberblick √ºber bekannte Probleme der Datenqualit√§t.\nDatenqualit√§t ist ein vielschichtiges Konzept, typische Elemente sind Genauigkeit, Vollst√§ndigkeit, Konsistenz, Aktualit√§t und Zug√§nglichkeit."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#erweiterung-des-blickwinkels",
    "href": "content/02-dbb-introduction_overview/slides/index.html#erweiterung-des-blickwinkels",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Erweiterung des Blickwinkels",
    "text": "Erweiterung des Blickwinkels\nEthische Erw√§gungen bei DBD-Forschung\nAus √∂ffentlicher Zug√§nglich- bzw. Verf√ºgbarkeit von Daten leitet sich nicht automatisch ethische Verwertbarkeit ab (boyd & Crawford, 2012; Zimmer, 2010)\n\nVerletzung der Privatsph√§re der Nutzer (Goroff, 2015)\nErm√∂glichung von rassischem, sozio√∂konomischem oder geschlechtsspezifischem Profiling (Barocas & Selbst, 2016)\n\nNegative Beispiele\n\nFacebook contagion experiment (2012-2014): Feeds von Nutzer*Innen so manipulierten, dass sie je nach den ge√§u√üerten Emotionen mehr oder weniger von bestimmten Inhalten enthielten (Kramer et al., 2014)\nEncore-Forschungsprojekt: Messung der Internetzensur auf der ganzen Welt, bei der Webbrowser angewiesen wurden, zu versuchen, sensible Webinhalte ohne das Wissen oder die Zustimmung der Nutzer herunterzuladen (Burnett & Feamster, 2014)\n\n\nHintergrund:\n\nEthische Fragen bisher epistemische Bedenken (Verwendung von nicht schl√ºssigen oder fehlgeleiteten Beweisen), jetzt normativ Bedenken (Folgen der Forschung)\nForschung grunds√§tzlich in vielen L√§ndern gesetztlich geregelt\n\nNegativbeispiele:\n\nFacebook contagion experiment: Das Experiment wurde als ein Eingriff kritisiert, der den emotionalen Zustand von ahnungslosen Nutzern beeinflusste, die keine Zustimmung zur Teilnahme an der Studie gegeben hatten (Hutton und Henderson, 2015a).\nEncore-Forschngsprojekt: Menschen in einigen L√§ndern durch diese Zugriffsversuche m√∂glicherweise gef√§hrdet wurden\n\nFolgende Abschnitte:\n\nzentrales Spannungsverh√§ltnis in der Forschungsethik digitaler Daten dargestellt.\nAnschlie√üend wird die Diskussion spezifischer ethischer Probleme in der Sozialdatenforschung im Hinblick auf drei grundlegende Kriterien gegliedert, die im Belmont-Bericht (Ryan et al., 1978), einem grundlegenden Werk zur Forschungsethik, vorgebracht wurden: Autonomie (Abschnitt 9.2), Wohlt√§tigkeit (Abschnitt 9.3) und Gerechtigkeit (Abschnitt 9.4)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#ein-schmaler-grat",
    "href": "content/02-dbb-introduction_overview/slides/index.html#ein-schmaler-grat",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Ein schmaler Grat",
    "text": "Ein schmaler Grat\nForschungethik bei digitalen Daten\nHintergrund: Die Herausforderung besteht in der Kombination von zwei extremen Sichtweisen, der Betrachtung der Forschung mit sozialen Daten als ‚Äúklinische‚Äù Forschung oder als Computerforschung\n\nDie Sozialdatenforschung unterscheidet sich von klinischen Versuchen.\nEthische Entscheidungen in der Sozialdatenforschung m√ºssen gut √ºberlegt sein, da oft sind mehrere Werte betroffen, die miteinander in Konflikt stehen k√∂nnen\n\n\nHintergrund:\n\nDie Sozialdatenforschung √§hnelt klinischen Versuchen und anderen Experimenten am Menschen in ihrer F√§higkeit, Menschen zu schaden, und sollte daher auch als solche reguliert werden\ndie Sozialdatenforschung √§hnelt der sonstigen Computerforschung, die sich traditionell auf Methoden, Algorithmen und den Aufbau von Systemen konzentriert, mit minimalen direkten Auswirkungen auf Menschen.\n\nPunkt 2: Sch√§den, die die √ºblichen Arten der Sozialdatenforschung ( z. B. die Verletzung der Privatsph√§re oder der Anblick verst√∂render Bilder)verursachen k√∂nnen, oft nicht mit Sch√§den von klinischen Versuchen gleichzusetzen\nPunkt 3: Datenanalyse beispielsweise erforderlich sein, um wichtige Dienste bereitzustellen, und es sollten L√∂sungen erwogen werden, die ein Gleichgewicht zwischen Datenschutz und Genauigkeit herstellen (Goroff, 2015)."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#achtung-der-individuellen-autonomie",
    "href": "content/02-dbb-introduction_overview/slides/index.html#achtung-der-individuellen-autonomie",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Achtung der individuellen Autonomie",
    "text": "Achtung der individuellen Autonomie\nDiskussion der Informierte Zustimmung als Indikator autonomer Entscheidung\nDie Einwilligung nach Aufkl√§rung setzt voraus, dass\n\ndie Forscher*Innen den potenziellen Teilnehmenden alle relevanten Informationen offenlegen;\ndie potenziellen Teilnehmenden in der Lage sind, diese Informationen zu bewerten;\ndie potenziellen Teilnehmenden freiwillig entscheiden k√∂nnen, ob sie teilnehmen wollen oder nicht;\ndie Teilnehmenden den Forschernden ihre ausdr√ºckliche Erlaubnis erteilen, h√§ufig in schriftlicher Form; und\ndie Teilnehmende die M√∂glichkeit haben, ihre Einwilligung jederzeit zur√ºckzuziehen.\n\n\nPotentielle Probleme\n\nDie Zustimmung von Millionen von Nutzern einzuholen ist unpraktisch.\nDas √∂ffentliche Teilen von Inhalten im Internet bedeutet nicht unbedingt eine Zustimmung zur Forschung1.\nDie Nutzungsbedingungen sozialer Plattformen stellen m√∂glicherweise keine informierte Zustimmung zur Forschung dar.\n\n\nBeispiel 1:\n\nH√§ufig keine Zustimmung bei Studien mit Daten von Millionen von Social-Media-Nutzern (Zimmer, 2010; Hutton und Henderson, 2015a)\nObwohl die Einholung der Zustimmung oft als unpraktisch angesehen wird (Boyd und Crawford, 2012), gibt es Bem√ºhungen, Methoden zur Einholung der Zustimmung zu entwickeln, die den Aufwand f√ºr die Teilnehmer m√∂glichst gering halten (Hutton und Henderson, 2015a).\n\n\nDatenschutzpr√§ferenzen h√§ngen h√§ufig von Lebensumst√§nden ab (Crawford und Finn, 2014)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#wohlt√§tigkeit-und-unsch√§dlichkeit-als-ziel",
    "href": "content/02-dbb-introduction_overview/slides/index.html#wohlt√§tigkeit-und-unsch√§dlichkeit-als-ziel",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Wohlt√§tigkeit und Unsch√§dlichkeit als Ziel",
    "text": "Wohlt√§tigkeit und Unsch√§dlichkeit als Ziel\nBewertung von Risken & Nutzen\nHintergrund: Nicht nur Fokus auf den Nutzen der Forschung, sondern auch auf die m√∂glichen Arten von Sch√§den, die betroffenen Gruppen und die Art und Weise, wie nachteilige Auswirkungen getestet werden k√∂nnen .(Sweeney, 2013)\n\nPotentielle Probleme\n\nDaten √ºber Einzelpersonen k√∂nnen ihnen schaden, wenn sie offengelegt werden12.\nForschungsergebnisse k√∂nnen verwendet werden, um Schaden anzurichten3.\n‚ÄúDual-Use‚Äù- und Sekund√§ranalysen sind in der Sozialdatenforschung immer h√§ufiger anzutreffen4.\n\n\nDie Forschung zu sozialen Daten wird mit bestimmten Arten von Sch√§den in Verbindung gebracht, von denen die Verletzung der Privatsph√§re vielleicht die offensichtlichste ist (Zimmer, 2010; Crawford und Finn, 2014).\nBeispiel 1: Einige prominente Beispiele sind die Datenpanne bei Ashley Madison im Jahr 2015, bei der einer Website, die sich als Dating-Netzwerk f√ºr betr√ºgerische Ehepartner anpreist, Kontoinformationen (einschlie√ülich der vollst√§ndigen Namen der Nutzer) gestohlen und online gestellt wurden (Thomsen, 2015), sowie die j√ºngsten Datenpannen bei Facebook, bei denen Hunderte Millionen von Datens√§tzen mit Kommentaren, Likes, Reaktionen, Kontonamen, App-Passw√∂rtern und mehr √∂ffentlich gemacht wurden.\n\nStalking, Diskriminierung, Erpressung oder Identit√§tsdiebstahl (Gross und Acquisti, 2005).Zu lange Archivierung personenbezogener Daten oder die √∂ffentliche Freigabe schlecht anonymisierter Datens√§tze kann zu Verletzungen der Privatsph√§re f√ºhren, da diese Daten mit anderen Quellen kombiniert werden k√∂nnen, um Erkenntnisse √ºber Personen ohne deren Wissen zu gewinnen (Crawford und Finn, 2014; Goroff, 2015; Horvitz und Mulligan, 2015)Abgesehen von der Tatsache, dass aus sozialen Daten gezogene R√ºckschl√ºsse in vielerlei Hinsicht falsch sein k√∂nnen, wie in dieser Studie hervorgehoben wird, k√∂nnen zu pr√§zise R√ºckschl√ºsse dazu f√ºhren, dass Menschen in immer kleinere Gruppen eingeteilt werden k√∂nnen (Barocas, 2014).Daten, Instrumente und Schlussfolgerungen, die f√ºr einen bestimmten Zweck gewonnen wurden, f√ºr einen anderen Zweck verwendet werden (Hovy und Spruit, 2016; Benton et al., 2017)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#faire-verteilung-von-risiken-nutzen",
    "href": "content/02-dbb-introduction_overview/slides/index.html#faire-verteilung-von-risiken-nutzen",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Faire Verteilung von Risiken & Nutzen",
    "text": "Faire Verteilung von Risiken & Nutzen\nRecht & Gerechtigkeit\nAnnahme: Es ist von Anfang an bekannt, wer durch die Forschung belastet wird und wer von den Ergebnissen profitieren wird.\n\nPotentielle Probleme\n\nDie digitale Kluft kann das Forschungsdesign beeinflussen1 (Stichwort: WEIRD Samples)\nAlgorithmen und Forschungsergebnisse k√∂nnen zu Diskriminierung f√ºhren.\nForschungsergebnisse sind m√∂glicherweise nicht allgemein zug√§nglich2.\nNicht alle Interessengruppen werden √ºber die Verwendung von Forschungsergebnissen konsultiert3.\n\n\nüîî-> Plausibilit√§t der Annahme?\n\nData divide: mangelnde Verf√ºgbarkeit von hochwertigen Daten √ºber Entwicklungsl√§nder und unterprivilegierte Gemeinschaften (Cinnamon und Schuurman, 2013).Idealerweise sollten die Menschen Zugang zu den Forschungsergebnissen und Artefakten haben, die aus der Untersuchung ihrer pers√∂nlichen Daten entstanden sind (Gross und Acquisti, 2005; Crawford und Finn, 2014).In die √úberlegungen dar√ºber, wie, f√ºr wen und wann Forschungsergebnisse umgesetzt werden, sollten diejenigen einbezogen werden, die m√∂glicherweise betroffen sind oder deren Daten verwendet werden (Costanza-Chock, 2018; Design Justice, 2018; Green, 2018)"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#zwei-trends-drei-fragen-vier-empfehlungen",
    "href": "content/02-dbb-introduction_overview/slides/index.html#zwei-trends-drei-fragen-vier-empfehlungen",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Zwei Trends, Drei Fragen, Vier Empfehlungen",
    "text": "Zwei Trends, Drei Fragen, Vier Empfehlungen\nZusammenfassung und Ausblick\nTrend 1: Eine zunehmende Skepsis gegen√ºber einfachen Antworten\n\nWie einstehen die Daten, was enthalten sie tats√§chlich und wie die Arbeitsdatens√§tze zusammengestellt?\nWird deutlich, was was ausgewertet wird?\nWird die Verwendung von vorgefertigten Datens√§tzen und Modellen des maschinellen Lernens hinterfragt?\n\n\nTrend 2: Vom Aufwerfen von Bedenken √ºber soziale Daten zum Umgang mit ihnen. 4 Empfehlungen:\n\nDetaillierte Dokumentation und kritische Pr√ºfung der Datensatz- und Modellerstellung\nDBD-Studien auf verschiedene Plattformen, Themen, Zeitpunkte und Teilpopulationen auszuweiten, um festzustellen, wie sich die Ergebnisse beispielsweise in verschiedenen kulturellen, demografischen und verhaltensbezogenen Kontexten unterscheiden\nTransparenzmechanismen zu schaffen, die es erm√∂glichen, soziale Software zu √ºberpr√ºfen und Verzerrungen in sozialen Daten an der Quelle zu evaluieren\nForschung zu diesen Leitlinien, Standards, Methoden und Protokollen auszuweiten und ihre √úbernahme zu f√∂rdern.\n\nSchlie√ülich gibt es angesichts der Komplexit√§t der inh√§rent kontextabh√§ngigen, anwendungs- und bereichsabh√§ngigen Verzerrungen und Probleme in sozialen Daten und Analysepipelines, die in diesem Papier behandelt werden, keine Einheitsl√∂sungen - bei der Bewertung und Bek√§mpfung von Verzerrungen ist Nuancierung entscheidend."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "href": "content/02-dbb-introduction_overview/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Vielen Dank f√ºr Ihre Fragen!",
    "text": "Vielen Dank f√ºr Ihre Fragen!\n\nWie wird mit ungenauen, verzerrten und/oder unvollst√§ndigen digitalen Verhaltensdaten umgegangen? Was passiert mit ihnen?\n\n\nBereinigen ‚Äì> Validieren ‚Äì> Bereinigen ‚Äì> Validieren ‚Ä¶\n\n\n\nWas versteht man unter der Herausforderung des Privacy-Utility-Trade-Off und wie kann dieses ‚ÄúProblem‚Äù bew√§ltigt werden?\n\n\nLeider kein Zugang zur Quelle, Antwort ‚Äúverschoben‚Äù\n\n\nWe consider a privacy-utility trade-off encountered by users who wish to disclose some information to an analyst, that is correlated with their private data, in the hope of receiving some utility."
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#was-denken-sie-1",
    "href": "content/02-dbb-introduction_overview/slides/index.html#was-denken-sie-1",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Was denken Sie?",
    "text": "Was denken Sie?\n\n\nNutzer sind sich oftmals nicht bewusst, dass ihre Posts/Tweets zu Forschungszwecken verwendet werden.\nSollten im Sinne der Transparenz von Vornherein mehr Informationen zur Verwendung von Daten gegeben werden? W√ºrde dieses tats√§chliche Wissen etwas am Verhalten/Akzeptanz der Datenerhebung der Nutzer √§ndern?\n\n\n\n\nDa die Daten der Nutzer meist ohne Ihr aktives Wissen dar√ºber erhoben werden ist ihr Verhalten sehr nah an der Realit√§t. W√ºrde eine bessere Information und Transparenz √ºber das mitschreiben der Daten Ihr Verhalten beeinflussen und verf√§lschen? Kann dies bereits durch Benachrichtigungen wie ‚ÄúCoockies‚Äù der Fall sein?"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#lets-discuss",
    "href": "content/02-dbb-introduction_overview/slides/index.html#lets-discuss",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Let‚Äôs discuss!",
    "text": "Let‚Äôs discuss!\n\nEs gibt Individuen, die sich nicht im digitalen Raum bewegen und somit in den Daten nicht erfasst werden k√∂nnen. Dadurch k√∂nnen bestimmte Gruppen nicht untersucht werden, was zu verzerrten Daten f√ºhrt. Welche M√∂glichkeiten hat man dieses Problem zu umgehen.\n\n\nWie w√ºrden Sie (methodisch) vorgehen?\n\n\n\nIst es das eine Frage der Methodik oder des Forschungsdesigns?"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#lets-discuss-1",
    "href": "content/02-dbb-introduction_overview/slides/index.html#lets-discuss-1",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Let‚Äôs discuss!",
    "text": "Let‚Äôs discuss!\n\nWenn Unternehmen bei der Verwendung unserer Verhaltensdaten Profit erwirtschaften, sollten wir dann nicht auch etwas daran verdienen?\n\n\nWas denken Sie?\nWie k√∂nnten/sollte ein potentielles Bezahlungssystem aussehen?"
  },
  {
    "objectID": "content/02-dbb-introduction_overview/slides/index.html#literatur",
    "href": "content/02-dbb-introduction_overview/slides/index.html#literatur",
    "title": "Einf√ºhrung & √úberblick",
    "section": "Literatur",
    "text": "Literatur\n\n\nAnderson, C. (2008). The end of theory: The data deluge makes the scientific method obsolete. Wired. https://www.wired.com/2008/06/pb-theory/\n\n\nBaeza-Yates, R. A. (2013). Big data or right data.\n\n\nBarocas, S., & Selbst, A. D. (2016). Big Data‚Äôs Disparate Impact. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.2477899\n\n\nboyd, danah m., & Crawford, K. (2012). CRITICAL QUESTIONS FOR BIG DATA: Provocations for a cultural, technological, and scholarly phenomenon. Information, Communication & Society, 15(5), 662‚Äì679. https://doi.org/10.1080/1369118X.2012.678878\n\n\nboyd, danah m., & Ellison, N. B. (2007). Social Network Sites: Definition, History, and Scholarship. Journal of Computer-Mediated Communication, 13(1), 210‚Äì230. https://doi.org/10.1111/j.1083-6101.2007.00393.x\n\n\nBurnett, S., & Feamster, N. (2014). Encore: Lightweight measurement of web censorship with cross-origin requests. https://doi.org/10.48550/ARXIV.1410.1211\n\n\nEngel, U., Quan-Haase, A., Liu, S. X., & Lyberg, L. (2021). Digital trace data (1st ed., pp. 100‚Äì118). Routledge. https://doi.org/10.4324/9781003024583-8\n\n\nGoroff, D. L. (2015). Balancing privacy versus accuracy in research protocols. Science, 347(6221), 479‚Äì480. https://doi.org/10.1126/science.aaa3483\n\n\nHarford, T. (2014). Big data: A big mistake? Significance, 11(5), 14‚Äì19. https://doi.org/10.1111/j.1740-9713.2014.00778.x\n\n\nKramer, A. D. I., Guillory, J. E., & Hancock, J. T. (2014). Experimental evidence of massive-scale emotional contagion through social networks. Proceedings of the National Academy of Sciences, 111(24), 8788‚Äì8790. https://doi.org/10.1073/pnas.1320040111\n\n\nLazer, D. M. J., Pentland, A., Watts, D. J., Aral, S., Athey, S., Contractor, N., Freelon, D., Gonzalez-Bailon, S., King, G., Margetts, H., Nelson, A., Salganik, M. J., Strohmaier, M., Vespignani, A., & Wagner, C. (2020). Computational social science: Obstacles and opportunities. Science, 369(6507), 1060‚Äì1062. https://doi.org/10.1126/science.aaz8170\n\n\nNaveed, N., Gottron, T., Kunegis, J., & Alhadi, A. C. (2011). the 20th ACM international conference. 183. https://doi.org/10.1145/2063576.2063607\n\n\nOlteanu, A., Castillo, C., Diaz, F., & Kƒ±cƒ±man, E. (2019). Social data: Biases, methodological pitfalls, and ethical boundaries. Frontiers in Big Data, 2, 13. https://doi.org/10.3389/fdata.2019.00013\n\n\nSalganik, M. J. (2018). Bit by bit: Social research in the digital age. Princeton University Press.\n\n\nStruminskaya, B., Lugtig, P., Keusch, F., & H√∂hne, J. K. (2020). Augmenting Surveys With Data From Sensors and Apps: Opportunities and Challenges. Social Science Computer Review, 089443932097995. https://doi.org/10.1177/0894439320979951\n\n\nSweeney, L. (2013). Discrimination in Online Ad Delivery: Google ads, black names and white names, racial discrimination, and click advertising. Queue, 11(3), 10‚Äì29. https://doi.org/10.1145/2460276.2460278\n\n\nWeller, K. (2021). A short introduction to computational social science and digital behavioral data. https://www.gesis.org/fileadmin/user_upload/MeettheExperts/GESIS_Meettheexperts_Introductioncss.pdf\n\n\nZimmer, M. (2010). ‚ÄúBut the data is already public‚Äù: on the ethics of research in Facebook. Ethics and Information Technology, 12(4), 313‚Äì325. https://doi.org/10.1007/s10676-010-9227-5\n\n\n\n\n\nDigital Behavioral Data"
  },
  {
    "objectID": "content/03-dbd-data_collection/03-slides.html",
    "href": "content/03-dbd-data_collection/03-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you find the slides for the third session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‚Äòe‚Äô button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#seminarplan",
    "href": "content/03-dbd-data_collection/slides/index.html#seminarplan",
    "title": "Datenerhebung im Fokus",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einf√ºhrung und √úberblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nESM: m-path\nD√∂rr\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nData Donations\n\n\n\n10\n19.01.2023\nMock-Up-Virtual Environments\n\n\n\n11\n26.01.2023\nOpen Science\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian\n\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#brace-yourself-presentations-are-coming",
    "href": "content/03-dbd-data_collection/slides/index.html#brace-yourself-presentations-are-coming",
    "title": "Datenerhebung im Fokus",
    "section": "Brace yourself, presentations are coming!",
    "text": "Brace yourself, presentations are coming!\nAllgemeine Hinweise rund um die Pr√§sentation\n\nüìë Denken Sie bitte an die Fragen zur Pflichtlekt√ºre!\n\nüï¶ Office Hours bzw. Feedbackgespr√§ch nach dem Kurs\n\nüîç Info zu den Evaluationskriterien\n\n\n‚ùì Fragen\n\n\n‚ñ∂Ô∏è\nKriterien:\n\nPr√§sentationsstil (Roter Faden) ‚Äì> Verst√§ndlichkeit & Konsistenz\nPr√§sentationsfolien (Funktionalit√§t √ºber Design)\nBearbeitung des Arbeitsauftrages\nSelbstst√§ndigkeit & Tiefer der Bearbeitung\nEinleitung, Abschluss & Diskussion\nExtra: Bezug zur Kommunikationswissenschaft"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#die-power-von-social-sensing",
    "href": "content/03-dbd-data_collection/slides/index.html#die-power-von-social-sensing",
    "title": "Datenerhebung im Fokus",
    "section": "Die Power von Social Sensing",
    "text": "Die Power von Social Sensing\nForschungsdesign zur Erhebung digitaler Verhaltensdaten (Fl√∂ck & Sen, 2022)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie Zukunft: Linking"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#mit-fokus-auf-die-platform",
    "href": "content/03-dbd-data_collection/slides/index.html#mit-fokus-auf-die-platform",
    "title": "Datenerhebung im Fokus",
    "section": "Mit Fokus auf die Platform",
    "text": "Mit Fokus auf die Platform\nForschungsdesign zur Erhebung digitaler Verhaltensdaten (Fl√∂ck & Sen, 2022)"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#online-plattformen-pr√§gen-die-gesellschaft",
    "href": "content/03-dbd-data_collection/slides/index.html#online-plattformen-pr√§gen-die-gesellschaft",
    "title": "Datenerhebung im Fokus",
    "section": "Online-Plattformen pr√§gen die Gesellschaft",
    "text": "Online-Plattformen pr√§gen die Gesellschaft\nGr√ºnde f√ºr den Fokus auf Onlineplattformen (Ulloa, 2021)\n\n\nvermitteln & formen menschliche Kommunikation (z.B. Tweet mit 280 Zeichen)\npolitische (Miss-)Nutzung\nGatekeeper f√ºr Informationen (z.B. ‚ÄúDr.Google‚Äù)\nt√§gliche algorithmische Empfehlungen und Werbung: Nachrichten, Produkte, Jobangebote, Bewerbungen, Versicherungen, Hotels, ‚Ä¶"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#aber-welche-und-warum",
    "href": "content/03-dbd-data_collection/slides/index.html#aber-welche-und-warum",
    "title": "Datenerhebung im Fokus",
    "section": "Aber welche? Und warum?",
    "text": "Aber welche? Und warum?\nDenken Sie √ºber Ihre Forschungsfrage nach ‚Ä¶ (Ulloa, 2021)\n\nwelche Population ist vertreten?\nwelche Arten von Interaktionen sind wichtig? (z. B.: eins zu eins oder eins zu vielen)\nWelche Interaktionsregeln sind wichtig?\nBietet die Plattform Zugang zu den ben√∂tigten Daten?\n\nWenn nicht, gibt es alternative Weg um an die Daten zu gelangen?\nWenn ja, ist dies legal/ethisch?\n\n\n\n\nABER:\nBeachten Sie die der Art und Weise, wie Sie die Daten sammeln!\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#possibilities-over-possibilities",
    "href": "content/03-dbd-data_collection/slides/index.html#possibilities-over-possibilities",
    "title": "Datenerhebung im Fokus",
    "section": "Possibilities over possibilities",
    "text": "Possibilities over possibilities\nBeispiele f√ºr verschiedene Datenquellen\n\nAutomatisiertes Browsing\nDaten-Spenden\nDirekter Zugang\nRepositories\n\n\nWeb-APIs\nWeb Scraping / Crawling\n\n\nWeb-Tracking\n‚Ä¶"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#bedeutung-ist-eine-frage-der-disziplin",
    "href": "content/03-dbd-data_collection/slides/index.html#bedeutung-ist-eine-frage-der-disziplin",
    "title": "Datenerhebung im Fokus",
    "section": "Bedeutung ist eine Frage der Disziplin",
    "text": "Bedeutung ist eine Frage der Disziplin\nApplication Programming Interfaces [APIs] im Fokus\n\n\n\nInformatik:\n\nz.B. Routinen, die Maschineninteraktionen strukturieren.\n\n\nSozialwissenschaften:\n\nClient-Server-Interaktionen (Web-APIs), zur Abfrage von Daten aus einem Dienst\n\n\n\n\n\nMerke:\nIn dieser Pr√§sentation bezieht sich der Begriff API in der Regel bzw. wenn nicht anders erw√§hnt auf die sehr enge Teilmenge von (spezifischen) Web-APIs.\n\n\n\n‚ñ∂Ô∏è\nAber selbst innerhalb der Untergruppe der Web-APIs beschr√§nkt sich das sozialwissenschaftliche Interesse in der Regel auf diejenigen APIs, die die Abfrage von Daten aus einem Dienst erm√∂glichen, w√§hrend Web-APIs in der modernen Web-Entwicklung wesentlich breitere Anwendungen haben"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#api-endet-wo-scraping-beginnt",
    "href": "content/03-dbd-data_collection/slides/index.html#api-endet-wo-scraping-beginnt",
    "title": "Datenerhebung im Fokus",
    "section": "API endet, wo Scraping beginnt",
    "text": "API endet, wo Scraping beginnt\nZentrale Unterschiede in der Vorgehensweise\n\nTypische Vorgehen beim Web-Scraping als zweistufiger Prozess:\n\nAbfrage an Server senden, um eine bestimmte Ressource, h√§ufig ein HTML-Dokument, anzufordern\n(H√§ufig sehr aufw√§ndige) Extraktion der relevanten Information aus dem HTML-Dokument\n\n\nAPI im Vergleich:\n\nErster Schritt √§hnlich wie beim Web-Scraping, aber API legen fest, welche Art von Informationen angefordert werden k√∂nnen und wie das Format einer g√ºltigen Abfrage aussieht"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#api-endet-wo-scraping-beginnt-1",
    "href": "content/03-dbd-data_collection/slides/index.html#api-endet-wo-scraping-beginnt-1",
    "title": "Datenerhebung im Fokus",
    "section": "API endet, wo Scraping beginnt",
    "text": "API endet, wo Scraping beginnt\nZentrale Unterschiede in der Vorgehensweise\n\nTypische Vorgehen beim Web-Scraping als zweistufiger Prozess:\n\nAbfrage an Server senden, um eine bestimmte Ressource, h√§ufig ein HTML-Dokument, anzufordern\n(H√§ufig sehr aufw√§ndigere) Extraktion der relevanten Information aus dem HTML-Dokument\n\nAPI im Vergleich:\n\nErster Schritt √§hnlich wie beim Web-Scraping, aber API legen fest, welche Art von Informationen angefordert werden k√∂nnen und wie das Format einer g√ºltigen Abfrage aussieht\n\n\n\nZusammengefasst:\n\nAPI-Zugriff = kontrolliertes Scraping\nHauptunterschied liegt in der ‚ÄúAntwort‚Äù des Server (‚ÄúEinfaches‚Äù Datenformat bei API, statt komplettes HTML-Dokument beim Scraping)\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#kurze-einf√ºhrung",
    "href": "content/03-dbd-data_collection/slides/index.html#kurze-einf√ºhrung",
    "title": "Datenerhebung im Fokus",
    "section": "Kurze Einf√ºhrung",
    "text": "Kurze Einf√ºhrung\n(Web) Application Programming Interface (API)"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#scraping-oder-api",
    "href": "content/03-dbd-data_collection/slides/index.html#scraping-oder-api",
    "title": "Datenerhebung im Fokus",
    "section": "Scraping oder API?",
    "text": "Scraping oder API?\nVor- und Nachteile\n\n\nWeb scraping\n\nüëç WYSIWYG-Prinzip\n\n\nüëé viel Programmierung\n\n\nüëé Verst√∂√üt h√§ufig gegen die AGBs\n\n\nAPIs\n\nüëé Platform bestimmt Inhalte & Limits\n\n\nüëç wenig Programmierung\n\n\nüëç API selbst verhindert Verst√∂√üe gegen AGBs"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#schl√ºsseltechnologie-f√ºr-√ºbertragung-der-nachrichten",
    "href": "content/03-dbd-data_collection/slides/index.html#schl√ºsseltechnologie-f√ºr-√ºbertragung-der-nachrichten",
    "title": "Datenerhebung im Fokus",
    "section": "Schl√ºsseltechnologie f√ºr √úbertragung der Nachrichten",
    "text": "Schl√ºsseltechnologie f√ºr √úbertragung der Nachrichten\nHypertext transfer protocol (HTTP)\nZwei f√ºr die API-Abfrage wichtige Aspekte dieser Nachrichten:\n\nUniform Resource Locator (URL), bestehend aus dem Protokoll, der Domain und dem Pfad zu einer spezifischen Ort der ‚ÄúRessource‚Äù\n\nBeispiel: https://en.wikipedia.org/wiki/API\n\n\nAustausch der Nachrichten haupts√§chlich √ºber GET- und POST-Methode. Bei GET-Methode werden die Abfrageparameter an die URL angeh√§ngt, bei der POST-Methode in den Textk√∂rper der Nachricht aufgenommen\n\nBeispiel: https://en.wikipedia.org/w/index.php?search=API&fulltext=1\n\n\n\n\nSchl√ºsseltechnologie f√ºr die √úbertragung von Nachrichten zwischen Client und Server\nEine einzige Benutzeranfrage resultiert i.d.R. in einer Reihe von Nachrichten zwischen Client und Server, die alle dem HTTP-Protokoll entsprechen\nEine sehr kurze Einf√ºhrung in Webtechnologien und Datenformate\nHauptunterschied der Methoden (GET-/POST) ist, wie sie Abfrageparameter einbeziehen\nBeispiel:\n\nProtokoll & Domaine unver√§ndert, aber Pfad zur Ressource ver√§ndert\nDie spezifische Abfrage wird mit einem Fragezeichen (?) eingeleitet, und die Parameter liegen immer in Form von Schl√ºssel-Wert-Paaren vor, die durch Gleichheitszeichen (=) getrennt sind. Die m√∂glichen Schl√ºssel werden von jeder Seite beliebig festgelegt. Im allgemeinen Fall von mehreren Parametern werden sie durch ein kaufm√§nnisches Und (&) getrennt, wie im folgenden Beispiel, in dem wir Wikipedia bitten, eine Liste von Artikeln zu liefern, die den Suchbegriff enthalten"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#xml-json",
    "href": "content/03-dbd-data_collection/slides/index.html#xml-json",
    "title": "Datenerhebung im Fokus",
    "section": "XML & JSON",
    "text": "XML & JSON\nBeispiele f√ºr prominente Formate von API-Exporten\n\n\nXML (HTML √§hnlich)\n<dataformats>\n  <formats>\n    <names>XML</names>\n    <file_extension>.xml</file_extension>\n  </format>\n  <formats>\n    <names>JSON</names>\n    <file_extension>.json</file_extension>\n  </format>\n</dataformats>\n\n\nXML (Alternative)\n<dataformats>\n  <formats name=\"XML\" file_extension=\".xml\"/>\n  <formats name=\"JSON\" file_extension=\".json\"/>\n</dataformats>\n\n\nJSON\n{\"dataformats\":[\n  {\"name\":\"XML\", \"file_extension\":\".xml\"},\n  {\"name\":\"JSON\", \"file_extension\":\".JSON\"},\n]}"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#koordination-nicht-bereitstellung",
    "href": "content/03-dbd-data_collection/slides/index.html#koordination-nicht-bereitstellung",
    "title": "Datenerhebung im Fokus",
    "section": "Koordination, nicht Bereitstellung",
    "text": "Koordination, nicht Bereitstellung\nImplikationen der Nutzen von APIs\n\nQuery- bzw. Abfragesystem (basierend auf Parametern)\nProgrammierung notwendig (API scraping)\nDaten nicht im Tabellenformat, sondern in JSON/XML\nErgebnisse werden in ‚ÄúChunks‚Äù geliefert (z.B. 100 ‚ÄúReihen‚Äù)\nLimit: Anfragen/MB pro Minuten\n\n\n\nABER:\nImmer h√§ufiger auch f√ºr die gezielte Bereitstellung von Daten genutzt\n\n\n\n‚ñ∂Ô∏è\nDer Zweck von APIs ist die Kommunikation zwischen Programmen zu koordinieren, nicht die Bereitstellung von Daten f√ºr Wissenschaft."
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#know-your-bias",
    "href": "content/03-dbd-data_collection/slides/index.html#know-your-bias",
    "title": "Datenerhebung im Fokus",
    "section": "Know your bias!",
    "text": "Know your bias!\nEin Framework zur Minimierung von Bias (Olteanu et al., 2019)\n\n\nDescription:\n\nSocial data analysis starts with certain goals (section 2.1), such as understanding or influencing phenomena specific to social platforms (Type I) and/or phenomena beyond social platforms (Type II).\nThese goals require that research satisfies certain validity criteria, described earlier (section 2.2).\nThese criteria, in turn, can be compromised by a series of general biases and issues (section 3).\nThese challenges may depend on the characteristics of each data platform (section 4)‚Äîwhich are often not under the control of the researcher‚Äîand on the research designs choices made along a data processing pipeline (from sections 5 to 8)‚Äìwhich are often under the researcher control.\n\nPfeile zeigen an, wie sich Komponenten in unserem Rahmenwerk direkt auf andere auswirken\n\nErreichen bestimmter Ziele (Type I & II) bei der Analyse von Sozialdaten (Abschnitt 2.1) voraussetzt, dass die Forschung bestimmte Validit√§tskriterien erf√ºllt (Abschnitt 2.2),\ndie durch Verzerrungen und andere Probleme mit Sozialdaten beeintr√§chtigt werden k√∂nnen (Abschnitt 3)\nDiese Verzerrungen und Probleme k√∂nnen an der Quelle der Daten auftreten (Abschnitt 4), oder sie k√∂nnen im Verlauf der Datenanalyse eingef√ºhrt werden (Abschnitte 5-8)."
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#bias-at-the-source",
    "href": "content/03-dbd-data_collection/slides/index.html#bias-at-the-source",
    "title": "Datenerhebung im Fokus",
    "section": "Bias at the source",
    "text": "Bias at the source\nPotentielle Probleme mit der Datenquelle oder -herkunft\n\nBiases, die auf das Design und die M√∂glichkeiten der Plattformen zur√ºckzuf√ºhren sind (functional biases).\nVerhaltensnormen, die auf den einzelnen Plattformen bestehen oder sich herausbilden (normative biases).\nFaktoren, die au√üerhalb der sozialen Plattformen liegen, aber das Nutzerverhalten beeinflussen k√∂nnen (external biases)\nVorhandensein von nicht-individuellen Konten ein (non-individuals)."
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#be-aware-when-collecting-data",
    "href": "content/03-dbd-data_collection/slides/index.html#be-aware-when-collecting-data",
    "title": "Datenerhebung im Fokus",
    "section": "Be aware when collecting data",
    "text": "Be aware when collecting data\nPotentielle Probleme bei der Datenerhebung\n\nAkquisition: Abh√§ngig von den Daten, die von Plattformen erfasst und zur Verf√ºgung gestellt werden, den f√ºr den Zugang gesetzten Grenzen und von der Art und Weise, wie der Zugang gew√§hrt wird.\nAbfrage: APIs basieren auf unterschiedlich Dokumentationen sowie Arten von (unterst√ºzten) Abfragen.\nFilterung: In der Regel impliziert die Entscheidung, bestimmte Daten zu entfernen, die Annahme, dass sie f√ºr eine Studie nicht relevant sind. Dies ist hilfreich, wenn die Annahme zutrifft, und sch√§dlich, wenn sie nicht zutrifft.\n\n\n‚ñ∂Ô∏è\nProbleme bei Akquisition:\n\nViele soziale Plattformen raten von der Datenerfassung durch Dritte ab.\nDer programmatische Zugang ist oft mit Einschr√§nkungen verbunden.\nDie Plattform erfasst m√∂glicherweise nicht alle relevanten Daten.\nDie Plattformen gew√§hren m√∂glicherweise keinen Zugang zu allen erfassten Daten.\nStichprobenstrategien sind oft undurchsichtig\n\nProbleme bei Abfrage:\n\nAPIs haben eine begrenzte Aussagekraft in Bezug auf den Informationsbedarf.\nDer Informationsbedarf kann auf unterschiedliche Weise operationalisiert (formuliert) werden.\nDie Wahl der Schl√ºsselw√∂rter in stichwortbasierten Abfragen pr√§gt die resultierenden Datens√§tze.\n\nFilterung: Bei der Datenfilterung werden irrelevante Teile der Daten entfernt, was manchmal w√§hrend der Datenerfassung aufgrund der begrenzten Ausdruckskraft einer API oder Abfragesprache nicht m√∂glich ist. Der Schritt der Datenfilterung am Ende einer Datenerfassungspipeline wird h√§ufig als Nachfilterung bezeichnet, da er nach der Erfassung oder Abfrage der Daten erfolgt (daher das Pr√§fix ‚Äúpost-‚Äù).\n\nProbleme\n\nAusrei√üer sind manchmal f√ºr die Datenanalyse von Bedeutung.\nTextfilterung kann bestimmte Analysen einschr√§nken."
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#handle-with-care",
    "href": "content/03-dbd-data_collection/slides/index.html#handle-with-care",
    "title": "Datenerhebung im Fokus",
    "section": "Handle with care",
    "text": "Handle with care\nPotentielle Probleme bei der Datenverarbeitung\n\nBereinigung: K√∂nnen die √úberzeugungen der Wissenschaftler*Innen √ºber ein Ph√§nomen sowie das System im Allgemeinen in den Datensatz einbetten und in falschen oder irref√ºhrenden Datenmustern resultieren\nAnreicherung: Sowohl manuelle als auch automatische Annotation ( (z.B. Part-of-Speech Tagging) sind fehleranf√§llig und k√∂nnen sowohl bestehende Verzerrungen versch√§rfen als auch neue Verzerrungen und Fehler einf√ºhren.\nAggregation: Die Art und Weise, wie diese Aggregationen vorgenommen werden, oder welche Informationen sie komprimieren, kann zu unterschiedlichen Schlussfolgerungen f√ºhren.\n\n\n‚ñ∂Ô∏è\nAnnahmen bei der Gestaltung von Datenverarbeitungspipelines k√∂nnen sich auf Datens√§tze auswirken und deren Inhalt, Struktur, Organisation oder Darstellung ver√§ndern (Barocas und Selbst, 2016; Poirier, 2018).\nDatenbereinigung:\n\nnicht gleichbedeutend mit Datenfilterung: W√§hrend die Datenbereinigung die Entfernung bestimmter Datenelemente beinhalten kann, kann sie auch die Normalisierung von Daten durch Korrektur oder Ersetzung unvollst√§ndiger oder fehlender Werte umfassen.\nProbleme\n\nDie Wahl der Datendarstellung und der Standardwerte kann zu Verzerrungen f√ºhren.\nDie Normalisierung von Text oder geografischen Referenzen kann zu Verzerrungen f√ºhren.\n\n\nAnreicherungen:\n\numfasst das Hinzuf√ºgen von Anmerkungen zu Datenelementen, die in der Analysephase verwendet werden k√∂nnen. Annotationen k√∂nnen von einfachen kategorischen Etiketten, die jedem Element zugeordnet sind, bis hin zu komplexeren Verarbeitungen wie Part-of-Speech-Tagging oder Dependency Parsing von Text reichen. Sie k√∂nnen entweder durch eine Form der (halb-)automatischen Klassifizierung oder durch menschliche Anmerkungen (z. B. Crowdsourcing, Umfragen) gewonnen werden.\nProbleme\n\nDie manuelle Beschriftung kann zu subjektiven und verrauschten Angaben f√ºhren.\nDie automatische Beschriftung durch statistische oder maschinelle Lernmethoden f√ºhrt zu Fehlern.\n\n\nAggregation:\n\nwird durchgef√ºhrt, um Daten zu strukturieren, zu organisieren, darzustellen oder umzuwandeln; betrachten Sie Vorverarbeitungsheuristiken, die Daten aggregieren, um sie auf Kosten von Informationsverlusten besser handhabbar zu machen. Die Aggregation kann auch die Hervorhebung bestimmter Muster verringern oder verst√§rken (Olteanu et al., 2014b; Poirier, 2018).\nProbleme\n\nBei der Aggregation nach geografischen Gesichtspunkten kann es tats√§chlich zu einer Art ‚ÄúGerrymandering‚Äù kommen, das zu sehr unterschiedlichen Ergebnissen f√ºhrt.\nBei der Betrachtung der Gesamth√§ufigkeit verschiedener Themen unter den Nutzern kann die Aggregation von Inhalten nach Nutzern den Interessen jedes Nutzers das gleiche Gewicht verleihen, w√§hrend die Aggregation nach Themen den Inhalten hochaktiver Nutzer mehr Gewicht verleihen kann.\nWenn die Daten entlang eines bestimmten Attributs organisiert sind (z. B. das Vorhandensein eines Schl√ºsselworts oder Hashtags) und es mehrere unabh√§ngige Faktoren gibt, die dazu f√ºhren, dass das Attribut einen bestimmten Wert annimmt, ist die Analyse von Dateneintr√§gen mit diesem Wert gleichbedeutend mit einer Konditionierung auf diesen Wert und kann zu falschen Assoziationsmustern zwischen diesen Faktoren f√ºhren (Blyth, 1972; Tufekci, 2014)."
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#pre-regestrierung-statt-harking",
    "href": "content/03-dbd-data_collection/slides/index.html#pre-regestrierung-statt-harking",
    "title": "Datenerhebung im Fokus",
    "section": "Pre-Regestrierung statt HARKing",
    "text": "Pre-Regestrierung statt HARKing\nMethodische Fallstricke bei der Analyse von Daten\nDie Wahl einer Analysemethode spiegelt in der Regel die Erfahrung und den Blickwinkel der Forschenden wider und kann verschiedene Bedenken hervorrufen, wie z. B.\n\ndie Verwendung von Daten als Quelle f√ºr Hypothesen und nicht als Instrument zu deren Pr√ºfung;\ndie Anpassung der Forschungsagenda an die Datenverf√ºgbarkeit, was zu Verzerrungen bei der Art der gestellten Fragen f√ºhren kann; oder\ndas Testen mehrerer Hypothesen, bis ein signifikantes, positives Ergebnis gefunden wird (‚Äúfeature hunting‚Äù)\n\n\n‚ñ∂Ô∏è\n‚ÄúHARKing = hypothesizing after results are known‚Äù\nImplikationen. Eine wichtige Konsequenz ist die mangelnde Replizierbarkeit. Aufgrund von Unterschieden in der Analysemethodik, Messung und Datenerhebung konnten Liang und Fu (2015) beispielsweise 6 von 10 bekannten Thesen aus Social-Media-Studien nicht wiederholen. Generell kann die interne und externe Validit√§t sowohl der Typ-I- als auch der Typ-II-Forschung durch die Wahl der Methoden beeinflusst werden, die bei der Analyse der Daten angewandt werden, um Nutzerpopulationen und -verhaltensweisen zu charakterisieren (Abschnitte 7.1-7.2), Schlussfolgerungen und Vorhersagen zu treffen (Abschnitt 7.3) und (kausale) Zusammenh√§nge zu ermitteln (Abschnitt 7.4)."
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#offenheit-und-transparenz-als-l√∂sung-statt-als-problem",
    "href": "content/03-dbd-data_collection/slides/index.html#offenheit-und-transparenz-als-l√∂sung-statt-als-problem",
    "title": "Datenerhebung im Fokus",
    "section": "Offenheit und Transparenz als L√∂sung statt als Problem",
    "text": "Offenheit und Transparenz als L√∂sung statt als Problem\nProbleme bei der Auswertung und Interpretation der Ergebnisse\n\nAuswahl der Messgr√∂√üen: Besonders bei latenten Konstrukten ist die Art der Operationalisierung (z. B. Sharing-Muster als N√§herungswert f√ºr Beliebtheit) entscheidend f√ºr die Aussagekraft der Studie(n)\nBewertung und Interpretation der Ergebnisse: Abh√§ngig von den urspr√ºnglichen Annahmen (z.B. dass soziale Online-Spuren in gewisser Weise quantifizierbare Ph√§nomene der realen Welt\nDisclaimer und Reproduzierbarkeit: Um die Reproduzierbarkeit (durch standardisierte experimentelle Methoden) zu f√∂rdern, ist die Entwicklung von Standardbewertungsverfahren und -metriken notwendig\n\n\n‚ñ∂Ô∏è\nEine letzte M√∂glichkeit, Verzerrungen zu ber√ºcksichtigen und die Zuverl√§ssigkeit der Ergebnisse zu beurteilen, besteht bei der Bewertung und Interpretation der Leistung eines Instruments oder der Ergebnisse einer Studie. Ein guter Ausgangspunkt ist ein angemessenes Verst√§ndnis f√ºr die Art der verwendeten Daten. Rost et al.¬†(2013) argumentieren beispielsweise, dass Daten, die explizit von Nutzern in sozialen Medien generiert werden, eher als kommunikativ denn als repr√§sentativ interpretiert werden sollten, da diese Daten oft eine Aufzeichnung der Kommunikation und nicht eine direkte Darstellung anderer (‚Äúrealer‚Äù) Verhaltensweisen sind, was Fragen zur Konstrukt- und internen Validit√§t aufwirft.\nProbleme bei Auswahl der Messgr√∂√üen:\n\nDie Wahl der Metriken pr√§gt eine Forschungsstudie - Schlussfolgerungen\nDie Bewertung der Fairness bringt ihre eigenen Herausforderungen mit sich.\nKontext- oder bereichsspezifische Leistungsindikatoren werden selten verwendet.\n\nProbleme bei der Bewertung und Interpretation der Ergebnisse\n\nDie Bedeutung sozialer Spuren kann sich je nach Kontext √§ndern; dies ist jedoch bei der Bewertung schwer zu erkennen\nAnalysen und Bewertungen, die sich auf einen einzigen Datensatz oder eine einzige Methode beschr√§nken, k√∂nnen nicht verallgemeinert werden.\nDie Interpretation und Bewertung der Ergebnisse wird zu oft von Datenexperten und nicht von Fachleuten vorgenommen.\n\nDisclaimers und Reproduzierbarkeit\n\nUm die Reproduzierbarkeit zu f√∂rdern, m√ºssen Grundlagen und Leitlinien entwickelt werden (Tufekci, 2014; Weller und Kinder-Kurlanda, 2015), eine gemeinsame Basis f√ºr methodische Ans√§tze gefunden werden (Counts et al., 2014) und selbst entwickelte Instrumente und Methoden sowie die Datenherkunft besser dokumentiert werden (Bruns, 2013; Weller und Kinder-Kurlanda, 2015).\nProbleme:\n\nDisclaimers und negative Ergebnisse werden √ºbersehen.\nDie gemeinsame Nutzung von Daten und Instrumenten muss erleichtert werden."
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#final-takeaways",
    "href": "content/03-dbd-data_collection/slides/index.html#final-takeaways",
    "title": "Datenerhebung im Fokus",
    "section": "Final Takeaways",
    "text": "Final Takeaways\nAbschlie√üende Bewertung der Arbeit mit DBD\n\nViele M√∂glichkeiten zur Untersuchung verschiedener Forschungsfragen\nDie (begr√ºndete) Auswahl der Plattform, die f√ºr die Forschung dienen soll, ist wichtig\nAPIs sind nicht f√ºr Forschende gedacht, um auf Daten zuzugreifen.\nAPIs bieten Zugang zu Modellen des maschinellen Lernens:\n\nBei ‚Äúlangweilige‚Äù Annotationsaufgabe lohnt sich die Suchen nach einer API. Die Chancen stehen gut, dass bereits eine API f√ºr diese Aufgabe existiert.\n\n\n\n\nEmpfehlungen:\nKnow your biases and validate, validate, validate!\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "href": "content/03-dbd-data_collection/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "title": "Datenerhebung im Fokus",
    "section": "Vielen Dank f√ºr Ihre Fragen!",
    "text": "Vielen Dank f√ºr Ihre Fragen!\n\n\nDie Vernetzung in unserer Welt nimmt immer mehr zu und Prozesse m√ºssen perfekt aufeinander abgestimmt sein. Es gibt eine riesige Menge an verschiedenen APIs und unsere Abh√§ngigkeit von ihnen wird zunehmend gr√∂√üer. Aber wie zuverl√§ssig sind APIs eigentlich und wie kann ein API-Missbrauch aussehen?\n\n\n\n\nFacebook und andere Plattformen haben den Zugang zu Nutzerdaten √ºber ihr API aus Datenschutzgr√ºnden stark eingeschr√§nkt. Jedoch kann bislang jede Organisation individuell dar√ºber entscheiden, welche Restriktionen es in dieser Hinsicht geben soll. Sollte es √ºbergreifende ‚ÄûRegeln‚Äù f√ºr APIs geben, die von jedem einzuhalten sind? Wenn ja, k√∂nnten Verst√∂√üe strafrechtlich verfolgt werden?\n\n\n\n\nMithilfe von APIs kann man verh√§ltnism√§√üig einfach an Daten gelangen. Jedoch sind die Algorithmen hinter den Plattformen oft nicht nachvollziehbar (z.B. woher kommen personalisierte Empfehlungen). K√∂nnen die extrahierten Daten tats√§chlich interpretiert werden, wenn die Entstehung nicht nachvollziehbar ist?\n\n\n\n\nWeb-APIs erfordern grundlegende Programmierkenntnisse, um den Zugang zu erm√∂glichen. Leider gibt es bislang keine effizienten Alternativen. Gibt es potentielle Ans√§tze, um diese H√ºrde auf eine andere Art und Weise zu √ºberwinden."
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#mehr-als-eine-enzyklop√§die",
    "href": "content/03-dbd-data_collection/slides/index.html#mehr-als-eine-enzyklop√§die",
    "title": "Datenerhebung im Fokus",
    "section": "Mehr als eine Enzyklop√§die",
    "text": "Mehr als eine Enzyklop√§die\nDie Vielfalt von Wikipedia\n\n\n‚Ä¶ als soziales Netzwerk der Zusammenarbeit\n\n20K aktive Redakteur*Innen pro Monat (englisches Wikipedia)\nWikipedia-Seitengespr√§che (wo Diskussionen √ºber Artikel√ºberarbeitungen stattfinden)\nAufzeichnung aller √úberarbeitungen\nQuellen (Referenzen), die den Inhalt unterst√ºtzen (Zagovora et al., 2020)\n\n\n‚Ä¶ als eine Vielzahl von APIs und Tools, die damit verbunden sind, z. B:\n\nStatistiken: https://xtools.wmflabs.org\nWissensdatenbank: https://www.wikidata.org\nKlassifizierungssysteme: https://ores.wikimedia.org\nVerfolgung von √Ñnderungen: https://www.wikiwho.net (Fl√∂ck & Acosta, 2014)\nBedeutung von Wikipedia als Korpus f√ºr maschinelle Lernsysteme (NLP)\nEine kostenlose API (oder direkter Download von Dumps)\n\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#im-fokus-wikiwho-whocolor-api",
    "href": "content/03-dbd-data_collection/slides/index.html#im-fokus-wikiwho-whocolor-api",
    "title": "Datenerhebung im Fokus",
    "section": "Im Fokus: WikiWho & WhoColor API",
    "text": "Im Fokus: WikiWho & WhoColor API\nAuswertung von √Ñnderungen und Interaktionen auf √ºberarbeiteten Schreibplattformen.\n\n\nKernfunktionalit√§t von WikiWho\n\nBei einem revidierten Textdokument werden aller historischen Revisionen (Versionen) analysiert, um herauszufinden, wer welchen genauen Text auf Token-Ebene in welcher Revision geschrieben und/oder entfernt und/oder wieder eingef√ºgt hat\nF√ºr jedes Token (~Wort) ist seine individuelle Hinzuf√ºgungs-/Entfernungs-/Wiedereinf√ºgungsgeschichte verf√ºgbar.\n\n‚Ä¶ in Kombination mit WhoColor API\n\nBeim √ñffnen eines Wikipedia-Artikels wird eine farbliche Markierung des Textes erstellt, die die urspr√ºnglichen Autor:Innen des Inhalts, eine Autor:Innenliste, geordnet nach dem prozentualen Anteil an der Erstellung des Artikels, und zus√§tzliche Herkunftsinformationen anzeigt.\nEs kann auch Konflikte in Bezug auf bestimmte Textteile und die Historie des Hinzuf√ºgens/L√∂schens eines bestimmten Wortes anzeigen.\n\n\nBeispiel:"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#and-now-you",
    "href": "content/03-dbd-data_collection/slides/index.html#and-now-you",
    "title": "Datenerhebung im Fokus",
    "section": "And now ‚Ä¶ you!",
    "text": "And now ‚Ä¶ you!\nAnwendung von WhoColor API\n\n\nErster Schritt:\n\nf√ºr Google Chrome: Laden und installieren Sie die Tampermonkey-Erweiterung.\nf√ºr Mozilla Firefox: Laden und installieren Sie die Greasemonkey-Erweiterung.\n\nZweiter Schritt:\n\nSobald Sie eine der *Monkey-Erweiterungen erfolgreich installiert haben, gehen Sie zu whocolor.user.js.\nIhre *monkey-Browsererweiterung sollte Ihnen dann automatisch eine Installationsaufforderung anzeigen, die Sie best√§tigen m√ºssen.\n\nDritter Schritt:\n√ñffnen Sie entweder den Wikipedia-Artikel von Donald Trump oder Elon Musk und wenden Sie das ‚ÄúWhoColor‚Äù-Plugin an.\n\n\n\n\n\n\n\n\n\nVierter Schritt: Explore!\nWas f√§llt Ihnen auf ‚Ä¶\n\nbez√ºglich der Editors List?\nmit Blick auf besonders ‚Äúkonfliktreiche‚Äù Stellen?\nmit Blick auf aktuelle Ver√§nderungen?\n‚Ä¶"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#many-more-apis-to-access-data",
    "href": "content/03-dbd-data_collection/slides/index.html#many-more-apis-to-access-data",
    "title": "Datenerhebung im Fokus",
    "section": "Many more APIs to access data",
    "text": "Many more APIs to access data\n\nSuchmaschinen-APIs (Google, Bing)\nStaatliche Daten (abgeordnetenwatch.de, data.gov, data.gov.uk, open-data.europa.eu)\nInternationale Agenturen: UN, WHO, die Weltbank\nNachrichtenorganisationen: BBC, The New York Times, The Guardian, NPR, USA Today und ZEIT Online\nWissenschaftliche Archive und Fachzeitschriften: arXiv, PLoS, Mendeley\nMetadaten von Daten: Dryad (https://datadryad.org/api/v2/docs/), Figshare (https://docs.figshare.com/)\nMusik: Spotify, Soundcloud\n‚Ä¶"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/index.html#literatur",
    "href": "content/03-dbd-data_collection/slides/index.html#literatur",
    "title": "Datenerhebung im Fokus",
    "section": "Literatur",
    "text": "Literatur\n\n\nFl√∂ck, F., & Acosta, M. (2014). the 23rd international conference. 843‚Äì854. https://doi.org/10.1145/2566486.2568026\n\n\nFl√∂ck, F., & Sen, I. (2022). Digital traces of human behaviour in online platforms  research design and error sources. https://www.gesis.org/fileadmin/user_upload/MeettheExperts/GESIS_Meet_the_experts_Digitaltraces_humanbehaviour.pdf\n\n\nOlteanu, A., Castillo, C., Diaz, F., & Kƒ±cƒ±man, E. (2019). Social data: Biases, methodological pitfalls, and ethical boundaries. Frontiers in Big Data, 2, 13. https://doi.org/10.3389/fdata.2019.00013\n\n\nUlloa, R. (2021). Introduction to online data acquisition. https://www.gesis.org/fileadmin/user_upload/MeettheExperts/GESIS_Meettheexperts_Introductioncss.pdf\n\n\nZagovora, O., Ulloa, R., Weller, K., & Fl√∂ck, F. (2020). ‚ÄôI updated the ‚Äô: The evolution of references in the english wikipedia and the implications for altmetrics. https://doi.org/10.48550/ARXIV.2010.03083"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/scripts/graph_creation.html",
    "href": "content/03-dbd-data_collection/slides/scripts/graph_creation.html",
    "title": "graph_creation",
    "section": "",
    "text": "library(tidyverse)\n\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ\n‚úî ggplot2 3.4.0      ‚úî purrr   0.3.5 \n‚úî tibble  3.1.8      ‚úî dplyr   1.0.10\n‚úî tidyr   1.2.1      ‚úî stringr 1.4.1 \n‚úî readr   2.1.3      ‚úî forcats 0.5.2 \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n\nlibrary(svgtools)\nlibrary(here)\n\nhere() starts at D:/repos/github/digital-behavioral-data"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/scripts/graph_creation.html#dbd-research-design",
    "href": "content/03-dbd-data_collection/slides/scripts/graph_creation.html#dbd-research-design",
    "title": "graph_creation",
    "section": "DBD Research design",
    "text": "DBD Research design\n\nGet base graphic\n\ngraph_base_dbd <- svgtools::read_svg(\n  here(\"content/03-dbd-data_collection/slides/graphs/graph_dbd-01_base.svg\")) \n\n\n\ngraph_dbd_01\n\n# Create graph\ngraph_dbd_01 <- graph_base_dbd %>% \n  toString() %>%\n  #### GROUP: Population\n   # Circles\n  stringr::str_replace_all('\"#00B050\"', '\"#04316A\"') %>% # change color\n   # Label\n  stringr::str_replace(\"symbol1label\", \"Population\") %>% # change label\n  #### GROUP: Construct\n    # Shape\n  stringr::str_replace_all('\"#FFFF00\"', '\"#FFFF0000\"') %>% # hide symbol\n    # Label\n  stringr::str_replace('symbol2label', '') %>% # hide label\n  #### GROUP: Text bubbles (Population and Construct)\n    # Shape\n  stringr::str_replace_all('\"#7F6000\"', '\"#7F600000\"') %>% # hide bubble\n    # Text\n  stringr::str_replace(\"bubble1label1\", \"\") %>% # hide text\n  stringr::str_replace(\"bubble1label2\", \"\") %>% # hide text\n  stringr::str_replace(\"bubble2label1\", \"\") %>% # hide text\n  stringr::str_replace(\"bubble2label2\", \"\") %>% # hide text\n  #### GROUP: Survey\n    # Symbol\n  stringr::str_replace_all('\"#70AD47\"', '\"#70AD4700\"') %>% # hide symbol\n    # Label\n  stringr::str_replace_all('label_box_3', '') %>% # hide label\n  #### GROUP: Free Text(Survey)\n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff8080\"',\n    'style=\"fill:#ff808000\"') %>% # hide bulletpoints \n    # Text\n  stringr::str_replace(\"surveylabel1\", \"\") %>% # hide text\n  stringr::str_replace(\"surveylabel2\", \"\") %>% # hide text\n  stringr::str_replace(\"surveylabel3\", \"\") %>% # hide text\n  #### GROUP: SNS Twitter\n    # Box & Symbol\n  stringr::str_replace_all('\"#00B0F0\"', '\"#00B0F000\"') %>% # hide filling\n    # Cirles\n  stringr::str_replace_all('\"#0066FF\"', '\"#0066FF00\"') %>% # hide filling  \n  stringr::str_replace_all('\"#FF0000\"', '\"#FF000000\"') %>% # hide strokes\n    # Label\n  stringr::str_replace_all('User', '') %>% # hide label\n  #### GROUP: SNS Populations\n    # Boxes & Symbols\n  stringr::str_replace_all('\"#C55A11\"', '\"#C55A1100\"') %>% # hide stroke\n    # Cirles\n  stringr::str_replace_all('\"#800000\"', '\"#80000000\"') %>% # hide filling  \n  stringr::str_replace_all('\"#9900FF\"', '\"#9900FF00\"') %>% # hide strokes\n  #### GROUP: Links\n  stringr::str_replace_all('\"#7F7F7F\"', '\"#7F7F7F00\"') %>% # hide stroke\n  #### GROUP: SNS Population Textboxes\n    # Shape\n  stringr::str_replace_all('\"#7030A0\"', '\"#7030A000\"') %>% # hide boxes \n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff00ff\"',\n    'style=\"fill:#ff00ff00\"') %>% # hide bulletpoints \n    # Text\n    ## Box 1\n  stringr::str_replace_all('box1h1', '') %>% # hide text\n  stringr::str_replace_all('box1text1', '') %>% # hide text\n  stringr::str_replace_all('box1text2', '') %>% # hide text\n  stringr::str_replace_all('box1text3', '') %>% # hide text\n  stringr::str_replace_all('box1text4', '') %>% # hide text\n    ## Box 2 \n  stringr::str_replace_all('box2h1', '') %>% # hide text\n  stringr::str_replace_all('box2text1', '') %>% # hide text\n  stringr::str_replace_all('box2text2', '') %>% # hide text\n  stringr::str_replace_all('box2text3', '') %>% # hide text\n #### Convert back to .svg\n  svgtools::read_svg(.) \n  \n# Save output\nsvgtools::write_svg(\n  graph_dbd_01, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_dbd_01.svg\"))\n\n\n\ngraph_dbd_02\n\n# Create graph\ngraph_dbd_02 <- graph_base_dbd %>% \n  toString() %>%\n  #### GROUP: Population\n   # Circles\n  stringr::str_replace_all('\"#00B050\"', '\"#04316A\"') %>% \n   # Label\n  stringr::str_replace(\"symbol1label\", \"Population\") %>%\n  #### GROUP: Construct\n    # Shape\n  stringr::str_replace_all('\"#FFFF00\"', '\"#E6002E\"') %>% # CHANGE color \n    # Label\n  stringr::str_replace('symbol2label', 'Konstrukt') %>% # CHANGE text\n  #### GROUP: Text bubbles (Population and Construct)\n    # Shape\n  stringr::str_replace_all('\"#7F6000\"', '\"#7F600000\"') %>%\n    # Text\n  stringr::str_replace(\"bubble1label1\", \"\") %>% \n  stringr::str_replace(\"bubble1label2\", \"\") %>% \n  stringr::str_replace(\"bubble2label1\", \"\") %>% \n  stringr::str_replace(\"bubble2label2\", \"\") %>% \n  #### GROUP: Survey\n    # Symbol\n  stringr::str_replace_all('\"#70AD47\"', '\"#70AD4700\"') %>% \n    # Label\n  stringr::str_replace_all('label_box_3', '') %>% \n  #### GROUP: Free Text(Survey)\n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff8080\"',\n    'style=\"fill:#ff808000\"') %>%  \n    # Text\n  stringr::str_replace(\"surveylabel1\", \"\") %>% \n  stringr::str_replace(\"surveylabel2\", \"\") %>% \n  stringr::str_replace(\"surveylabel3\", \"\") %>% \n  #### GROUP: SNS Twitter\n    # Box & Symbol\n  stringr::str_replace_all('\"#00B0F0\"', '\"#00B0F000\"') %>%\n    # Cirles\n  stringr::str_replace_all('\"#0066FF\"', '\"#0066FF00\"') %>%   \n  stringr::str_replace_all('\"#FF0000\"', '\"#FF000000\"') %>% \n    # Label\n  stringr::str_replace_all('User', '') %>% \n  #### GROUP: SNS Populations\n    # Boxes & Symbols\n  stringr::str_replace_all('\"#C55A11\"', '\"#C55A1100\"') %>% \n    # Cirles\n  stringr::str_replace_all('\"#800000\"', '\"#80000000\"') %>%   \n  stringr::str_replace_all('\"#9900FF\"', '\"#9900FF00\"') %>% \n  #### GROUP: Links\n  stringr::str_replace_all('\"#7F7F7F\"', '\"#7F7F7F00\"') %>% \n  #### GROUP: SNS Population Textboxes\n    # Shape\n  stringr::str_replace_all('\"#7030A0\"', '\"#7030A000\"') %>%  \n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff00ff\"',\n    'style=\"fill:#ff00ff00\"') %>%\n    # Text\n    ## Box 1\n  stringr::str_replace_all('box1h1', '') %>% \n  stringr::str_replace_all('box1text1', '') %>% \n  stringr::str_replace_all('box1text2', '') %>%\n  stringr::str_replace_all('box1text3', '') %>%\n  stringr::str_replace_all('box1text4', '') %>% \n    ## Box 2 \n  stringr::str_replace_all('box2h1', '') %>% \n  stringr::str_replace_all('box2text1', '') %>% \n  stringr::str_replace_all('box2text2', '') %>% \n  stringr::str_replace_all('box2text3', '') %>% \n #### Convert back to .svg\n  svgtools::read_svg(.) \n  \n# Save output\nsvgtools::write_svg(\n  graph_dbd_02, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_dbd_02.svg\"))\n\n\n\ngraph_dbd_03\n\n# Create graph\ngraph_dbd_03 <- graph_base_dbd %>% \n  toString() %>%\n  #### GROUP: Population\n   # Circles\n  stringr::str_replace_all('\"#00B050\"', '\"#04316A\"') %>% \n   # Label\n  stringr::str_replace(\"symbol1label\", \"Population\") %>%\n  #### GROUP: Construct\n    # Shape\n  stringr::str_replace_all('\"#FFFF00\"', '\"#04316A\"') %>% # CHANGE color \n    # Label\n  stringr::str_replace('symbol2label', 'Konstrukt') %>% # CHANGE text\n #### Group: Symbol text bubbles\n    # Shape\n  stringr::str_replace_all('stroke=\"#7F6000\"','stroke=\"#e6002e\"') %>% # CHANGE stroke\n  stringr::str_replace_all('fill=\"#7F6000\"', 'fill=\"#ffffff\"') %>% # CHANGE fill\n    # Text\n  stringr::str_replace(\"bubble1label1\", \"Alle Erwachsenen\") %>% # CHANGE text\n  stringr::str_replace(\"bubble1label2\", \"in Deutschland\") %>% # CHANGE text\n  stringr::str_replace(\"bubble2label1\", \"Unterst√ºtzung der\") %>% # CHANGE text\n  stringr::str_replace(\"bubble2label2\", \"COVID19-Ma√ünamen\") %>% # CHANGE text\n  #### GROUP: Survey\n    # Symbol\n  stringr::str_replace_all('\"#70AD47\"', '\"#70AD4700\"') %>% \n    # Label\n  stringr::str_replace_all('label_box_3', '') %>% \n  #### GROUP: Free Text(Survey)\n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff8080\"',\n    'style=\"fill:#ff808000\"') %>%  \n    # Text\n  stringr::str_replace(\"surveylabel1\", \"\") %>% \n  stringr::str_replace(\"surveylabel2\", \"\") %>% \n  stringr::str_replace(\"surveylabel3\", \"\") %>% \n  #### GROUP: SNS Twitter\n    # Box & Symbol\n  stringr::str_replace_all('\"#00B0F0\"', '\"#00B0F000\"') %>%\n    # Cirles\n  stringr::str_replace_all('\"#0066FF\"', '\"#0066FF00\"') %>%   \n  stringr::str_replace_all('\"#FF0000\"', '\"#FF000000\"') %>% \n    # Label\n  stringr::str_replace_all('User', '') %>% \n  #### GROUP: SNS Populations\n    # Boxes & Symbols\n  stringr::str_replace_all('\"#C55A11\"', '\"#C55A1100\"') %>% \n    # Cirles\n  stringr::str_replace_all('\"#800000\"', '\"#80000000\"') %>%   \n  stringr::str_replace_all('\"#9900FF\"', '\"#9900FF00\"') %>% \n  #### GROUP: Links\n  stringr::str_replace_all('\"#7F7F7F\"', '\"#7F7F7F00\"') %>% \n  #### GROUP: SNS Population Textboxes\n    # Shape\n  stringr::str_replace_all('\"#7030A0\"', '\"#7030A000\"') %>%  \n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff00ff\"',\n    'style=\"fill:#ff00ff00\"') %>%\n    # Text\n    ## Box 1\n  stringr::str_replace_all('box1h1', '') %>% \n  stringr::str_replace_all('box1text1', '') %>% \n  stringr::str_replace_all('box1text2', '') %>%\n  stringr::str_replace_all('box1text3', '') %>%\n  stringr::str_replace_all('box1text4', '') %>% \n    ## Box 2 \n  stringr::str_replace_all('box2h1', '') %>% \n  stringr::str_replace_all('box2text1', '') %>% \n  stringr::str_replace_all('box2text2', '') %>% \n  stringr::str_replace_all('box2text3', '') %>% \n #### Convert back to .svg\n  svgtools::read_svg(.) \n  \n# Save output\nsvgtools::write_svg(\n  graph_dbd_03, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_dbd_03.svg\"))\n\n\n\ngraph_dbd_04\n\n# Create graph\ngraph_dbd_04 <- graph_base_dbd %>% \n  toString() %>%\n  #### GROUP: Population\n   # Circles\n  stringr::str_replace_all('\"#00B050\"', '\"#04316A\"') %>% \n   # Label\n  stringr::str_replace(\"symbol1label\", \"Population\") %>%\n  #### GROUP: Construct\n    # Shape\n  stringr::str_replace_all('\"#FFFF00\"', '\"#04316A\"') %>% \n    # Label\n  stringr::str_replace('symbol2label', 'Konstrukt') %>% \n  #### GROUP: Text bubbles (Population and Construct)\n    # Shape\n  stringr::str_replace_all('\"#7F6000\"', '\"#7F600000\"') %>%  # HIDE boxes\n    # Text\n  stringr::str_replace(\"bubble1label1\", \"\") %>% # HIDE text\n  stringr::str_replace(\"bubble1label2\", \"\") %>% # HIDE text\n  stringr::str_replace(\"bubble2label1\", \"\") %>% # HIDE text\n  stringr::str_replace(\"bubble2label2\", \"\") %>% # HIDE text\n  #### GROUP: Survey\n    # Symbol\n  stringr::str_replace_all('\"#70AD47\"', '\"#E6002E\"') %>% # CHANGE color\n    # Label\n  stringr::str_replace_all('label_box_3', 'Survey') %>% # CHANGE label\n  #### GROUP: Free Text(Survey)\n    # Bulletpoints\n  stringr::str_replace_all('style=\"fill:#ff8080\"','style=\"fill:#E6002E\"') %>% # CHANGE color\n    # Text\n  stringr::str_replace(\"surveylabel1\", \"Teuer\") %>% # CHANGE text\n  stringr::str_replace(\"surveylabel2\", \"Zeitverz√∂rgert\") %>% # CHANGE text\n  stringr::str_replace(\"surveylabel3\", '\"Kleine\" Samples') %>% # CHANGE text \n  #### GROUP: SNS Twitter\n    # Box & Symbol\n  stringr::str_replace_all('\"#00B0F0\"', '\"#00B0F000\"') %>%\n    # Cirles\n  stringr::str_replace_all('\"#0066FF\"', '\"#0066FF00\"') %>%   \n  stringr::str_replace_all('\"#FF0000\"', '\"#FF000000\"') %>% \n    # Label\n  stringr::str_replace_all('User', '') %>% \n  #### GROUP: SNS Populations\n    # Boxes & Symbols\n  stringr::str_replace_all('\"#C55A11\"', '\"#C55A1100\"') %>% \n    # Cirles\n  stringr::str_replace_all('\"#800000\"', '\"#80000000\"') %>%   \n  stringr::str_replace_all('\"#9900FF\"', '\"#9900FF00\"') %>% \n  #### GROUP: Links\n  stringr::str_replace_all('\"#7F7F7F\"', '\"#7F7F7F00\"') %>% \n  #### GROUP: SNS Population Textboxes\n    # Shape\n  stringr::str_replace_all('\"#7030A0\"', '\"#7030A000\"') %>%  \n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff00ff\"',\n    'style=\"fill:#ff00ff00\"') %>%\n    # Text\n    ## Box 1\n  stringr::str_replace_all('box1h1', '') %>% \n  stringr::str_replace_all('box1text1', '') %>% \n  stringr::str_replace_all('box1text2', '') %>%\n  stringr::str_replace_all('box1text3', '') %>%\n  stringr::str_replace_all('box1text4', '') %>% \n    ## Box 2 \n  stringr::str_replace_all('box2h1', '') %>% \n  stringr::str_replace_all('box2text1', '') %>% \n  stringr::str_replace_all('box2text2', '') %>% \n  stringr::str_replace_all('box2text3', '') %>% \n #### Convert back to .svg\n  svgtools::read_svg(.) \n  \n# Save output\nsvgtools::write_svg(\n  graph_dbd_04, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_dbd_04.svg\"))\n\n\n\ngraph_dbd_05\n\n# Create graph\ngraph_dbd_05 <- graph_base_dbd %>% \n  toString() %>%\n  #### GROUP: Population\n   # Circles\n  stringr::str_replace_all('\"#00B050\"', '\"#04316A\"') %>% \n   # Label\n  stringr::str_replace(\"symbol1label\", \"Population\") %>%\n  #### GROUP: Construct\n    # Shape\n  stringr::str_replace_all('\"#FFFF00\"', '\"#04316A\"') %>% \n    # Label\n  stringr::str_replace('symbol2label', 'Konstrukt') %>% \n  #### GROUP: Text bubbles (Population and Construct)\n    # Shape\n  stringr::str_replace_all('\"#7F6000\"', '\"#7F600000\"') %>%  \n    # Text\n  stringr::str_replace(\"bubble1label1\", \"\") %>% \n  stringr::str_replace(\"bubble1label2\", \"\") %>%  \n  stringr::str_replace(\"bubble2label1\", \"\") %>% \n  stringr::str_replace(\"bubble2label2\", \"\") %>% \n  #### GROUP: Survey\n    # Symbol\n  stringr::str_replace_all('\"#70AD47\"', '\"#04316A\"') %>% # CHANGE color\n    # Label\n  stringr::str_replace_all('label_box_3', 'Survey') %>% # CHANGE label\n  #### GROUP: Free Text(Survey)\n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff8080\"',\n    'style=\"fill:#ff808000\"') %>%  \n    # Text\n  stringr::str_replace(\"surveylabel1\", \"\") %>% # HIDE text\n  stringr::str_replace(\"surveylabel2\", \"\") %>% # HIDE text\n  stringr::str_replace(\"surveylabel3\", \"\") %>% # HIDE text \n  #### GROUP: Links (moved to avoid replacement of color)\n  stringr::str_replace_all('\"#7F7F7F\"', '\"#7F7F7F00\"') %>% \n  #### GROUP: SNS Twitter\n    # Box & Symbol\n  stringr::str_replace_all('\"#00B0F0\"', '\"#E6002E\"') %>% # CHANGE color\n    # Cirles\n  stringr::str_replace_all('\"#0066FF\"', '\"#7F7F7F\"') %>% # CHANGE color  \n  stringr::str_replace_all('\"#FF0000\"', '\"#04316A\"') %>% # CHANGE color\n    # Label\n  stringr::str_replace_all('User', '') %>% \n  #### GROUP: SNS Populations\n    # Boxes & Symbols\n  stringr::str_replace_all('\"#C55A11\"', '\"#E6002E\"') %>% # CHANGE color\n    # Cirles\n  stringr::str_replace_all('\"#800000\"', '\"#7F7F7F\"') %>% # CHANGE color  \n  stringr::str_replace_all('\"#9900FF\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP: SNS Population Textboxes\n    # Shape\n  stringr::str_replace_all('\"#7030A0\"', '\"#7030A000\"') %>%  \n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff00ff\"',\n    'style=\"fill:#ff00ff00\"') %>%\n    # Text\n    ## Box 1\n  stringr::str_replace_all('box1h1', '') %>% \n  stringr::str_replace_all('box1text1', '') %>% \n  stringr::str_replace_all('box1text2', '') %>%\n  stringr::str_replace_all('box1text3', '') %>%\n  stringr::str_replace_all('box1text4', '') %>% \n    ## Box 2 \n  stringr::str_replace_all('box2h1', '') %>% \n  stringr::str_replace_all('box2text1', '') %>% \n  stringr::str_replace_all('box2text2', '') %>% \n  stringr::str_replace_all('box2text3', '') %>% \n #### Convert back to .svg\n  svgtools::read_svg(.) \n  \n# Save output\nsvgtools::write_svg(\n  graph_dbd_05, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_dbd_05.svg\"))\n\n\n\ngraph_dbd_06\n\n# Create graph\ngraph_dbd_06 <- graph_base_dbd %>% \n  toString() %>%\n  #### GROUP: Population\n   # Circles\n  stringr::str_replace_all('\"#00B050\"', '\"#04316A\"') %>% \n   # Label\n  stringr::str_replace(\"symbol1label\", \"Population\") %>%\n  #### GROUP: Construct\n    # Shape\n  stringr::str_replace_all('\"#FFFF00\"', '\"#04316A\"') %>% \n    # Label\n  stringr::str_replace('symbol2label', 'Konstrukt') %>% \n  #### GROUP: Text bubbles (Population and Construct)\n    # Shape\n  stringr::str_replace_all('\"#7F6000\"', '\"#7F600000\"') %>%  \n    # Text\n  stringr::str_replace(\"bubble1label1\", \"\") %>% \n  stringr::str_replace(\"bubble1label2\", \"\") %>%  \n  stringr::str_replace(\"bubble2label1\", \"\") %>% \n  stringr::str_replace(\"bubble2label2\", \"\") %>% \n  #### GROUP: Survey\n    # Symbol\n  stringr::str_replace_all('\"#70AD47\"', '\"#04316A\"') %>%  \n    # Label\n  stringr::str_replace_all('label_box_3', 'Survey') %>% \n  #### GROUP: Free Text(Survey)\n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff8080\"',\n    'style=\"fill:#ff808000\"') %>%  \n    # Text\n  stringr::str_replace(\"surveylabel1\", \"\") %>% \n  stringr::str_replace(\"surveylabel2\", \"\") %>% \n  stringr::str_replace(\"surveylabel3\", \"\") %>% \n  #### GROUP: Links (moved to avoid replacement of color)\n  stringr::str_replace_all('\"#7F7F7F\"', '\"#E6002E\"') %>% # CHANGE color\n  #### GROUP: SNS Twitter\n    # Box & Symbol\n  stringr::str_replace_all('\"#00B0F0\"', '\"#04316A\"') %>% # CHANGE color\n    # Cirles\n  stringr::str_replace_all('\"#0066FF\"', '\"#7F7F7F\"') %>% #   \n  stringr::str_replace_all('\"#FF0000\"', '\"#04316A\"') %>% # \n    # Label\n  stringr::str_replace_all('User', '') %>% \n  #### GROUP: SNS Populations\n    # Boxes & Symbols\n  stringr::str_replace_all('\"#C55A11\"', '\"#04316A\"') %>% # CHANGE color\n    # Cirles\n  stringr::str_replace_all('\"#800000\"', '\"#7F7F7F\"') %>% #   \n  stringr::str_replace_all('\"#9900FF\"', '\"#04316A\"') %>% # \n  #### GROUP: SNS Population Textboxes\n    # Shape\n  stringr::str_replace_all('\"#7030A0\"', '\"#7030A000\"') %>%  \n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff00ff\"',\n    'style=\"fill:#ff00ff00\"') %>%\n    # Text\n    ## Box 1\n  stringr::str_replace_all('box1h1', '') %>% \n  stringr::str_replace_all('box1text1', '') %>% \n  stringr::str_replace_all('box1text2', '') %>%\n  stringr::str_replace_all('box1text3', '') %>%\n  stringr::str_replace_all('box1text4', '') %>% \n    ## Box 2 \n  stringr::str_replace_all('box2h1', '') %>% \n  stringr::str_replace_all('box2text1', '') %>% \n  stringr::str_replace_all('box2text2', '') %>% \n  stringr::str_replace_all('box2text3', '') %>% \n #### Convert back to .svg\n  svgtools::read_svg(.) \n  \n# Save output\nsvgtools::write_svg(\n  graph_dbd_06, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_dbd_06.svg\"))\n\n\n\ngraph_dbd_07\n\n# Create graph\ngraph_dbd_07 <- graph_base_dbd %>% \n  toString() %>%\n  #### GROUP: Population\n   # Circles\n  stringr::str_replace_all('\"#00B050\"', '\"#04316A\"') %>% \n   # Label\n  stringr::str_replace(\"symbol1label\", \"Population\") %>%\n  #### GROUP: Construct\n    # Shape\n  stringr::str_replace_all('\"#FFFF00\"', '\"#04316A\"') %>% \n    # Label\n  stringr::str_replace('symbol2label', 'Konstrukt') %>% \n  #### GROUP: Text bubbles (Population and Construct)\n    # Shape\n  stringr::str_replace_all('\"#7F6000\"', '\"#7F600000\"') %>%  \n    # Text\n  stringr::str_replace(\"bubble1label1\", \"\") %>% \n  stringr::str_replace(\"bubble1label2\", \"\") %>%  \n  stringr::str_replace(\"bubble2label1\", \"\") %>% \n  stringr::str_replace(\"bubble2label2\", \"\") %>% \n  #### GROUP: Survey\n    # Symbol\n  stringr::str_replace_all('\"#70AD47\"', '\"#04316A\"') %>%  \n    # Label\n  stringr::str_replace_all('label_box_3', 'Survey') %>% \n  #### GROUP: Free Text(Survey)\n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff8080\"',\n    'style=\"fill:#ff808000\"') %>%  \n    # Text\n  stringr::str_replace(\"surveylabel1\", \"\") %>% \n  stringr::str_replace(\"surveylabel2\", \"\") %>% \n  stringr::str_replace(\"surveylabel3\", \"\") %>% \n  #### GROUP: Links (moved to avoid replacement of color)\n  # stringr::str_replace_all('\"#7F7F7F\"', '\"#7F7F7F\"') %>% # CHANGE color\n  #### GROUP: SNS Twitter\n    # Box & Symbol\n  stringr::str_replace_all('\"#00B0F0\"', '\"#04316A\"') %>% # \n    # Cirles\n  stringr::str_replace_all('\"#0066FF\"', '\"#7F7F7F\"') %>% #   \n  stringr::str_replace_all('\"#FF0000\"', '\"#04316A\"') %>% # \n    # Label\n  stringr::str_replace_all('User', '') %>% \n  #### GROUP: SNS Populations\n    # Boxes & Symbols\n  stringr::str_replace_all('\"#C55A11\"', '\"#04316A\"') %>% # \n    # Cirles\n  stringr::str_replace_all('\"#800000\"', '\"#7F7F7F\"') %>% #   \n  stringr::str_replace_all('\"#9900FF\"', '\"#04316A\"') %>% # \n  #### GROUP: SNS Population Textboxes\n    # Shape\n  stringr::str_replace_all('stroke=\"#7030A0\"','stroke=\"#E6002E\"') %>% # CHANGE stroke\n  stringr::str_replace_all('fill=\"#7030A0\"','fill=\"#FFFFFF\"') %>% # CHANGE fill\n    # Bulletpoints\n  stringr::str_replace_all('style=\"fill:#ff00ff\"','style=\"fill:#E6002E\"') %>% # CHANGE color\n    # Text\n    ## Box 1\n  stringr::str_replace_all('box1h1', 'Traces') %>% # CHANGE text\n  stringr::str_replace_all('box1text1', 'Tweet') %>% # CHANGE text\n  stringr::str_replace_all('box1text2', 'Retweet') %>% # CHANGE text\n  stringr::str_replace_all('box1text3', 'Like') %>% # CHANGE text\n  stringr::str_replace_all('box1text4', 'Reply') %>% # CHANGE text \n    ## Box 2 \n  stringr::str_replace_all('box2h1', 'Traces') %>% # CHANGE text\n  stringr::str_replace_all('box2text1', 'Queries') %>% # CHANGE text\n  stringr::str_replace_all('box2text2', 'Visits') %>% # CHANGE text\n  stringr::str_replace_all('box2text3', 'Standort') %>% # CHANGE text\n #### Convert back to .svg\n  svgtools::read_svg(.) \n  \n# Save output\nsvgtools::write_svg(\n  graph_dbd_07, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_dbd_07.svg\"))\n\n\n\ngraph_dbd_08\n\n# Create graph\ngraph_dbd_08 <- graph_base_dbd %>% \n  toString() %>%\n  #### GROUP: Population\n   # Circles\n  stringr::str_replace_all('\"#00B050\"', '\"#04316A\"') %>% \n   # Label\n  stringr::str_replace(\"symbol1label\", \"Population\") %>%\n  #### GROUP: Construct\n    # Shape\n  stringr::str_replace_all('\"#FFFF00\"', '\"#04316A\"') %>% \n    # Label\n  stringr::str_replace('symbol2label', 'Konstrukt') %>% \n  #### GROUP: Text bubbles (Population and Construct)\n    # Shape\n  stringr::str_replace_all('\"#7F6000\"', '\"#7F600000\"') %>%  \n    # Text\n  stringr::str_replace(\"bubble1label1\", \"\") %>% \n  stringr::str_replace(\"bubble1label2\", \"\") %>%  \n  stringr::str_replace(\"bubble2label1\", \"\") %>% \n  stringr::str_replace(\"bubble2label2\", \"\") %>% \n  #### GROUP: Survey\n    # Symbol\n  stringr::str_replace_all('\"#70AD47\"', '\"#70AD4700\"') %>% # HIDE symbol\n    # Label\n  stringr::str_replace_all('label_box_3', '') %>% # HIDE label\n  #### GROUP: Free Text(Survey)\n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff8080\"',\n    'style=\"fill:#ff808000\"') %>%  \n    # Text\n  stringr::str_replace(\"surveylabel1\", \"\") %>% \n  stringr::str_replace(\"surveylabel2\", \"\") %>% \n  stringr::str_replace(\"surveylabel3\", \"\") %>% \n  #### GROUP: Links (moved to avoid replacement of color)\n  stringr::str_replace_all('\"#7F7F7F\"', '\"#7F7F7F00\"') %>% # HIDE links\n  #### GROUP: SNS Twitter\n    # Box & Symbol\n  stringr::str_replace_all('\"#00B0F0\"', '\"#04316A\"') %>% # \n    # Cirles\n  stringr::str_replace_all('\"#0066FF\"', '\"#7F7F7F\"') %>% #   \n  stringr::str_replace_all('\"#FF0000\"', '\"#04316A\"') %>% # \n    # Label\n  stringr::str_replace_all('User', '') %>% \n  #### GROUP: SNS Populations\n    # Boxes & Symbols\n  stringr::str_replace_all('\"#C55A11\"', '\"#04316A\"') %>% # \n    # Cirles\n  stringr::str_replace_all('\"#800000\"', '\"#7F7F7F\"') %>% #   \n  stringr::str_replace_all('\"#9900FF\"', '\"#04316A\"') %>% # \n  #### GROUP: SNS Population Textboxes\n    # Shape\n  stringr::str_replace_all('\"#7030A0\"', '\"#7030A000\"') %>% # Hide shape\n    # Bulletpoints\n  stringr::str_replace_all('style=\"fill:#ff00ff\"', 'style=\"fill:#ff00ff00\"') %>% # Hide color\n    # Text\n    ## Box 1\n  stringr::str_replace_all('box1h1', '') %>% # Hide text\n  stringr::str_replace_all('box1text1', '') %>% # Hide text\n  stringr::str_replace_all('box1text2', '') %>% # Hide text\n  stringr::str_replace_all('box1text3', '') %>% # Hide text\n  stringr::str_replace_all('box1text4', '') %>% # Hide text\n    ## Box 2 \n  stringr::str_replace_all('box2h1', '') %>% # Hide text\n  stringr::str_replace_all('box2text1', '') %>% # Hide text\n  stringr::str_replace_all('box2text2', '') %>% # Hide text\n  stringr::str_replace_all('box2text3', '') %>% # Hide text\n #### Convert back to .svg\n  svgtools::read_svg(.) \n  \n# Save output\nsvgtools::write_svg(\n  graph_dbd_08, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_dbd_08.svg\"))\n\n\n\ngraph_dbd_09\n\n# Create graph\ngraph_dbd_09 <- graph_base_dbd %>% \n  toString() %>%\n  #### GROUP: Population\n   # Circles\n  stringr::str_replace_all('\"#00B050\"', '\"#04316A20\"') %>% # APLHA circles\n   # Label\n  stringr::str_replace(\"symbol1label\", \"Population\") %>%\n  #### GROUP: Construct\n    # Shape\n  stringr::str_replace_all('\"#FFFF00\"', '\"#04316A\"') %>% \n    # Label\n  stringr::str_replace('symbol2label', 'Konstrukt') %>% \n  #### GROUP: Text bubbles (Population and Construct)\n    # Shape\n  stringr::str_replace_all('stroke=\"#7F6000\"','stroke=\"#E6002E\"') %>% # CHANGE stroke\n  stringr::str_replace_all('fill=\"#7F6000\"', 'fill=\"#ffffff\"') %>% # CHANGE fill\n    # Text\n  stringr::str_replace(\"bubble1label1\", \"Alle deutschsprachigen\") %>% # CHANGE text\n  stringr::str_replace(\"bubble1label2\", \"Twitter-Nutzer*Innen\") %>% # CHANGE text \n  stringr::str_replace(\"bubble2label1\", \"Empf√§nglichkeit\") %>% # CHANGE text\n  stringr::str_replace(\"bubble2label2\", \"f√ºr Fake News\") %>% # CHANGE text \n  #### GROUP: Survey\n    # Symbol\n  stringr::str_replace_all('\"#70AD47\"', '\"#70AD4700\"') %>% \n    # Label\n  stringr::str_replace_all('label_box_3', '') %>%\n  #### GROUP: Free Text(Survey)\n    # Bulletpoints\n  stringr::str_replace_all(\n    'style=\"fill:#ff8080\"',\n    'style=\"fill:#ff808000\"') %>%  \n    # Text\n  stringr::str_replace(\"surveylabel1\", \"\") %>% \n  stringr::str_replace(\"surveylabel2\", \"\") %>% \n  stringr::str_replace(\"surveylabel3\", \"\") %>% \n  #### GROUP: Links (moved to avoid replacement of color)\n  stringr::str_replace_all('\"#7F7F7F\"', '\"#7F7F7F00\"') %>% \n  #### GROUP: SNS Twitter\n    # Box & Symbol\n  # stringr::str_replace_all('\"#00B0F0\"', '\"#04316A\"') %>% # \n    # Cirles\n  stringr::str_replace_all('\"#0066FF\"', '\"#E6002E\"') %>% #   \n  stringr::str_replace_all('\"#FF0000\"', '\"#0066FF\"') %>% # \n    # Label\n  stringr::str_replace_all('User', '') %>% \n  #### GROUP: SNS Populations\n    # Boxes & Symbols\n  stringr::str_replace_all('\"#C55A11\"', '\"#04316A\"') %>% # \n    # Cirles\n  stringr::str_replace_all('\"#800000\"', '\"#7F7F7F\"') %>% #   \n  stringr::str_replace_all('\"#9900FF\"', '\"#04316A\"') %>% # \n  #### GROUP: SNS Population Textboxes\n    # Shape\n  stringr::str_replace_all('\"#7030A0\"', '\"#7030A000\"') %>% \n    # Bulletpoints\n  stringr::str_replace_all('style=\"fill:#ff00ff\"', 'style=\"fill:#ff00ff00\"') %>% \n    # Text\n    ## Box 1\n  stringr::str_replace_all('box1h1', '') %>% \n  stringr::str_replace_all('box1text1', '') %>% \n  stringr::str_replace_all('box1text2', '') %>% \n  stringr::str_replace_all('box1text3', '') %>% \n  stringr::str_replace_all('box1text4', '') %>% \n    ## Box 2 \n  stringr::str_replace_all('box2h1', '') %>% \n  stringr::str_replace_all('box2text1', '') %>% \n  stringr::str_replace_all('box2text2', '') %>% \n  stringr::str_replace_all('box2text3', '') %>% \n #### Convert back to .svg\n  svgtools::read_svg(.) \n  \n# Save output\nsvgtools::write_svg(\n  graph_dbd_09, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_dbd_09.svg\"))"
  },
  {
    "objectID": "content/03-dbd-data_collection/slides/scripts/graph_creation.html#api",
    "href": "content/03-dbd-data_collection/slides/scripts/graph_creation.html#api",
    "title": "graph_creation",
    "section": "API",
    "text": "API\n\nGet base graphic\n\ngraph_base_api <- svgtools::read_svg(\n  here(\"content/03-dbd-data_collection/slides/graphs/graph_api-01_base.svg\")) \n\n\n\ngraph_api_01\n\ngraph_api_01 <- graph_base_api %>% \n  toString() %>%\n  #### GROUP 1: programmer\n  stringr::str_replace_all('\"#FF0000\"', '\"#E6002E\"') %>% # CHANGE color\n  #### GROUP 2: server\n  stringr::str_replace_all('\"#FFC000\"', '\"#FFC00000\"') %>% # CHANGE color\n  #### GROUP 3: reference\n  stringr::str_replace_all('\"#92D050\"', '\"#92D05000\"') %>% # CHANGE color\n  #### GROUP 4: developer\n  stringr::str_replace_all('\"#00B050\"', '\"#00B05000\"') %>% # CHANGE color \n  #### GROUP 5: client\n  stringr::str_replace_all('\"#00B0F0\"', '\"#00B0F000\"') %>% # CHANGE color\n  #### GROUP 6: cloud\n  stringr::str_replace_all('\"#0070C0\"', '\"#0070C000\"') %>% # CHANGE color\n  #### Convert back to .svg\n  svgtools::read_svg(.) \n\n# Save output\nsvgtools::write_svg(\n  graph_api_01, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_api_01.svg\"))\n\n\n\ngraph_api_02\n\ngraph_api_02 <- graph_base_api %>% \n  toString() %>%\n  #### GROUP 1: programmer\n  stringr::str_replace_all('\"#FF0000\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 2: server\n  stringr::str_replace_all('\"#FFC000\"', '\"#E6002E\"') %>% # CHANGE color\n  #### GROUP 3: reference\n  stringr::str_replace_all('\"#92D050\"', '\"#92D05000\"') %>% # CHANGE color\n  #### GROUP 4: developer\n  stringr::str_replace_all('\"#00B050\"', '\"#00B05000\"') %>% # CHANGE color \n  #### GROUP 5: client\n  stringr::str_replace_all('\"#00B0F0\"', '\"#00B0F000\"') %>% # CHANGE color\n  #### GROUP 6: cloud\n  stringr::str_replace_all('\"#0070C0\"', '\"#0070C000\"') %>% # CHANGE color\n  #### Convert back to .svg\n  svgtools::read_svg(.) \n\n# Save output\nsvgtools::write_svg(\n  graph_api_02, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_api_02.svg\"))\n\n\n\ngraph_api_03\n\ngraph_api_03 <- graph_base_api %>% \n  toString() %>%\n  #### GROUP 1: programmer\n  stringr::str_replace_all('\"#FF0000\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 2: server\n  stringr::str_replace_all('\"#FFC000\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 3: reference\n  stringr::str_replace_all('\"#92D050\"', '\"#E6002E\"') %>% # CHANGE color\n  #### GROUP 4: developer\n  stringr::str_replace_all('\"#00B050\"', '\"#00B05000\"') %>% # CHANGE color \n  #### GROUP 5: client\n  stringr::str_replace_all('\"#00B0F0\"', '\"#00B0F000\"') %>% # CHANGE color\n  #### GROUP 6: cloud\n  stringr::str_replace_all('\"#0070C0\"', '\"#0070C000\"') %>% # CHANGE color\n  #### Convert back to .svg\n  svgtools::read_svg(.) \n\n# Save output\nsvgtools::write_svg(\n  graph_api_03, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_api_03.svg\"))\n\n\n\ngraph_api_04\n\ngraph_api_04 <- graph_base_api %>% \n  toString() %>%\n  #### GROUP 1: programmer\n  stringr::str_replace_all('\"#FF0000\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 2: server\n  stringr::str_replace_all('\"#FFC000\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 3: reference\n  stringr::str_replace_all('\"#92D050\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 4: developer\n  stringr::str_replace_all('\"#00B050\"', '\"#E6002E\"') %>% # CHANGE color \n  #### GROUP 5: client\n  stringr::str_replace_all('\"#00B0F0\"', '\"#00B0F000\"') %>% # CHANGE color\n  #### GROUP 6: cloud\n  stringr::str_replace_all('\"#0070C0\"', '\"#0070C000\"') %>% # CHANGE color\n  #### Convert back to .svg\n  svgtools::read_svg(.) \n\n# Save output\nsvgtools::write_svg(\n  graph_api_04, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_api_04.svg\"))\n\n\n\ngraph_api_05\n\ngraph_api_05 <- graph_base_api %>% \n  toString() %>%\n  #### GROUP 1: programmer\n  stringr::str_replace_all('\"#FF0000\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 2: server\n  stringr::str_replace_all('\"#FFC000\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 3: reference\n  stringr::str_replace_all('\"#92D050\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 4: developer\n  stringr::str_replace_all('\"#00B050\"', '\"#04316A\"') %>% # CHANGE color \n  #### GROUP 5: client\n  stringr::str_replace_all('\"#00B0F0\"', '\"#E6002E\"') %>% # CHANGE color\n  #### GROUP 6: cloud\n  stringr::str_replace_all('\"#0070C0\"', '\"#0070C000\"') %>% # CHANGE color\n  #### Convert back to .svg\n  svgtools::read_svg(.) \n\n# Save output\nsvgtools::write_svg(\n  graph_api_05, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_api_05.svg\"))\n\n\n\ngraph_api_06\n\ngraph_api_06 <- graph_base_api %>% \n  toString() %>%\n  #### GROUP 1: programmer\n  stringr::str_replace_all('\"#FF0000\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 2: server\n  stringr::str_replace_all('\"#FFC000\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 3: reference\n  stringr::str_replace_all('\"#92D050\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 4: developer\n  stringr::str_replace_all('\"#00B050\"', '\"#04316A\"') %>% # CHANGE color \n  #### GROUP 5: client\n  stringr::str_replace_all('\"#00B0F0\"', '\"#04316A\"') %>% # CHANGE color\n  #### GROUP 6: cloud\n  stringr::str_replace_all('\"#0070C0\"', '\"#E6002E\"') %>% # CHANGE color\n  #### Convert back to .svg\n  svgtools::read_svg(.) \n\n# Save output\nsvgtools::write_svg(\n  graph_api_06, \n  here(\"content/03-dbd-data_collection/slides/graphs/graph_api_06.svg\"))"
  },
  {
    "objectID": "content/04-api_access-twitter/04-exercise.html",
    "href": "content/04-api_access-twitter/04-exercise.html",
    "title": "Showcase",
    "section": "",
    "text": "library(academictwitteR) # Collecting the data\nlibrary(tidyverse) # Preparation of the data\nlibrary(quanteda) # Text mining\nlibrary(quanteda.textstats) # Text statistics\nlibrary(quanteda.textplots) # Visualisation of text data\nlibrary(here)\nlibrary(sjmisc)\nlibrary(lubridate)\nlibrary(ggthemes)\nlibrary(ggpubr)"
  },
  {
    "objectID": "content/04-api_access-twitter/04-exercise.html#set-personal-bearer-token",
    "href": "content/04-api_access-twitter/04-exercise.html#set-personal-bearer-token",
    "title": "Showcase",
    "section": "Set personal bearer token",
    "text": "Set personal bearer token\n\npersonal_bearer_token <- \"INSERT BEARER TOKEN HERE\""
  },
  {
    "objectID": "content/04-api_access-twitter/04-exercise.html#mining-tweets-hashtags",
    "href": "content/04-api_access-twitter/04-exercise.html#mining-tweets-hashtags",
    "title": "Showcase",
    "section": "Mining tweets: hashtag(s)",
    "text": "Mining tweets: hashtag(s)\n\nData collection\n\nget_all_tweets(\n    query = \"#Karneval\", \n    start_tweets = \"2022-11-11T00:00:00Z\",\n    end_tweets = \"2022-11-13T12:00:00Z\",\n    file = \"karneval\",\n    data_path = \"data/raw_karneval/\",\n    n = 100000,\n    #bearer_token = personal_bearer_token\n  )\n\n\nRead data from disc\n\ntweets_karneval <- bind_tweets(\n  data_path = here(\"content/04-api_access-twitter/data/raw_karneval\"),\n  output_format = \"tidy\") %>% \n    mutate(\n    datetime = ymd_hms(created_at),\n    date = date(datetime),\n    hour = hour(datetime),\n    min  = minute(datetime),\n    hms  = hms::as_hms(datetime),\n    hm   = hms::parse_hm(hms)\n  )\n\n\n\n\nData analysis\n\nOverview of dataset\n\ntweets_karneval %>% glimpse\n\nRows: 2,637\nColumns: 37\n$ tweet_id               <chr> \"1590981439457464321\", \"1590981390123892740\", \"‚Ä¶\n$ user_username          <chr> \"truthonearth3\", \"Auno94\", \"HaiAriane\", \"ElCobr‚Ä¶\n$ text                   <chr> \"RT @faqyoutoo: Ab heute 11:11 h d√ºrfen wir uns‚Ä¶\n$ created_at             <chr> \"2022-11-11T08:15:08.000Z\", \"2022-11-11T08:14:5‚Ä¶\n$ lang                   <chr> \"de\", \"de\", \"de\", \"und\", \"und\", \"und\", \"und\", \"‚Ä¶\n$ possibly_sensitive     <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE,‚Ä¶\n$ author_id              <chr> \"1486309822832287746\", \"2745840416\", \"995739344‚Ä¶\n$ source                 <chr> \"Twitter for Android\", \"Twitter for Android\", \"‚Ä¶\n$ conversation_id        <chr> \"1590981439457464321\", \"1590981390123892740\", \"‚Ä¶\n$ in_reply_to_user_id    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ user_protected         <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE‚Ä¶\n$ user_description       <chr> \"I‚ô•Ô∏èTrump\\nAnd Trump ‚ô•Ô∏èUS.\", \"Zertifizierter Alma‚Ä¶\n$ user_profile_image_url <chr> \"https://pbs.twimg.com/profile_images/158736121‚Ä¶\n$ user_pinned_tweet_id   <chr> \"1591132482271080448\", \"1346065459297267712\", N‚Ä¶\n$ user_verified          <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE‚Ä¶\n$ user_name              <chr> \"truthonearth\", \"Auno\", \"Pirschelb√§r\", \"Michael‚Ä¶\n$ user_created_at        <chr> \"2022-01-26T12:07:54.000Z\", \"2014-08-19T17:42:0‚Ä¶\n$ user_location          <chr> NA, \"K√∂ln, Deutschland\", NA, \"Bonn, Germany\", N‚Ä¶\n$ user_url               <chr> NA, \"https://t.co/lodH0xUg0C\", NA, NA, NA, NA, ‚Ä¶\n$ retweet_count          <int> 2, 0, 0, 178, 178, 178, 178, 178, 178, 178, 178‚Ä¶\n$ like_count             <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,‚Ä¶\n$ quote_count            <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,‚Ä¶\n$ user_tweet_count       <int> 840, 5851, 495, 110593, 5045, 1351, 932, 29967,‚Ä¶\n$ user_list_count        <int> 0, 0, 0, 77, 0, 1, 1, 0, 0, 1, 1, 5, 3, 73, 18,‚Ä¶\n$ user_followers_count   <int> 268, 197, 18, 1260, 54, 109, 71, 372, 126, 145,‚Ä¶\n$ user_following_count   <int> 1102, 1124, 118, 476, 436, 403, 411, 748, 1339,‚Ä¶\n$ sourcetweet_type       <chr> \"retweeted\", NA, NA, \"retweeted\", \"retweeted\", ‚Ä¶\n$ sourcetweet_id         <chr> \"1590967777762086912\", NA, NA, \"159097615399271‚Ä¶\n$ sourcetweet_text       <chr> \"Ab heute 11:11 h d√ºrfen wir uns wieder verklei‚Ä¶\n$ sourcetweet_lang       <chr> \"de\", NA, NA, \"und\", \"und\", \"und\", \"und\", \"und\"‚Ä¶\n$ sourcetweet_author_id  <chr> \"946619921454247937\", NA, NA, \"529561909\", \"529‚Ä¶\n$ datetime               <dttm> 2022-11-11 08:15:08, 2022-11-11 08:14:57, 2022‚Ä¶\n$ date                   <date> 2022-11-11, 2022-11-11, 2022-11-11, 2022-11-11‚Ä¶\n$ hour                   <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,‚Ä¶\n$ min                    <int> 15, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 12,‚Ä¶\n$ hms                    <time> 08:15:08, 08:14:57, 08:14:29, 08:14:29, 08:13:‚Ä¶\n$ hm                     <time> 08:15:00, 08:14:00, 08:14:00, 08:14:00, 08:13:‚Ä¶\n\n\n\n\nLanguage of tweets\n\nfrq(tweets_karneval$lang, sort.frq = \"desc\")\n\nx <character> \n# total N=2637 valid N=2637 mean=6.85 sd=5.06\n\nValue |    N | Raw % | Valid % | Cum. %\n---------------------------------------\nde    | 2180 | 82.67 |   82.67 |  82.67\nund   |  201 |  7.62 |    7.62 |  90.29\nen    |  112 |  4.25 |    4.25 |  94.54\nqme   |   43 |  1.63 |    1.63 |  96.17\nes    |   18 |  0.68 |    0.68 |  96.85\ntr    |   10 |  0.38 |    0.38 |  97.23\nfr    |    9 |  0.34 |    0.34 |  97.57\nnl    |    9 |  0.34 |    0.34 |  97.91\npl    |    8 |  0.30 |    0.30 |  98.22\nin    |    7 |  0.27 |    0.27 |  98.48\nno    |    7 |  0.27 |    0.27 |  98.75\nqht   |    6 |  0.23 |    0.23 |  98.98\nca    |    5 |  0.19 |    0.19 |  99.17\nda    |    4 |  0.15 |    0.15 |  99.32\ncs    |    3 |  0.11 |    0.11 |  99.43\neu    |    3 |  0.11 |    0.11 |  99.54\nfi    |    3 |  0.11 |    0.11 |  99.66\ncy    |    2 |  0.08 |    0.08 |  99.73\net    |    2 |  0.08 |    0.08 |  99.81\nja    |    2 |  0.08 |    0.08 |  99.89\nlt    |    2 |  0.08 |    0.08 |  99.96\nis    |    1 |  0.04 |    0.04 | 100.00\n<NA>  |    0 |  0.00 |    <NA> |   <NA>\n\n\n\n\nTweets over time\n\ntweets_karneval %>% \n  ggplot(aes(hour)) +\n  geom_bar() +\n  facet_grid(cols = vars(date)) +\n  theme_pubr()\n\n\n\n\n\n\nMost frequent time (HH:MM) of sending tweets\n\ntweets_karneval %>%\n  frq(hm,\n      sort.frq = \"desc\", \n      min.frq = 10)\n\nhm <numeric> \n# total N=2637 valid N=2637 mean=48463.12 sd=16629.59\n\nValue    |    N | Raw % | Valid % | Cum. %\n------------------------------------------\n10:11:00 |   59 |  2.24 |    2.24 |   2.24\n10:12:00 |   14 |  0.53 |    0.53 |   2.77\n10:13:00 |   12 |  0.46 |    0.46 |   3.22\n16:54:00 |   12 |  0.46 |    0.46 |   3.68\n10:10:00 |   10 |  0.38 |    0.38 |   4.06\n11:29:00 |   10 |  0.38 |    0.38 |   4.44\n16:53:00 |   10 |  0.38 |    0.38 |   4.82\nn < 10   | 2510 | 95.18 |   95.18 | 100.00\n<NA>     |    0 |  0.00 |    <NA> |   <NA>\n\n\n\n\nUser with the most tweets\n\ntweets_karneval %>% \n  frq(user_username,\n      sort.frq = \"desc\", \n      min.frq = 5)\n\nuser_username <character> \n# total N=2637 valid N=2637 mean=976.88 sd=562.18\n\nValue           |    N | Raw % | Valid % | Cum. %\n-------------------------------------------------\nGun17170309     |   65 |  2.46 |    2.46 |   2.46\nberlinaffaires  |   28 |  1.06 |    1.06 |   3.53\nBeratungszimmer |   19 |  0.72 |    0.72 |   4.25\nbartl_katrin    |   16 |  0.61 |    0.61 |   4.85\nrammwars        |   15 |  0.57 |    0.57 |   5.42\nfree_cart9      |   12 |  0.46 |    0.46 |   5.88\nploetschkoepp   |   12 |  0.46 |    0.46 |   6.33\nKespelHelau     |   11 |  0.42 |    0.42 |   6.75\nkryptomania84   |   10 |  0.38 |    0.38 |   7.13\nneussentweetet  |   10 |  0.38 |    0.38 |   7.51\nRaissoussama1   |   10 |  0.38 |    0.38 |   7.89\nRaissRaiss2     |    9 |  0.34 |    0.34 |   8.23\nexpress24       |    8 |  0.30 |    0.30 |   8.53\npolizei_nrw_k   |    8 |  0.30 |    0.30 |   8.84\nhedonist_redux  |    7 |  0.27 |    0.27 |   9.10\nPfantomaus      |    7 |  0.27 |    0.27 |   9.37\nrudibruns       |    7 |  0.27 |    0.27 |   9.63\nWDRaktuell      |    7 |  0.27 |    0.27 |   9.90\nGermanAtPompey  |    6 |  0.23 |    0.23 |  10.13\nIamIllgner      |    6 |  0.23 |    0.23 |  10.35\nMadameK_tweetet |    6 |  0.23 |    0.23 |  10.58\nStreamDESupport |    6 |  0.23 |    0.23 |  10.81\ntonight_news    |    6 |  0.23 |    0.23 |  11.04\nTrendsanalysed  |    6 |  0.23 |    0.23 |  11.26\narnohb112       |    5 |  0.19 |    0.19 |  11.45\ncarsten_fiedler |    5 |  0.19 |    0.19 |  11.64\ndieBasisKoeln   |    5 |  0.19 |    0.19 |  11.83\nDieFRAKTIONKoln |    5 |  0.19 |    0.19 |  12.02\nHeike_T_        |    5 |  0.19 |    0.19 |  12.21\nHowie591        |    5 |  0.19 |    0.19 |  12.40\njoergprante     |    5 |  0.19 |    0.19 |  12.59\nJoker_6278      |    5 |  0.19 |    0.19 |  12.78\nKSTA            |    5 |  0.19 |    0.19 |  12.97\nlibertaeredeju  |    5 |  0.19 |    0.19 |  13.16\nMarktzyniker    |    5 |  0.19 |    0.19 |  13.35\nMieterV         |    5 |  0.19 |    0.19 |  13.54\nmuesztaerrieh   |    5 |  0.19 |    0.19 |  13.73\nTrixiMaus502    |    5 |  0.19 |    0.19 |  13.92\nwieichfm        |    5 |  0.19 |    0.19 |  14.11\nn < 5           | 2265 | 85.89 |   85.89 | 100.00\n<NA>            |    0 |  0.00 |    <NA> |   <NA>\n\n\n\n\nDisplay tweets from most freuquent users\n\ntweets_karneval %>% \n  filter(user_username == \"Gun17170309\") %$% \n  glue::glue(\n    \"Tweet-ID: {tweet_id} \n    Inhalt:\n    {text}\\n\\n\") %>% \n  head()\n\nTweet-ID: 1591125966809878528 \nInhalt:\n#F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\nhttps://t.co/peg7JWAKdN\nKarnevals-Klassiker: Rheinische Krapfenü§° https://t.co/Am7A84C4Dj\n\nTweet-ID: 1591120408102961153 \nInhalt:\nRT @Gun17170309: #F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\nhttps://t.co/vZxzhaeUNY\nFasching Berlinerüòã h‚Ä¶\n\nTweet-ID: 1591120391904587777 \nInhalt:\nRT @Gun17170309: #F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\nhttps://t.co/6XKwts10gk\nT√§t√§-T√§t√§ ‚Äì Das Karn‚Ä¶\n\nTweet-ID: 1591120367321419776 \nInhalt:\nRT @Gun17170309: #F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\nSo schnell gehen Berliner, Kreppel, Krapfenr‚Ä¶\n\nTweet-ID: 1591120292436643840 \nInhalt:\n#F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\nSo schnell gehen Berliner, Kreppel, Krapfenr√§ppel, Pfannkuchen, Krapfen,\nin Frankreich: ‚ÄûBoule de Berlin‚Äú\nin England ‚ÄûJelly Doughnut‚Äú\n. . . einfach selber backen, lecker!\nhttps://t.co/mw3W1iynuL https://t.co/WQ45iMavLn\n\nTweet-ID: 1591119195928166400 \nInhalt:\nRT @Gun17170309: https://t.co/mw3W1igegD \n#F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\n\n\n\ntweets_karneval %>% \n  filter(user_username == \"berlinaffaires\") %$% \n  glue::glue(\n    \"Tweet-ID: {tweet_id} \n    Inhalt:\n    {text}\\n\\n\") %>% \n  head()\n\nTweet-ID: 1591076515110060033 \nInhalt:\nRT @berlinaffaires: #HauptstadtStudio #SanktMartin #Karneval #Fastnacht #Fasching #ElfteElfte der Himmel √ºber Berlin\nLuftrettung Christoph‚Ä¶\n\nTweet-ID: 1591076479663624192 \nInhalt:\n#HauptstadtStudio #SanktMartin #Karneval #Fastnacht #Fasching #ElfteElfte der Himmel √ºber Berlin\nLuftrettung Christoph Callsign fliegt immer noch hin und her #DHXCA #CHX31 #H135 #MASH #HelicopterSpotting https://t.co/OETymAoOL1\n\nTweet-ID: 1591055201598701568 \nInhalt:\nRT @berlinaffaires: #HauptstadtStudio #SanktMartin #Karneval #Fastnacht #Fasching #ElfteElfte der Himmel √ºber Berlin\nLuftrettung Christoph‚Ä¶\n\nTweet-ID: 1591055143579004928 \nInhalt:\n#HauptstadtStudio #SanktMartin #Karneval #Fastnacht #Fasching #ElfteElfte der Himmel √ºber Berlin\nLuftrettung Christoph Callsign #DHXCA #CHX31 #H135 #MASH #HelicopterSpotting #Funkturm https://t.co/jv22RwAgS9\n\nTweet-ID: 1591043114181218306 \nInhalt:\nRT @DresdenNews: #Karneval im #PieschenerRathaus: Am 11.11 √ºbernehmen um 11:11 Uhr die #N√§rrinnen und #Narren der Initiative Karneval in #P‚Ä¶\n\nTweet-ID: 1591042750408929280 \nInhalt:\nRT @bernhardboeth: @hessenschau Was haben wir den ganzen Vormittag auf diesen Moment hingefiebert #Fasching #Fastnacht #Karneval https://t.‚Ä¶"
  },
  {
    "objectID": "content/04-api_access-twitter/04-exercise.html#mining-tweets-profiles",
    "href": "content/04-api_access-twitter/04-exercise.html#mining-tweets-profiles",
    "title": "Showcase",
    "section": "Mining tweets: profile(s)",
    "text": "Mining tweets: profile(s)\n\nData collection\n\nget_all_tweets(\n    users = c(\"elonmusk\"),\n    start_tweets = \"2020-11-11T00:00:00Z\",\n    end_tweets = \"2022-11-13T12:00:00Z\",\n    file = \"elonmusk\",\n    data_path = here(\"content/04-api_access-twitter/data/raw_elonmusk/\"),\n    n = 100000,\n    bearer_token = personal_bearer_token\n  )\n\n\nRead data from disc\n\ntweets_musk <- bind_tweets(\n  data_path = here(\"content/04-api_access-twitter/data/raw_elonmusk\"),\n  # data_path = \"data/raw_karneval\",\n  output_format = \"tidy\") %>% \n    mutate(\n    datetime = ymd_hms(created_at),\n    date = date(datetime),\n    hour = hour(datetime),\n    min  = minute(datetime),\n    hms  = hms::as_hms(datetime),\n    hm   = hms::parse_hm(hms)\n  )\n\n\n\n\nData analysis\n\nOverview of dataset\n\ntweets_musk %>% glimpse\n\nRows: 7,255\nColumns: 37\n$ tweet_id               <chr> \"1336809767574982658\", \"1336808486022258688\", \"‚Ä¶\n$ user_username          <chr> \"elonmusk\", \"elonmusk\", \"elonmusk\", \"elonmusk\",‚Ä¶\n$ text                   <chr> \"Fuel header tank pressure was low during landi‚Ä¶\n$ conversation_id        <chr> \"1336808486022258688\", \"1336808486022258688\", \"‚Ä¶\n$ author_id              <chr> \"44196397\", \"44196397\", \"44196397\", \"44196397\",‚Ä¶\n$ in_reply_to_user_id    <chr> \"44196397\", NA, \"4914384040\", \"3101588527\", \"34‚Ä¶\n$ source                 <chr> \"Twitter for iPhone\", \"Twitter for iPhone\", \"Tw‚Ä¶\n$ possibly_sensitive     <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE‚Ä¶\n$ created_at             <chr> \"2020-12-09T23:07:39.000Z\", \"2020-12-09T23:02:3‚Ä¶\n$ lang                   <chr> \"en\", \"en\", \"und\", \"en\", \"en\", \"en\", \"en\", \"en\"‚Ä¶\n$ user_created_at        <chr> \"2009-06-02T20:12:29.000Z\", \"2009-06-02T20:12:2‚Ä¶\n$ user_description       <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",‚Ä¶\n$ user_profile_image_url <chr> \"https://pbs.twimg.com/profile_images/159096873‚Ä¶\n$ user_name              <chr> \"Elon Musk\", \"Elon Musk\", \"Elon Musk\", \"Elon Mu‚Ä¶\n$ user_protected         <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE‚Ä¶\n$ user_verified          <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,‚Ä¶\n$ user_location          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ user_url               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ user_pinned_tweet_id   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ retweet_count          <int> 6987, 9775, 349, 348, 1055, 7732, 10719, 324, 5‚Ä¶\n$ like_count             <int> 96961, 106142, 15267, 13204, 22581, 0, 170964, ‚Ä¶\n$ quote_count            <int> 2027, 2953, 93, 111, 177, 0, 5106, 92, 143, 12,‚Ä¶\n$ user_tweet_count       <int> 20290, 20290, 20290, 20290, 20290, 20290, 20290‚Ä¶\n$ user_list_count        <int> 102027, 102027, 102027, 102027, 102027, 102027,‚Ä¶\n$ user_followers_count   <int> 115405919, 115405919, 115405919, 115405919, 115‚Ä¶\n$ user_following_count   <int> 130, 130, 130, 130, 130, 130, 130, 130, 130, 13‚Ä¶\n$ sourcetweet_type       <chr> NA, \"quoted\", NA, NA, NA, \"retweeted\", NA, NA, ‚Ä¶\n$ sourcetweet_id         <chr> NA, \"1336777137391456256\", NA, NA, NA, \"1336349‚Ä¶\n$ sourcetweet_text       <chr> NA, \"Watch Starship high-altitude test live ‚Üí h‚Ä¶\n$ sourcetweet_lang       <chr> NA, \"en\", NA, NA, NA, \"en\", NA, NA, NA, NA, \"en‚Ä¶\n$ sourcetweet_author_id  <chr> NA, \"34743251\", NA, NA, NA, \"34743251\", NA, NA,‚Ä¶\n$ datetime               <dttm> 2020-12-09 23:07:39, 2020-12-09 23:02:34, 2020‚Ä¶\n$ date                   <date> 2020-12-09, 2020-12-09, 2020-12-09, 2020-12-08‚Ä¶\n$ hour                   <int> 23, 23, 18, 18, 16, 16, 16, 2, 2, 0, 22, 20, 18‚Ä¶\n$ min                    <int> 7, 2, 13, 5, 57, 55, 44, 51, 50, 16, 16, 13, 14‚Ä¶\n$ hms                    <time> 23:07:39, 23:02:34, 18:13:21, 18:05:28, 16:57:‚Ä¶\n$ hm                     <time> 23:07:00, 23:02:00, 18:13:00, 18:05:00, 16:57:‚Ä¶\n\n\n\n\nTweets over time\n\ntweets_musk %>% \n  ggplot(aes(date)) +\n  geom_bar() +\n  theme_pubr()\n\n\n\n\n\n\nTweets with the most likes\n\ntweets_musk %>% \n  filter(is.na(sourcetweet_type)) %>% \n  arrange(-like_count) %>% \n  select(text, created_at, like_count) %>% \n  head(10)\n\n# A tibble: 10 √ó 3\n   text                                                          creat‚Ä¶¬π like_‚Ä¶¬≤\n   <chr>                                                         <chr>     <int>\n 1 \"Next I‚Äôm buying Coca-Cola to put the cocaine back in\"        2022-0‚Ä¶ 4767770\n 2 \"I hope that even my worst critics remain on Twitter, becaus‚Ä¶ 2022-0‚Ä¶ 3221746\n 3 \"Let‚Äôs make Twitter maximum fun!\"                             2022-0‚Ä¶ 2641791\n 4 \"\\U0001f680\\U0001f4ab‚ô•Ô∏è Yesss!!! ‚ô•Ô∏è\\U0001f4ab\\U0001f680 https:‚Ä¶ 2022-0‚Ä¶ 2599811\n 5 \"Listen, I can‚Äôt do miracles ok https://t.co/z7dvLMUXy8\"      2022-0‚Ä¶ 2572036\n 6 \"the bird is freed\"                                           2022-1‚Ä¶ 2497902\n 7 \"Comedy is now legal on Twitter\"                              2022-1‚Ä¶ 2400045\n 8 \"https://t.co/kGncG7Hs3M\"                                     2022-1‚Ä¶ 1893281\n 9 \"If I die under mysterious circumstances, it‚Äôs been nice kno‚Ä¶ 2022-0‚Ä¶ 1891028\n10 \"The extreme antibody reaction from those who fear free spee‚Ä¶ 2022-0‚Ä¶ 1647281\n# ‚Ä¶ with abbreviated variable names ¬π‚Äãcreated_at, ¬≤‚Äãlike_count\n\n\n\n\nTweets with the most retweets\n\ntweets_musk %>% \n  filter(is.na(sourcetweet_type)) %>% \n  arrange(-retweet_count) %>% \n  select(text, created_at, retweet_count) %>% \n  head(10)\n\n# A tibble: 10 √ó 3\n   text                                                          creat‚Ä¶¬π retwe‚Ä¶¬≤\n   <chr>                                                         <chr>     <int>\n 1 \"Next I‚Äôm buying Coca-Cola to put the cocaine back in\"        2022-0‚Ä¶  679688\n 2 \"I hope that even my worst critics remain on Twitter, becaus‚Ä¶ 2022-0‚Ä¶  366807\n 3 \"the bird is freed\"                                           2022-1‚Ä¶  357937\n 4 \"\\U0001f680\\U0001f4ab‚ô•Ô∏è Yesss!!! ‚ô•Ô∏è\\U0001f4ab\\U0001f680 https:‚Ä¶ 2022-0‚Ä¶  346717\n 5 \"Comedy is now legal on Twitter\"                              2022-1‚Ä¶  261224\n 6 \"Listen, I can‚Äôt do miracles ok https://t.co/z7dvLMUXy8\"      2022-0‚Ä¶  212059\n 7 \"https://t.co/Q9OjlJhi7f\"                                     2022-0‚Ä¶  207978\n 8 \"Let‚Äôs make Twitter maximum fun!\"                             2022-0‚Ä¶  193913\n 9 \"The extreme antibody reaction from those who fear free spee‚Ä¶ 2022-0‚Ä¶  191983\n10 \"Entering Twitter HQ ‚Äì let that sink in! https://t.co/D68z4K‚Ä¶ 2022-1‚Ä¶  190507\n# ‚Ä¶ with abbreviated variable names ¬π‚Äãcreated_at, ¬≤‚Äãretweet_count\n\n\n\n\nProportion of tweets\n\ntweets_musk %>% \n  frq(sourcetweet_type)\n\nsourcetweet_type <character> \n# total N=7255 valid N=489 mean=1.74 sd=0.44\n\nValue     |    N | Raw % | Valid % | Cum. %\n-------------------------------------------\nquoted    |  125 |  1.72 |   25.56 |  25.56\nretweeted |  364 |  5.02 |   74.44 | 100.00\n<NA>      | 6766 | 93.26 |    <NA> |   <NA>\n\n\n\n\nLanguate of tweets\n\ntweets_musk %>% \n  frq(lang)\n\nlang <character> \n# total N=7255 valid N=7255 mean=14.37 sd=9.86\n\nValue |    N | Raw % | Valid % | Cum. %\n---------------------------------------\nar    |    2 |  0.03 |    0.03 |   0.03\nart   |   12 |  0.17 |    0.17 |   0.19\nbg    |    1 |  0.01 |    0.01 |   0.21\nca    |   10 |  0.14 |    0.14 |   0.34\ncs    |    1 |  0.01 |    0.01 |   0.36\ncy    |    1 |  0.01 |    0.01 |   0.37\nda    |    6 |  0.08 |    0.08 |   0.45\nde    |   24 |  0.33 |    0.33 |   0.79\nel    |    2 |  0.03 |    0.03 |   0.81\nen    | 5915 | 81.53 |   81.53 |  82.34\nes    |   15 |  0.21 |    0.21 |  82.55\net    |    6 |  0.08 |    0.08 |  82.63\neu    |    3 |  0.04 |    0.04 |  82.67\nfr    |   20 |  0.28 |    0.28 |  82.95\nhi    |    1 |  0.01 |    0.01 |  82.96\nht    |    2 |  0.03 |    0.03 |  82.99\nhu    |    2 |  0.03 |    0.03 |  83.02\nin    |    8 |  0.11 |    0.11 |  83.13\nis    |    1 |  0.01 |    0.01 |  83.14\nit    |    6 |  0.08 |    0.08 |  83.23\nja    |    5 |  0.07 |    0.07 |  83.29\nlt    |    3 |  0.04 |    0.04 |  83.34\nnl    |    4 |  0.06 |    0.06 |  83.39\nno    |    1 |  0.01 |    0.01 |  83.40\npl    |    5 |  0.07 |    0.07 |  83.47\npt    |    7 |  0.10 |    0.10 |  83.57\nqam   |   40 |  0.55 |    0.55 |  84.12\nqht   |    1 |  0.01 |    0.01 |  84.14\nqme   |   81 |  1.12 |    1.12 |  85.25\nqst   |    5 |  0.07 |    0.07 |  85.32\nro    |    3 |  0.04 |    0.04 |  85.36\nru    |    7 |  0.10 |    0.10 |  85.46\nsl    |    2 |  0.03 |    0.03 |  85.49\ntl    |   59 |  0.81 |    0.81 |  86.30\ntr    |    5 |  0.07 |    0.07 |  86.37\nuk    |    1 |  0.01 |    0.01 |  86.38\nund   |  817 | 11.26 |   11.26 |  97.64\nvi    |    1 |  0.01 |    0.01 |  97.66\nzh    |    1 |  0.01 |    0.01 |  97.67\nzxx   |  169 |  2.33 |    2.33 | 100.00\n<NA>  |    0 |  0.00 |    <NA> |   <NA>"
  },
  {
    "objectID": "content/04-api_access-twitter/04-exercise.html#text-mining",
    "href": "content/04-api_access-twitter/04-exercise.html#text-mining",
    "title": "Showcase",
    "section": "Text mining",
    "text": "Text mining\n\nPreprocessing\n\nremove_html <- \"&amp;|&lt;|&gt;\"\n\ntweets_en <- tweets_musk %>% \n  filter(lang == \"en\",\n         is.na(sourcetweet_type)) %>% \n  select(tweet_id, text, user_username) %>% \n  mutate(text = str_remove_all(text, remove_html))\n\n\ntweets_en_corpus <- corpus(tweets_en,\n                           docid_field = \"tweet_id\",\n                           text_field = \"text\")\n\n\ntweets_en_tokens <- \n  tokens(tweets_en_corpus,\n         remove_punct = TRUE,\n         remove_numbers = TRUE,\n         remove_symbols = TRUE,\n         remove_url = TRUE) %>% \n  tokens_tolower() %>% \n  tokens_remove(stopwords(\"english\"))\n\n\ntweets_en_dfm <- dfm(tweets_en_tokens)\n\n\n\nAnalysis\n\nTop Hashtags\n\ntag_dfm <- dfm_select(tweets_en_dfm, pattern = \"#*\")\ntoptag <- names(topfeatures(tag_dfm, 50))\nhead(toptag, 10)\n\n[1] \"#2\"                  \"#mars\"               \"#resistanceisfutile\"\n[4] \"#1\"                  \"#freespeech\"        \n\n\n\n\nTop Mentions\n\nuser_dfm <- dfm_select(tweets_en_dfm, pattern = \"@*\")\ntopuser <- names(topfeatures(user_dfm, 50))\nhead(topuser, 10)\n\n [1] \"@wholemarsblog\"  \"@spacex\"         \"@teslaownerssv\"  \"@ppathole\"      \n [5] \"@tesla\"          \"@erdayastronaut\" \"@billym2k\"       \"@teslarati\"     \n [9] \"@sawyermerritt\"  \"@evafoxu\"       \n\n\n\n\nExclude Hashtags & Metions\n\ntweets_en_clean <- tweets_en_dfm %>% \n  dfm_remove(pattern = \"@*\") %>% \n  dfm_remove(pattern = \"#*\")\n\n\n\nTop 10 features\n\nterm_freq_en <- textstat_frequency(tweets_en_clean)\nhead(term_freq_en, n = 10)\n\n   feature frequency rank docfreq group\n1    tesla       354    1     328   all\n2     just       227    2     225   all\n3     good       215    3     209   all\n4    great       187    4     183   all\n5     much       184    5     180   all\n6     like       172    6     168   all\n7      can       169    7     165   all\n8   people       167    8     156   all\n9  twitter       156    9     147   all\n10     one       146   10     144   all\n\n\n\n\nWordcloud with Top 50 features\n\ntextplot_wordcloud(tweets_en_clean, max_words = 50)"
  },
  {
    "objectID": "content/04-api_access-twitter/04-slides.html",
    "href": "content/04-api_access-twitter/04-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you find the slides for the fourth session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‚Äòe‚Äô button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "content/04-api_access-twitter/slides/index.html#seminarplan",
    "href": "content/04-api_access-twitter/slides/index.html#seminarplan",
    "title": "API-Access ‚Äì Twitter",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einf√ºhrung und √úberblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nExkurs: DBD Analyse mit R\nChristoph Adrian\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nESM: m-path\nD√∂rr\n\n\n10\n19.01.2023\nData Donations\nHofmann & Wierzbicki\n\n\n11\n26.01.2023\nPUFFER\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian\n\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/04-api_access-twitter/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "href": "content/04-api_access-twitter/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "title": "API-Access ‚Äì Twitter",
    "section": "Vielen Dank f√ºr Ihre Fragen!",
    "text": "Vielen Dank f√ºr Ihre Fragen!\n\n\nWas genau kann unter ‚ÄúN-gram analysis‚Äù verstanden werden?\n\n\n\n\nUm semantische Muster der Daten bei der Twitter-Forschung zu erkennen, wendet man h√§ufig Text-Mining-Methoden an. Wie wird dabei mit ironischen Aussagen oder Umgangssprache umgegangen? Sind solche Analysemethoden somit √ºberhaupt verl√§sslich oder kann man diesbez√ºglich mit einer hohen Fehleranf√§lligkeit rechnen?\n\n\n\n\nViele Studien verwenden Twitter in der Forschung. Dabei werden verschiedene Methoden eingesetzt. Welche Methode (aus Table 4 des Pflichtpapers) w√ºrden Sie am meisten empfehlen? Welche ist am aussagekr√§ftigsten? Oder ist das Kontext-bezogen und eine allgemeine Aussage kann nicht get√§tigt werden?\n\n\n\n\nInteressant w√§re es in diesem Kontext vielleicht nicht nur Twitter, sondern eine andere Social-Media-Plattform zu betrachten, zum Bsp. Facebook. W√ºrden die dominierenden Themen der Facebook-basierten Forschung √§hnlich wie bei Twitter ausfallen? Wie sieht wohl die Entwicklung der Themen in den letzten Jahren aus?\n\n\n\n\nInteressant w√§re es in diesem Kontext vielleicht nicht nur Twitter, sondern eine andere Social-Media-Plattform zu betrachten, zum Bsp. Facebook. W√ºrden die dominierenden Themen der Facebook-basierten Forschung √§hnlich wie bei Twitter ausfallen? Wie sieht wohl die Entwicklung der Themen in den letzten Jahren aus?\n\n\n\n\nTwitter wird unter anderem f√ºr ‚ÄûOpinion Mining‚Äú verwendet. Jedoch kann es gerade bei polarisierenden Themen vorkommen, dass sich vor allem Personen mit extremer Meinung √§u√üern und die Personen mittig im Spektrum zur√ºckhalten. Wie kann man einen solchen Bias ausgleichen?\n\n\n\n\nEs kann nur ein kleiner Bruchteil der Twitter-Kommunikation per API abgefragt werden, der zudem noch veraltet ist. Inwieweit sind Trend-Analysen √ºberhaupt m√∂glich? Gibt es M√∂glichkeiten Twitter-Kommunikation zu ‚Äústreamen‚Äù?\n\n\n\n\nEine gute Studie lebt von den Kriterien der Validit√§t, Objektivit√§t und Reliabilit√§t. Inwieweit k√∂nnen diese Kriterien bei einer Twitter-Analyse erf√ºllt werden?\n\n\n\n\nWas sind die Gr√ºnde f√ºr den R√ºckgang der Forschung mit Twitter-Daten rund um das Thema Marketing?"
  },
  {
    "objectID": "content/04-api_access-twitter/slides/index.html#suchanfrage-erstellen-daten-sammeln",
    "href": "content/04-api_access-twitter/slides/index.html#suchanfrage-erstellen-daten-sammeln",
    "title": "API-Access ‚Äì Twitter",
    "section": "Suchanfrage erstellen & Daten sammeln",
    "text": "Suchanfrage erstellen & Daten sammeln\nTwitter case study - Teil 1: Suchen & Sammeln\n\n\n\n\n\n\nF√ºr die Nutzung des Tweet Downloader ben√∂tigen Sie einen Bearer Token. Diesen finden Sie auf MS Teams.\n\n\n\nW√§heln Sie eine der folgenden Szenarien aus und erstellen Sie eine Suchanfrage mit Hilfe des Twitter Query Builder:\n\nAlle Tweets eines bestimmten Accounts seit dem 01.10.2022\nAlle Tweets (ohne Retweets) mit dem Hashtag #karneval oder #wokwm am letzten Wochenende\n\n‚Ä¶ und ziehen sich die Tweets als .csv & .json mit Hilfe des Tweet Downloader (ben√∂tigt Chrome, Edge oder Opera)"
  },
  {
    "objectID": "content/04-api_access-twitter/slides/index.html#format-der-daten-potentielle-analysen",
    "href": "content/04-api_access-twitter/slides/index.html#format-der-daten-potentielle-analysen",
    "title": "API-Access ‚Äì Twitter",
    "section": "Format der Daten & potentielle Analyse(n)",
    "text": "Format der Daten & potentielle Analyse(n)\nTwitter case study - Teil 2: Sichten & Konzipieren\n\nInspizieren Sie anschlie√üend die Datens√§tze und schauen Sie, welche Informationen Ihnen geliefert werden.\n\nWie unterscheiden sich die Datenformate?\n\n\n\n\nAuf Basis der gesichteten Daten ‚Ä¶\n\nWie w√ºrden Sie die Daten analyiseren bzw. welche Aspekte w√ºrden Sie sich anschauen?\nWelche potentielle Fragestellungen k√∂nnten Sie spontan entwickeln?"
  },
  {
    "objectID": "content/04-api_access-twitter/slides/index.html#setup-und-datensammlung-mit-r",
    "href": "content/04-api_access-twitter/slides/index.html#setup-und-datensammlung-mit-r",
    "title": "API-Access ‚Äì Twitter",
    "section": "Setup und Datensammlung mit R",
    "text": "Setup und Datensammlung mit R\n#Karneval im Fokus: Hintergrund und Datensammelung\n\n\nAlle Tweets herunterladen, die\n\n#Karneval enthalten\nzwischen 00:00 am 11.11.2022 und 12:00 am 13.12.2022 erschienen sind\n\nWeiterverarbeitung und Auswertung der Daten mit R, Fokus auf Paket academictwitteR (Barrie & Ho, 2021)\n\nSammlung der Daten mit academictwitteR:\n\nget_all_tweets(\n  query = \"#Karneval\", \n  start_tweets = \"2022-11-11T00:00:00Z\",\n  end_tweets = \"2022-11-13T12:00:00Z\",\n  file = \"karneval\",\n  data_path = \"data/raw_karneval/\",\n  n = 100000\n  )"
  },
  {
    "objectID": "content/04-api_access-twitter/slides/index.html#kurzer-blick-in-die-daten",
    "href": "content/04-api_access-twitter/slides/index.html#kurzer-blick-in-die-daten",
    "title": "API-Access ‚Äì Twitter",
    "section": "Kurzer Blick in die Daten",
    "text": "Kurzer Blick in die Daten\n#Karneval im Fokus: Daten√ºbersicht\n\ntweets_karneval %>% glimpse()\n\nRows: 2,637\nColumns: 37\n$ tweet_id               <chr> \"1590981439457464321\", \"1590981390123892740\", \"‚Ä¶\n$ user_username          <chr> \"truthonearth3\", \"Auno94\", \"HaiAriane\", \"ElCobr‚Ä¶\n$ text                   <chr> \"RT @faqyoutoo: Ab heute 11:11 h d√ºrfen wir uns‚Ä¶\n$ created_at             <chr> \"2022-11-11T08:15:08.000Z\", \"2022-11-11T08:14:5‚Ä¶\n$ lang                   <chr> \"de\", \"de\", \"de\", \"und\", \"und\", \"und\", \"und\", \"‚Ä¶\n$ possibly_sensitive     <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE,‚Ä¶\n$ author_id              <chr> \"1486309822832287746\", \"2745840416\", \"995739344‚Ä¶\n$ source                 <chr> \"Twitter for Android\", \"Twitter for Android\", \"‚Ä¶\n$ conversation_id        <chr> \"1590981439457464321\", \"1590981390123892740\", \"‚Ä¶\n$ in_reply_to_user_id    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ user_protected         <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE‚Ä¶\n$ user_description       <chr> \"I‚ô•Ô∏èTrump\\nAnd Trump ‚ô•Ô∏èUS.\", \"Zertifizierter Alma‚Ä¶\n$ user_profile_image_url <chr> \"https://pbs.twimg.com/profile_images/158736121‚Ä¶\n$ user_pinned_tweet_id   <chr> \"1591132482271080448\", \"1346065459297267712\", N‚Ä¶\n$ user_verified          <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE‚Ä¶\n$ user_name              <chr> \"truthonearth\", \"Auno\", \"Pirschelb√§r\", \"Michael‚Ä¶\n$ user_created_at        <chr> \"2022-01-26T12:07:54.000Z\", \"2014-08-19T17:42:0‚Ä¶\n$ user_location          <chr> NA, \"K√∂ln, Deutschland\", NA, \"Bonn, Germany\", N‚Ä¶\n$ user_url               <chr> NA, \"https://t.co/lodH0xUg0C\", NA, NA, NA, NA, ‚Ä¶\n$ retweet_count          <int> 2, 0, 0, 178, 178, 178, 178, 178, 178, 178, 178‚Ä¶\n$ like_count             <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,‚Ä¶\n$ quote_count            <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,‚Ä¶\n$ user_tweet_count       <int> 840, 5851, 495, 110593, 5045, 1351, 932, 29967,‚Ä¶\n$ user_list_count        <int> 0, 0, 0, 77, 0, 1, 1, 0, 0, 1, 1, 5, 3, 73, 18,‚Ä¶\n$ user_followers_count   <int> 268, 197, 18, 1260, 54, 109, 71, 372, 126, 145,‚Ä¶\n$ user_following_count   <int> 1102, 1124, 118, 476, 436, 403, 411, 748, 1339,‚Ä¶\n$ sourcetweet_type       <chr> \"retweeted\", NA, NA, \"retweeted\", \"retweeted\", ‚Ä¶\n$ sourcetweet_id         <chr> \"1590967777762086912\", NA, NA, \"159097615399271‚Ä¶\n$ sourcetweet_text       <chr> \"Ab heute 11:11 h d√ºrfen wir uns wieder verklei‚Ä¶\n$ sourcetweet_lang       <chr> \"de\", NA, NA, \"und\", \"und\", \"und\", \"und\", \"und\"‚Ä¶\n$ sourcetweet_author_id  <chr> \"946619921454247937\", NA, NA, \"529561909\", \"529‚Ä¶\n$ datetime               <dttm> 2022-11-11 08:15:08, 2022-11-11 08:14:57, 2022‚Ä¶\n$ date                   <date> 2022-11-11, 2022-11-11, 2022-11-11, 2022-11-11‚Ä¶\n$ hour                   <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,‚Ä¶\n$ min                    <int> 15, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 12,‚Ä¶\n$ hms                    <time> 08:15:08, 08:14:57, 08:14:29, 08:14:29, 08:13:‚Ä¶\n$ hm                     <time> 08:15:00, 08:14:00, 08:14:00, 08:14:00, 08:13:‚Ä¶"
  },
  {
    "objectID": "content/04-api_access-twitter/slides/index.html#deutsch-hashtags-englisch",
    "href": "content/04-api_access-twitter/slides/index.html#deutsch-hashtags-englisch",
    "title": "API-Access ‚Äì Twitter",
    "section": "Deutsch, Hashtags, Englisch ‚Ä¶",
    "text": "Deutsch, Hashtags, Englisch ‚Ä¶\n#Karneval im Fokus: Sprache der Tweets\n\n\n\ntable(tweets_karneval$lang)\n\n\n  ca   cs   cy   da   de   en   es   et   eu   fi   fr   in   is   ja   lt   nl \n   5    3    2    4 2180  112   18    2    3    3    9    7    1    2    2    9 \n  no   pl  qht  qme   tr  und \n   7    8    6   43   10  201 \n\n\n\n\nfrq(tweets_karneval$lang, sort.frq = \"desc\")\n\nx <character> \n# total N=2637 valid N=2637 mean=6.85 sd=5.06\n\nValue |    N | Raw % | Valid % | Cum. %\n---------------------------------------\nde    | 2180 | 82.67 |   82.67 |  82.67\nund   |  201 |  7.62 |    7.62 |  90.29\nen    |  112 |  4.25 |    4.25 |  94.54\nqme   |   43 |  1.63 |    1.63 |  96.17\nes    |   18 |  0.68 |    0.68 |  96.85\ntr    |   10 |  0.38 |    0.38 |  97.23\nfr    |    9 |  0.34 |    0.34 |  97.57\nnl    |    9 |  0.34 |    0.34 |  97.91\npl    |    8 |  0.30 |    0.30 |  98.22\nin    |    7 |  0.27 |    0.27 |  98.48\nno    |    7 |  0.27 |    0.27 |  98.75\nqht   |    6 |  0.23 |    0.23 |  98.98\nca    |    5 |  0.19 |    0.19 |  99.17\nda    |    4 |  0.15 |    0.15 |  99.32\ncs    |    3 |  0.11 |    0.11 |  99.43\neu    |    3 |  0.11 |    0.11 |  99.54\nfi    |    3 |  0.11 |    0.11 |  99.66\ncy    |    2 |  0.08 |    0.08 |  99.73\net    |    2 |  0.08 |    0.08 |  99.81\nja    |    2 |  0.08 |    0.08 |  99.89\nlt    |    2 |  0.08 |    0.08 |  99.96\nis    |    1 |  0.04 |    0.04 | 100.00\n<NA>  |    0 |  0.00 |    <NA> |   <NA>\n\n\n\n\n\nqme = only hashtags\nund = unidentified"
  },
  {
    "objectID": "content/04-api_access-twitter/slides/index.html#am-11.11.-um-1011",
    "href": "content/04-api_access-twitter/slides/index.html#am-11.11.-um-1011",
    "title": "API-Access ‚Äì Twitter",
    "section": "Am 11.11. um 10:11?",
    "text": "Am 11.11. um 10:11?\n#Karneval im Fokus: Tweets im Zeitverlauf\n\ntweets_karneval %>% \n  ggplot(aes(hour)) +\n  geom_bar() +\n  facet_grid(cols = vars(date)) +\n  theme_pubr()"
  },
  {
    "objectID": "content/04-api_access-twitter/slides/index.html#utc-statt-utc1",
    "href": "content/04-api_access-twitter/slides/index.html#utc-statt-utc1",
    "title": "API-Access ‚Äì Twitter",
    "section": "UTC statt UTC+1",
    "text": "UTC statt UTC+1\n#Karneval im Fokus: St√§rkste Konzentration von Tweets\n\ntweets_karneval %>%\n  frq(hm,\n      sort.frq = \"desc\", \n      min.frq = 10)\n\nhm <numeric> \n# total N=2637 valid N=2637 mean=48463.12 sd=16629.59\n\nValue    |    N | Raw % | Valid % | Cum. %\n------------------------------------------\n10:11:00 |   59 |  2.24 |    2.24 |   2.24\n10:12:00 |   14 |  0.53 |    0.53 |   2.77\n10:13:00 |   12 |  0.46 |    0.46 |   3.22\n16:54:00 |   12 |  0.46 |    0.46 |   3.68\n10:10:00 |   10 |  0.38 |    0.38 |   4.06\n11:29:00 |   10 |  0.38 |    0.38 |   4.44\n16:53:00 |   10 |  0.38 |    0.38 |   4.82\nn < 10   | 2510 | 95.18 |   95.18 | 100.00\n<NA>     |    0 |  0.00 |    <NA> |   <NA>"
  },
  {
    "objectID": "content/04-api_access-twitter/slides/index.html#ein-blick-auf-die-senderinnen",
    "href": "content/04-api_access-twitter/slides/index.html#ein-blick-auf-die-senderinnen",
    "title": "API-Access ‚Äì Twitter",
    "section": "Ein Blick auf die Sender:Innen",
    "text": "Ein Blick auf die Sender:Innen\n#Karneval im Fokus: User mit den meisten Tweets\n\n\n\ntweets_karneval$user_username %>% \n  frq(sort.frq = \"desc\", \n      min.frq = 10)\n\nx <character> \n# total N=2637 valid N=2637 mean=976.88 sd=562.18\n\nValue           |    N | Raw % | Valid % | Cum. %\n-------------------------------------------------\nGun17170309     |   65 |  2.46 |    2.46 |   2.46\nberlinaffaires  |   28 |  1.06 |    1.06 |   3.53\nBeratungszimmer |   19 |  0.72 |    0.72 |   4.25\nbartl_katrin    |   16 |  0.61 |    0.61 |   4.85\nrammwars        |   15 |  0.57 |    0.57 |   5.42\nfree_cart9      |   12 |  0.46 |    0.46 |   5.88\nploetschkoepp   |   12 |  0.46 |    0.46 |   6.33\nKespelHelau     |   11 |  0.42 |    0.42 |   6.75\nkryptomania84   |   10 |  0.38 |    0.38 |   7.13\nneussentweetet  |   10 |  0.38 |    0.38 |   7.51\nRaissoussama1   |   10 |  0.38 |    0.38 |   7.89\nn < 10          | 2429 | 92.11 |   92.11 | 100.00\n<NA>            |    0 |  0.00 |    <NA> |   <NA>\n\n\n\n\n\ntweets_karneval %>% \n  filter(user_username == \"Gun17170309\") %$% \n  glue::glue(\n    \"Tweet-ID: {tweet_id} \n    Inhalt:\n    {text}\\n\\n\") %>% \n  head()\n\nTweet-ID: 1591125966809878528 \nInhalt:\n#F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\nhttps://t.co/peg7JWAKdN\nKarnevals-Klassiker: Rheinische Krapfenü§° https://t.co/Am7A84C4Dj\n\nTweet-ID: 1591120408102961153 \nInhalt:\nRT @Gun17170309: #F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\nhttps://t.co/vZxzhaeUNY\nFasching Berlinerüòã h‚Ä¶\n\nTweet-ID: 1591120391904587777 \nInhalt:\nRT @Gun17170309: #F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\nhttps://t.co/6XKwts10gk\nT√§t√§-T√§t√§ ‚Äì Das Karn‚Ä¶\n\nTweet-ID: 1591120367321419776 \nInhalt:\nRT @Gun17170309: #F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\nSo schnell gehen Berliner, Kreppel, Krapfenr‚Ä¶\n\nTweet-ID: 1591120292436643840 \nInhalt:\n#F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\nSo schnell gehen Berliner, Kreppel, Krapfenr√§ppel, Pfannkuchen, Krapfen,\nin Frankreich: ‚ÄûBoule de Berlin‚Äú\nin England ‚ÄûJelly Doughnut‚Äú\n. . . einfach selber backen, lecker!\nhttps://t.co/mw3W1iynuL https://t.co/WQ45iMavLn\n\nTweet-ID: 1591119195928166400 \nInhalt:\nRT @Gun17170309: https://t.co/mw3W1igegD \n#F√ºnfteJahreszeit #Fasching #Faschingsbeginn #fastnacht #Karneval  \nüíôüíöüíõüß°‚ù§Ô∏èü§éüíúüíô\n\n\n\n\ntweets_karneval %>% \n  filter(user_username == \"berlinaffaires\") %$% \n  glue::glue(\n    \"Tweet-ID: {tweet_id} \n    Inhalt:\n    {text}\\n\\n\") %>% \n  head()\n\nTweet-ID: 1591076515110060033 \nInhalt:\nRT @berlinaffaires: #HauptstadtStudio #SanktMartin #Karneval #Fastnacht #Fasching #ElfteElfte der Himmel √ºber Berlin\nLuftrettung Christoph‚Ä¶\n\nTweet-ID: 1591076479663624192 \nInhalt:\n#HauptstadtStudio #SanktMartin #Karneval #Fastnacht #Fasching #ElfteElfte der Himmel √ºber Berlin\nLuftrettung Christoph Callsign fliegt immer noch hin und her #DHXCA #CHX31 #H135 #MASH #HelicopterSpotting https://t.co/OETymAoOL1\n\nTweet-ID: 1591055201598701568 \nInhalt:\nRT @berlinaffaires: #HauptstadtStudio #SanktMartin #Karneval #Fastnacht #Fasching #ElfteElfte der Himmel √ºber Berlin\nLuftrettung Christoph‚Ä¶\n\nTweet-ID: 1591055143579004928 \nInhalt:\n#HauptstadtStudio #SanktMartin #Karneval #Fastnacht #Fasching #ElfteElfte der Himmel √ºber Berlin\nLuftrettung Christoph Callsign #DHXCA #CHX31 #H135 #MASH #HelicopterSpotting #Funkturm https://t.co/jv22RwAgS9\n\nTweet-ID: 1591043114181218306 \nInhalt:\nRT @DresdenNews: #Karneval im #PieschenerRathaus: Am 11.11 √ºbernehmen um 11:11 Uhr die #N√§rrinnen und #Narren der Initiative Karneval in #P‚Ä¶\n\nTweet-ID: 1591042750408929280 \nInhalt:\nRT @bernhardboeth: @hessenschau Was haben wir den ganzen Vormittag auf diesen Moment hingefiebert #Fasching #Fastnacht #Karneval https://t.‚Ä¶"
  },
  {
    "objectID": "content/04-api_access-twitter/slides/index.html#literatur",
    "href": "content/04-api_access-twitter/slides/index.html#literatur",
    "title": "API-Access ‚Äì Twitter",
    "section": "Literatur",
    "text": "Literatur\n\n\nBarrie, C., & Ho, J. (2021). academictwitteR: An r package to access the twitter academic research product track v2 API endpoint. Journal of Open Source Software, 6(62), 3272. https://doi.org/10.21105/joss.03272\n\n\n\n\n\nDigital Behavioral Data"
  },
  {
    "objectID": "content/05-api_access-youtube/05-exercise.html#background",
    "href": "content/05-api_access-youtube/05-exercise.html#background",
    "title": "Showcase",
    "section": "Background",
    "text": "Background\nPractical application of the YouTube Data Tool (YTDT) using the example of Mai Thi Nguyen-Kim (  |  ) and her -Channel maiLab.\nYou can also open this showcase in other interactive and executable environments:"
  },
  {
    "objectID": "content/05-api_access-youtube/05-exercise.html#exercise-1",
    "href": "content/05-api_access-youtube/05-exercise.html#exercise-1",
    "title": "Showcase",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nUse the Channel Search site/function of the YTDT to find the (correct) channel ID for the  Channel maiLab.\nTherefore, enter ‚ÄúmaiLab‚Äù in the field Search query and download the results as .csv.\nOpen the file and search extract the correct channel ID.\nHint: If in doubt, use Channel Info function to check if the selected ID matches the channel description.\n\n\n# Load packages\nlibrary(readr)\nlibrary(tidyverse)\n\n# Import data\nchannel_list <- read_csv(\n  here(\"content/05-api_access-youtube/data/channelsearch_channels50_2022_11_17-09_54_22.csv\"))\n\n# Preview data \nchannel_list %>% glimpse()\n\nRows: 50\nColumns: 10\n$ position        <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,‚Ä¶\n$ id              <chr> \"UCyHDQ5C6z1NDmJ4g6SerW8g\", \"UC146qqkUMTrn4nfSSOTNwiA\"‚Ä¶\n$ title           <chr> \"maiLab\", \"musstewissen Chemie\", \"mailab\", \"MAILab_Î©î‚Ä¶\n$ description     <chr> \"Holt euch einen Tee, Freunde der Sonne, macht es euch‚Ä¶\n$ publishedAt     <dttm> 2016-09-08 14:13:08, 2016-09-23 09:24:14, 2020-03-19 ‚Ä¶\n$ defaultLanguage <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA‚Ä¶\n$ country         <chr> \"DE\", \"DE\", \"DE\", \"KR\", NA, NA, NA, NA, NA, \"DE\", NA, ‚Ä¶\n$ viewCount       <dbl> 127882489, 18039348, 21013, 5101, 11, 2, 2, 5004, 230,‚Ä¶\n$ subscriberCount <dbl> 1480000, 190000, 146, 26, 0, 1, 1, 9, 9, 66300, 0, 2, ‚Ä¶\n$ videoCount      <dbl> 186, 45, 9, 104, 3, 1, 1, 24, 12, 51, 1, 6, 31, 1, 2, ‚Ä¶\n\n\n\n# Get channel description with R\nchannel_list %>%\n  filter(title == \"maiLab\") %>%\n  select(id, title, description)\n\n# A tibble: 1 √ó 3\n  id                       title  description                                   \n  <chr>                    <chr>  <chr>                                         \n1 UCyHDQ5C6z1NDmJ4g6SerW8g maiLab Holt euch einen Tee, Freunde der Sonne, macht‚Ä¶"
  },
  {
    "objectID": "content/05-api_access-youtube/05-exercise.html#exercise-2",
    "href": "content/05-api_access-youtube/05-exercise.html#exercise-2",
    "title": "Showcase",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWith help of the Video List site/function of the YTDT, get a list of all published videos of the channel maiLab.\nTherefore, use the extracted channel id and download the results as .csv.\nImport/preview the data.\n\n\n# Import data: video list\nvideo_list <- read_csv(\n  here(\"content/05-api_access-youtube/data/videolist_channel186_2022_11_17-10_20_11.csv\"))\n\n# Preview data \nvideo_list %>% glimpse()\n\nRows: 186\nColumns: 23\n$ position           <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ‚Ä¶\n$ channelId          <chr> \"UCyHDQ5C6z1NDmJ4g6SerW8g\", \"UCyHDQ5C6z1NDmJ4g6SerW‚Ä¶\n$ channelTitle       <chr> \"maiLab\", \"maiLab\", \"maiLab\", \"maiLab\", \"maiLab\", \"‚Ä¶\n$ videoId            <chr> \"IK5BZdnqMDU\", \"Mt50U4_ueR0\", \"-NMs56pQ9EE\", \"-9OvN‚Ä¶\n$ publishedAt        <dttm> 2022-09-18 16:00:18, 2022-06-09 04:30:04, 2022-05-‚Ä¶\n$ publishedAtSQL     <dttm> 2022-09-18 16:00:18, 2022-06-09 04:30:04, 2022-05-‚Ä¶\n$ videoTitle         <chr> \"Das Ende der Hom√∂opathie | MAITHINK X\", \"Affenpock‚Ä¶\n$ videoDescription   <chr> \"Der vielleicht gr√∂√üte Abwasserskandal aller Zeiten‚Ä¶\n$ tags               <chr> \"Mai Thi Nguyen-Kim,Mai Thi,mai,nguyen,mailab,lab,m‚Ä¶\n$ videoCategoryId    <dbl> 28, 28, 28, 28, 22, 28, 22, 22, 22, 27, 22, 22, 28,‚Ä¶\n$ videoCategoryLabel <chr> \"Science & Technology\", \"Science & Technology\", \"Sc‚Ä¶\n$ duration           <chr> \"PT31M57S\", \"PT13M39S\", \"PT15M21S\", \"PT12M6S\", \"PT1‚Ä¶\n$ durationSec        <dbl> 1917, 819, 921, 726, 832, 1664, 306, 1065, 1325, 12‚Ä¶\n$ dimension          <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ‚Ä¶\n$ definition         <chr> \"hd\", \"hd\", \"hd\", \"hd\", \"hd\", \"hd\", \"hd\", \"hd\", \"hd‚Ä¶\n$ caption            <lgl> FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, T‚Ä¶\n$ thumbnail_maxres   <chr> \"https://i.ytimg.com/vi/IK5BZdnqMDU/maxresdefault.j‚Ä¶\n$ licensedContent    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ viewCount          <dbl> 1729562, 993841, 929302, 2125579, 3021542, 895038, ‚Ä¶\n$ likeCount          <dbl> 83334, 56794, 64304, 123191, 236388, 77980, 73251, ‚Ä¶\n$ dislikeCount       <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ favoriteCount      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ commentCount       <dbl> 18716, 9141, 8204, 38823, 111200, 7905, 3831, 5723,‚Ä¶"
  },
  {
    "objectID": "content/05-api_access-youtube/05-exercise.html#different-location-parameters",
    "href": "content/05-api_access-youtube/05-exercise.html#different-location-parameters",
    "title": "Showcase",
    "section": "Different location parameters",
    "text": "Different location parameters\n\n# Load additional packages\nlibrary(sjmisc) \n\n# Get distribution parameters for selected variables\nvideo_list %>% \n  select(durationSec, viewCount, likeCount, favoriteCount, commentCount) %>% \n  descr()\n\n\n## Basic descriptive statistics\n\n           var    type         label   n NA.prc      mean        sd       se\n   durationSec numeric   durationSec 186      0    612.92    402.74    29.53\n     viewCount numeric     viewCount 186      0 687563.73 763588.15 55989.00\n     likeCount numeric     likeCount 186      0  31172.50  36815.40  2699.44\n favoriteCount numeric favoriteCount 186      0      0.00      0.00     0.00\n  commentCount numeric  commentCount 186      0   5598.28  11238.77   824.07\n       md   trimmed                   range       iqr skew\n    530.5    579.42          1825 (92-1917)    633.25 0.64\n 467371.5 562670.19 6671382 (21298-6692680) 782761.75 3.36\n  20970.5  24734.81    267376 (1063-268439)  37023.75 3.10\n      0.0      0.00                 0 (0-0)      0.00  NaN\n   2068.0   3106.24      111166 (34-111200)   5718.00 5.54\n\n\n\nMore detailed distribution for each variable\n\nvideo_list %>% \n  plot_frq(durationSec, viewCount, likeCount, commentCount, type = \"density\")\n\n[[1]]\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n[[4]]"
  },
  {
    "objectID": "content/05-api_access-youtube/05-exercise.html#in-depth-analysis",
    "href": "content/05-api_access-youtube/05-exercise.html#in-depth-analysis",
    "title": "Showcase",
    "section": "In-depth analysis",
    "text": "In-depth analysis\nBased on the findings of the previous section, let us take a closer look. Interestingly, although most of the varialbes have a left-sloping distribution, there are isolated outliers on the ‚Äúright‚Äù edge.\nTherefore, the next goal is to find out which video(s) they are.\n\nTop 5 videos with the highest view count\n\nvideo_list %>% \n  arrange(-viewCount) %>% \n  select(videoTitle, publishedAt, viewCount, likeCount, commentCount) %>% \n  head()\n\n# A tibble: 6 √ó 5\n  videoTitle                     publishedAt         viewCount likeCount comme‚Ä¶¬π\n  <chr>                          <dttm>                  <dbl>     <dbl>   <dbl>\n1 Corona geht gerade erst los    2020-04-02 07:00:00   6692680    268439   48174\n2 Impfpflicht ist OK             2021-11-14 07:00:11   3021542    236388  111200\n3 So endet Corona                2021-01-28 06:15:04   3020999    170219   28363\n4 Virologen-Vergleich            2020-04-19 07:00:22   2654200     92957   33773\n5 Rezo wissenschaftlich gepruÃàft  2019-05-24 04:30:25   2605822    142990   16995\n6 Was ist jetzt mit dem Kokos√∂l? 2018-08-30 04:30:01   2362469     63198    6833\n# ‚Ä¶ with abbreviated variable name ¬π‚ÄãcommentCount\n\n\n\n\nTop 5 videos with the highest comment count\n\nvideo_list %>% \n  arrange(-commentCount) %>% \n  select(videoTitle, publishedAt, viewCount, likeCount, commentCount) %>% \n  head()\n\n# A tibble: 6 √ó 5\n  videoTitle                         publishedAt         viewC‚Ä¶¬π likeC‚Ä¶¬≤ comme‚Ä¶¬≥\n  <chr>                              <dttm>                <dbl>   <dbl>   <dbl>\n1 Impfpflicht ist OK                 2021-11-14 07:00:11 3021542  236388  111200\n2 Corona geht gerade erst los        2020-04-02 07:00:00 6692680  268439   48174\n3 7 kritische Fragen zur Impfung     2021-02-11 06:15:02 2068956   80075   38982\n4 Corona-Endlosschleife | Kommen wi‚Ä¶ 2021-11-25 07:48:24 2125579  123191   38823\n5 Corona hat meine Meinung ge√§ndert  2020-10-08 04:30:01 1602957   74811   36543\n6 Virologen-Vergleich                2020-04-19 07:00:22 2654200   92957   33773\n# ‚Ä¶ with abbreviated variable names ¬π‚ÄãviewCount, ¬≤‚ÄãlikeCount, ¬≥‚ÄãcommentCount"
  },
  {
    "objectID": "content/05-api_access-youtube/05-slides.html",
    "href": "content/05-api_access-youtube/05-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you find the slides for the fifth session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‚Äòe‚Äô button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#seminarplan",
    "href": "content/05-api_access-youtube/slides/index.html#seminarplan",
    "title": "API-Access ‚Äì YouTube",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einf√ºhrung und √úberblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nExkurs: DBD Analyse mit R\nChristoph Adrian\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nESM: m-path\nD√∂rr\n\n\n10\n19.01.2023\nData Donations\nHofmann & Wierzbicki\n\n\n11\n26.01.2023\nPUFFER\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian\n\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#what-is-it-an-who-made-it",
    "href": "content/05-api_access-youtube/slides/index.html#what-is-it-an-who-made-it",
    "title": "API-Access ‚Äì YouTube",
    "section": "What is it an who made it",
    "text": "What is it an who made it\nHintergrundinformationen YouTube Data Tools (Rieder, 2015)\n\nSammlung von einfachen Modulen zur Extraktion von Daten aus der YouTube-Plattform √ºber die YouTube-API v3.\nKeine voll entwickelte Analysesoftware, sondern ein Mittel f√ºr Forschende, um Daten in Standarddateiformaten zu sammeln und in anderen Softwarepaketen weiter zu analysieren.\ngeschrieben, entwickelt und gepflegt von Bernhard Rieder (Universit√§t Amsterdam)"
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#and-now-you",
    "href": "content/05-api_access-youtube/slides/index.html#and-now-you",
    "title": "API-Access ‚Äì YouTube",
    "section": "And now ‚Ä¶ you!",
    "text": "And now ‚Ä¶ you!\nBeispielhafte Nutzung\n\nSuchen Sie sich einen YouTube-Kanal aus, auf dem die folgenden Analysen basieren sollen\nNutzen Sie die Channel Search des YTDT um die ‚Äúkorrekte‚Äù Channel ID zu identifizieren.\nLaden Sie mit Hilfe der Video List Seite/Funktion des YTDT eine Liste aller ver√∂ffentlichten Videos Ihres ausgew√§hlten YouTube-Kanals herunter.\n\nOptional:\n\nSuchen Sie mit Hilfe der heruntergeladenen Liste der ver√∂ffentlichten Videos das Video mit den meisten Likes/Comments.\nDownloaden Sie die Kommentare des Videos mit Hilfe der Video Info des YTDT."
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#wissenschaftsjournalismus-auf-youtube",
    "href": "content/05-api_access-youtube/slides/index.html#wissenschaftsjournalismus-auf-youtube",
    "title": "API-Access ‚Äì YouTube",
    "section": "Wissenschaftsjournalismus auf YouTube",
    "text": "Wissenschaftsjournalismus auf YouTube\nHIntergrund zu  maiLab\n\n\n\nseit 2016 bestehende YouTube-Kanal (fr√ºher sch√∂nschlau) von Mai Thi Nguyen-Kim\nist Teil des funk-Netzwerks\nbehandelt diverse Themen aus den Bereichen Natur- und Gesellschaftswissenschaften"
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#zusammenspiel-von-ytdt-r",
    "href": "content/05-api_access-youtube/slides/index.html#zusammenspiel-von-ytdt-r",
    "title": "API-Access ‚Äì YouTube",
    "section": "Zusammenspiel von YTDT & R",
    "text": "Zusammenspiel von YTDT & R\n maiLab im Fokus: Datenimport mit R (1)\n\n# Load packages\nlibrary(readr)\nlibrary(tidyverse)\n\n# Import data\nchannel_list <- read_csv(\n  \"https://raw.githubusercontent.com/chrdrn/dbd_binder/main/data/05-youtube/channelsearch_channels50_2022_11_17-09_54_22.csv\")\n\n# Preview data \nchannel_list %>% glimpse()\n\nRows: 50\nColumns: 10\n$ position        <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,‚Ä¶\n$ id              <chr> \"UCyHDQ5C6z1NDmJ4g6SerW8g\", \"UC146qqkUMTrn4nfSSOTNwiA\"‚Ä¶\n$ title           <chr> \"maiLab\", \"musstewissen Chemie\", \"mailab\", \"MAILab_Î©î‚Ä¶\n$ description     <chr> \"Holt euch einen Tee, Freunde der Sonne, macht es euch‚Ä¶\n$ publishedAt     <dttm> 2016-09-08 14:13:08, 2016-09-23 09:24:14, 2020-03-19 ‚Ä¶\n$ defaultLanguage <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA‚Ä¶\n$ country         <chr> \"DE\", \"DE\", \"DE\", \"KR\", NA, NA, NA, NA, NA, \"DE\", NA, ‚Ä¶\n$ viewCount       <dbl> 127882489, 18039348, 21013, 5101, 11, 2, 2, 5004, 230,‚Ä¶\n$ subscriberCount <dbl> 1480000, 190000, 146, 26, 0, 1, 1, 9, 9, 66300, 0, 2, ‚Ä¶\n$ videoCount      <dbl> 186, 45, 9, 104, 3, 1, 1, 24, 12, 51, 1, 6, 31, 1, 2, ‚Ä¶"
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#mit-channel-id-zur-video-list",
    "href": "content/05-api_access-youtube/slides/index.html#mit-channel-id-zur-video-list",
    "title": "API-Access ‚Äì YouTube",
    "section": "Mit Channel ID zur Video List",
    "text": "Mit Channel ID zur Video List\n maiLab im Fokus: Datenimport mit R (2)\n\n# Import data: video list\nvideo_list <- read_csv(\n  \"https://raw.githubusercontent.com/chrdrn/dbd_binder/main/data/05-youtube/videolist_channel186_2022_11_17-10_20_11.csv\"\n)\n\n# Preview data \nvideo_list %>% glimpse()\n\nRows: 186\nColumns: 23\n$ position           <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ‚Ä¶\n$ channelId          <chr> \"UCyHDQ5C6z1NDmJ4g6SerW8g\", \"UCyHDQ5C6z1NDmJ4g6SerW‚Ä¶\n$ channelTitle       <chr> \"maiLab\", \"maiLab\", \"maiLab\", \"maiLab\", \"maiLab\", \"‚Ä¶\n$ videoId            <chr> \"IK5BZdnqMDU\", \"Mt50U4_ueR0\", \"-NMs56pQ9EE\", \"-9OvN‚Ä¶\n$ publishedAt        <dttm> 2022-09-18 16:00:18, 2022-06-09 04:30:04, 2022-05-‚Ä¶\n$ publishedAtSQL     <dttm> 2022-09-18 16:00:18, 2022-06-09 04:30:04, 2022-05-‚Ä¶\n$ videoTitle         <chr> \"Das Ende der Hom√∂opathie | MAITHINK X\", \"Affenpock‚Ä¶\n$ videoDescription   <chr> \"Der vielleicht gr√∂√üte Abwasserskandal aller Zeiten‚Ä¶\n$ tags               <chr> \"Mai Thi Nguyen-Kim,Mai Thi,mai,nguyen,mailab,lab,m‚Ä¶\n$ videoCategoryId    <dbl> 28, 28, 28, 28, 22, 28, 22, 22, 22, 27, 22, 22, 28,‚Ä¶\n$ videoCategoryLabel <chr> \"Science & Technology\", \"Science & Technology\", \"Sc‚Ä¶\n$ duration           <chr> \"PT31M57S\", \"PT13M39S\", \"PT15M21S\", \"PT12M6S\", \"PT1‚Ä¶\n$ durationSec        <dbl> 1917, 819, 921, 726, 832, 1664, 306, 1065, 1325, 12‚Ä¶\n$ dimension          <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ‚Ä¶\n$ definition         <chr> \"hd\", \"hd\", \"hd\", \"hd\", \"hd\", \"hd\", \"hd\", \"hd\", \"hd‚Ä¶\n$ caption            <lgl> FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, T‚Ä¶\n$ thumbnail_maxres   <chr> \"https://i.ytimg.com/vi/IK5BZdnqMDU/maxresdefault.j‚Ä¶\n$ licensedContent    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ viewCount          <dbl> 1729562, 993841, 929302, 2125579, 3021542, 895038, ‚Ä¶\n$ likeCount          <dbl> 83334, 56794, 64304, 123191, 236388, 77980, 73251, ‚Ä¶\n$ dislikeCount       <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ favoriteCount      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶\n$ commentCount       <dbl> 18716, 9141, 8204, 38823, 111200, 7905, 3831, 5723,‚Ä¶"
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#explorative-analyse-der-video-list",
    "href": "content/05-api_access-youtube/slides/index.html#explorative-analyse-der-video-list",
    "title": "API-Access ‚Äì YouTube",
    "section": "Explorative Analyse der Video List",
    "text": "Explorative Analyse der Video List\n maiLab im Fokus: Datenauswertung mit R (1)\n\n# Load additional packages\nlibrary(sjmisc) \n\n# Get distribution parameters for selected variables\nvideo_list %>% \n  select(durationSec, viewCount, likeCount, favoriteCount, commentCount) %>% \n  descr() %>%\n  select(!c(var, type)) \n\n\n## Basic descriptive statistics\n\n         label   n NA.prc      mean        sd       se       md   trimmed\n   durationSec 186      0    612.92    402.74    29.53    530.5    579.42\n     viewCount 186      0 687563.73 763588.15 55989.00 467371.5 562670.19\n     likeCount 186      0  31172.50  36815.40  2699.44  20970.5  24734.81\n favoriteCount 186      0      0.00      0.00     0.00      0.0      0.00\n  commentCount 186      0   5598.28  11238.77   824.07   2068.0   3106.24\n                   range       iqr skew\n          1825 (92-1917)    633.25 0.64\n 6671382 (21298-6692680) 782761.75 3.36\n    267376 (1063-268439)  37023.75 3.10\n                 0 (0-0)      0.00  NaN\n      111166 (34-111200)   5718.00 5.54"
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#videover√∂ffentlichungen-im-zeitverlauf",
    "href": "content/05-api_access-youtube/slides/index.html#videover√∂ffentlichungen-im-zeitverlauf",
    "title": "API-Access ‚Äì YouTube",
    "section": "Videover√∂ffentlichungen im Zeitverlauf",
    "text": "Videover√∂ffentlichungen im Zeitverlauf\n maiLab im Fokus: Datenauswertung mit R (2)\n\n# Load additional packages\nlibrary(sjPlot) \n\n# Create plot\nvideo_list %>% \n  mutate(year  = as.factor(year(publishedAt))) %>% \n  plot_frq(\n    year,\n    title = \"Video uploads on `maiLab` by year\")"
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#top-5-videos-mit-den-meisten-aufrufen",
    "href": "content/05-api_access-youtube/slides/index.html#top-5-videos-mit-den-meisten-aufrufen",
    "title": "API-Access ‚Äì YouTube",
    "section": "Top 5 Videos mit den meisten Aufrufen",
    "text": "Top 5 Videos mit den meisten Aufrufen\n maiLab im Fokus: Datenauswertung mit R (3)\n\nvideo_list %>% \n  arrange(-viewCount) %>% \n  select(videoTitle, publishedAt, viewCount, likeCount, commentCount) %>% \n  head()\n\n# A tibble: 6 √ó 5\n  videoTitle                     publishedAt         viewCount likeCount comme‚Ä¶¬π\n  <chr>                          <dttm>                  <dbl>     <dbl>   <dbl>\n1 Corona geht gerade erst los    2020-04-02 07:00:00   6692680    268439   48174\n2 Impfpflicht ist OK             2021-11-14 07:00:11   3021542    236388  111200\n3 So endet Corona                2021-01-28 06:15:04   3020999    170219   28363\n4 Virologen-Vergleich            2020-04-19 07:00:22   2654200     92957   33773\n5 Rezo wissenschaftlich gepruÃàft  2019-05-24 04:30:25   2605822    142990   16995\n6 Was ist jetzt mit dem Kokos√∂l? 2018-08-30 04:30:01   2362469     63198    6833\n# ‚Ä¶ with abbreviated variable name ¬π‚ÄãcommentCount"
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#top-5-videos-mit-den-meisten-kommentaren",
    "href": "content/05-api_access-youtube/slides/index.html#top-5-videos-mit-den-meisten-kommentaren",
    "title": "API-Access ‚Äì YouTube",
    "section": "Top 5 Videos mit den meisten Kommentaren",
    "text": "Top 5 Videos mit den meisten Kommentaren\n maiLab im Fokus: Datenauswertung mit R (4)\n\nvideo_list %>% \n  arrange(-commentCount) %>% \n  select(videoTitle, publishedAt, viewCount, likeCount, commentCount) %>% \n  head()\n\n# A tibble: 6 √ó 5\n  videoTitle                         publishedAt         viewC‚Ä¶¬π likeC‚Ä¶¬≤ comme‚Ä¶¬≥\n  <chr>                              <dttm>                <dbl>   <dbl>   <dbl>\n1 Impfpflicht ist OK                 2021-11-14 07:00:11 3021542  236388  111200\n2 Corona geht gerade erst los        2020-04-02 07:00:00 6692680  268439   48174\n3 7 kritische Fragen zur Impfung     2021-02-11 06:15:02 2068956   80075   38982\n4 Corona-Endlosschleife | Kommen wi‚Ä¶ 2021-11-25 07:48:24 2125579  123191   38823\n5 Corona hat meine Meinung ge√§ndert  2020-10-08 04:30:01 1602957   74811   36543\n6 Virologen-Vergleich                2020-04-19 07:00:22 2654200   92957   33773\n# ‚Ä¶ with abbreviated variable names ¬π‚ÄãviewCount, ¬≤‚ÄãlikeCount, ¬≥‚ÄãcommentCount"
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#interactive-and-executable-environments",
    "href": "content/05-api_access-youtube/slides/index.html#interactive-and-executable-environments",
    "title": "API-Access ‚Äì YouTube",
    "section": "Interactive and executable environments",
    "text": "Interactive and executable environments\nQuarto, Binder & Google Colab\nVerschiedene M√∂glichkeiten, um den Code bzw. das heutige Beispiel (‚Äúlive‚Äù) zu reproduzieren:\n\nQuarto-Dokument auf Kurs-Homepage\nBinder: Repositories mit Jupyter-Notebooks in ausf√ºhrbaren Umgebungen √∂ffnen und bearbeiten\n\nGoogle Colab: gehosteter Jupyter-Notebook-Dienst, der keine EInrichtung erfordertund gleichzeitig kostenlosen Zugang zu Rechenressourcen einschlie√ülich GPUs bietet"
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "href": "content/05-api_access-youtube/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "title": "API-Access ‚Äì YouTube",
    "section": "Vielen Dank f√ºr Ihre Fragen!",
    "text": "Vielen Dank f√ºr Ihre Fragen!\n\n\nIst es denkbar, dass YouTube eines Tages von anderen sozialen Plattformen wie Instagram oder Spotify √ºberholt wird, an Bekanntheit verliert oder sogar ganz von der Bildfl√§che verschwindet?\n\n\n\n\nYoutube-Influencer verdienen etwa das Doppelte mit Werbeanzeigen auf YouTube, als wenn sie Werbeanzeigen auf Facebook oder Instagram schalten w√ºrden (2016). Kann das im Jahr 2022 immer noch best√§tigt werden? Sind Werbeanzeigen auf YouTube erfolgreicher und haben eine weitere Reichweite im Vergleich mit Instagram?\n\n\n\n\nEs wird das Tool Webometric erw√§hnt, ein automatisiertes Instrument f√ºr die Sammlung von Social Media Daten √ºber die API der Plattform YouTube. Wie sieht Webometric genau aus und wie werden die Daten √ºber dieses Tool extrahiert?\n\n\n\n\nEs wird oft dar√ºber geredet, dass das ‚ÄûRecommendation System‚Äù fehlerhaft sei und bestimmte Videos trotz mangelnde Performance trotzdem empfohlen werden oder in den Trends landen (z.B Amerikanische Late Night Shows). Wie kann in der Forschung verhindert werden, dass Resultate entstehen die nicht den tats√§chlichen Verhaltensdaten der Konsumenten entstehen."
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#lets-discuss",
    "href": "content/05-api_access-youtube/slides/index.html#lets-discuss",
    "title": "API-Access ‚Äì YouTube",
    "section": "Let‚Äôs discuss",
    "text": "Let‚Äôs discuss\n\n\nSophie Bishop meint es w√§re interessant die Forschung zum Algorithmus von YouTube dahingehend zu erweitern, dass man untersucht was Nutzer denken, wie der Algorithmus funktioniert. Wie w√ºrde man bei dieser Fragestellung vorgehen bzw. wie k√∂nnte man das untersuchen?\n\n\n\n\nInwiefern kann YouTube als Soziales Netzwerk verstanden werden, wenn nur ein kleiner Bruchteil seiner User sich durch Upload von Content am Informationsaustausch beteiligt und der Gro√üteil ‚Äúnur‚Äù konsumiert?\n\n\n\n\nYouTube besteht als Social Media Platform l√§nger als die meisten anderen Plattformen (Twitter, Instagram, TikTok, etc.) und besitzt so gut wie weltweite Bekanntheit. Warum ist die Forschung in Richtung YouTube trotzdem so gering?"
  },
  {
    "objectID": "content/05-api_access-youtube/slides/index.html#literatur",
    "href": "content/05-api_access-youtube/slides/index.html#literatur",
    "title": "API-Access ‚Äì YouTube",
    "section": "Literatur",
    "text": "Literatur\n\n\nRieder, B. (2015). YouTube data tools. https://tools.digitalmethods.net/netvizz/youtube/index.php\n\n\n\n\n\nDigital Behavioral Data"
  },
  {
    "objectID": "content/06-api_access-reddit/06-exercise.html#background",
    "href": "content/06-api_access-reddit/06-exercise.html#background",
    "title": "Showcase",
    "section": "Background",
    "text": "Background\nThs showcase has two different goals:\n\nExemplary presentation of the collection of  Reddit data using the RedditExtractoR package\nImporting and analyzing the data collected with the üêàüêà 4CAT üêàüêà tool.\n\nYou can also open this showcase in other interactive and executable environments:"
  },
  {
    "objectID": "content/06-api_access-reddit/06-exercise.html#data-collection-with-redditextractor",
    "href": "content/06-api_access-reddit/06-exercise.html#data-collection-with-redditextractor",
    "title": "Showcase",
    "section": "Data collection with RedditExtractor",
    "text": "Data collection with RedditExtractor\nReddit Extractor is an R package for extracting data out of Reddit. It allows you to:\n\nfind subreddits based on a search query\nfind a user and their Reddit history\nfind URLs to threads of interest and retrieve comments out of these threads\n\n\n\n\n\n\n\nDisclaimer\n\n\n\nUnfortunately, the functions of the RedditExtractoR package can NOT be executed during the Markdown creation process and must be reproduced ‚Äúlive‚Äù.\nTherefore, there will be no output for the next two paragraphs.\n\n\n\nExample: Find subreddits\nSimilar to the example from the seminar, the function find_subreddits identifies all subreddits that contain the keyword news either in their name or in their attributes.\n\nlibrary(tidyverse)\nlibrary(RedditExtractoR)\n\n# Get list of subreddits\nnews <- find_subreddits(\"news\")\n\n# Quick preview of the dataset\nnews %>% glimpse()\n\n# Arrange subreddits by subscribers\nnews %>% \n  arrange(-subscribers) %>% \n  tibble() %>% head()\n\n\n\nExample: Find thread URLs\n\n# Get list of top thread urls\nnews_top_urls <- find_thread_urls(\n  subreddit = \"news\", \n  sort_by = \"top\", \n  period = \"month\"\n)\n\n# Quick preview of dataset\nnews_top_urls %>% glimpse()\nnews_top_urls %>% tibble()"
  },
  {
    "objectID": "content/06-api_access-reddit/06-exercise.html#analysis-of-collected-4cat-data",
    "href": "content/06-api_access-reddit/06-exercise.html#analysis-of-collected-4cat-data",
    "title": "Showcase",
    "section": "Analysis of collected üêàüêà 4CAT üêàüêà data",
    "text": "Analysis of collected üêàüêà 4CAT üêàüêà data\n\nData import from \n\n# load packages\nlibrary(readr)\n\n# get data from github\nmusk <- read_csv(\n  \"https://raw.githubusercontent.com/chrdrn/dbd_binder/main/data/06-reddit/4cat-reddit_news-musk_complete.csv\")\n\nmusk_entities <- read_csv(\n  \"https://raw.githubusercontent.com/chrdrn/dbd_binder/main/data/06-reddit/4cat-reddit_news-musk-named_entities.csv\")\n\n# quick preview\nmusk %>% glimpse()\n\nRows: 4,838\nColumns: 16\n$ thread_id      <chr> \"yugsz0\", \"yt59ku\", \"yulq2v\", \"yulq2v\", \"yulq2v\", \"yulq‚Ä¶\n$ id             <chr> \"iw9mhr7\", \"iw9tzrz\", \"iwa0egr\", \"iwa10h3\", \"iwa1gry\", ‚Ä¶\n$ timestamp      <dttm> 2022-11-14 00:13:59, 2022-11-14 01:11:53, 2022-11-14 0‚Ä¶\n$ body           <chr> \"Nick Cannon and Elon Musk need to put a damn condom on‚Ä¶\n$ subject        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ author         <chr> \"fbe0d753750a9f008871e6e829b727bf26cc2bdcdc71f340\", \"89‚Ä¶\n$ author_flair   <chr> \"aadb59c4da75af6c9fb8d5cb4c310ce59888aab7f96ffc15\", \"aa‚Ä¶\n$ post_flair     <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ domain         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ url            <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ image_file     <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ image_md5      <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ subreddit      <chr> \"worldnews\", \"news\", \"news\", \"news\", \"news\", \"news\", \"n‚Ä¶\n$ parent         <chr> \"t3_yugsz0\", \"t1_iw4y0aj\", \"t3_yulq2v\", \"t3_yulq2v\", \"t‚Ä¶\n$ score          <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ unix_timestamp <dbl> 1668384839, 1668388313, 1668391383, 1668391676, 1668391‚Ä¶\n\nmusk_entities %>% glimpse()\n\nRows: 3,633\nColumns: 3\n$ word   <chr> \"musk\", \"twitter\", \"twitter\", \"elon musk\", \"tesla\", \"trump\", \"t‚Ä¶\n$ entity <chr> \"PERSON\", \"PERSON\", \"PRODUCT\", \"PRODUCT\", \"ORG\", \"ORG\", \"GPE\", ‚Ä¶\n$ count  <dbl> 1147, 861, 479, 404, 345, 273, 222, 218, 205, 187, 154, 132, 13‚Ä¶\n\n\n\n\nMessages including ‚Äòmusk‚Äô over time\n\n\n\n\n\n\nTip\n\n\n\nThe following graphics (and especially their labels) may appear very small. To view the graphics in their original size, right-click on the images and select ‚ÄúOpen image/graphic in new tab‚Äù.\n\n\n\nTotal\n\nlibrary(lubridate)\nlibrary(sjPlot)\n\n# Display \nmusk %>% \n  mutate(date  = as.factor(date(timestamp))) %>% \n  plot_frq(\n    date,\n    title = \"Post including 'musk' on Reddit\") +\n  labs(subtitle = \"Subreddits 'news' & 'worldnews' between 14-11 and 26-11-2022\")\n\n\n\n\n\n\nBy subreddit\n\nlibrary(magrittr)\n\nmusk %>% \n  mutate(\n    date  = as.factor(date(timestamp)),\n    across(subreddit, as.factor)\n    ) %$% \n  plot_grpfrq(\n    date,\n    subreddit,\n    title = \"Post including 'musk' on Reddit\") +\n  labs(subtitle = \"Between 14-11 and 26-11-2022\")"
  },
  {
    "objectID": "content/06-api_access-reddit/06-slides.html",
    "href": "content/06-api_access-reddit/06-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you find the slides for the sixth session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‚Äòe‚Äô button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#seminarplan",
    "href": "content/06-api_access-reddit/slides/index.html#seminarplan",
    "title": "API-Access ‚Äì Reddit",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einf√ºhrung und √úberblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nExkurs: DBD Analyse mit R\nChristoph Adrian\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n12.01.2023\nESM: m-path\nD√∂rr\n\n\n10\n19.01.2023\nData Donations\nHofmann & Wierzbicki\n\n\n11\n26.01.2023\nPUFFER\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n09.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian\n\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#what-is-it-who-made-it",
    "href": "content/06-api_access-reddit/slides/index.html#what-is-it-who-made-it",
    "title": "API-Access ‚Äì Reddit",
    "section": "What is it & who made it?",
    "text": "What is it & who made it?\nHintergrundinformationen 4CAT (Peeters & Hagen, 2022)\n\n\n\nTool zur Analyse und Verarbeitung von Daten aus sozialen Online-Plattformen\nZiel ist es, die Erfassung und Analyse von Daten aus diesen Plattformen √ºber eine Webschnittstelle zug√§nglich zu machen, ohne dass Programmier- oder Web-Scraping-Kenntnisse erforderlich sind."
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#soziale-medien-sind-quelle-f√ºr-nachrichten",
    "href": "content/06-api_access-reddit/slides/index.html#soziale-medien-sind-quelle-f√ºr-nachrichten",
    "title": "API-Access ‚Äì Reddit",
    "section": "Soziale Medien sind Quelle f√ºr Nachrichten",
    "text": "Soziale Medien sind Quelle f√ºr Nachrichten\nMedienkonsum in Wandel\n\n\n\n\nAber: Wie prominent ist Reddit (als Nachrichtenquelle) bei Ihnen/in DE?"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#und-fa-brands-reddit-alien-noch-nicht-in-deutschland",
    "href": "content/06-api_access-reddit/slides/index.html#und-fa-brands-reddit-alien-noch-nicht-in-deutschland",
    "title": "API-Access ‚Äì Reddit",
    "section": "Und ? (Noch) Nicht in Deutschland!",
    "text": "Und ? (Noch) Nicht in Deutschland!\nNutzung sozialer Medien als Nachrichtenquelle in Deutschland & USA"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#and-now-you-reddit-als-newsfeed",
    "href": "content/06-api_access-reddit/slides/index.html#and-now-you-reddit-als-newsfeed",
    "title": "API-Access ‚Äì Reddit",
    "section": "And now ‚Ä¶ you: Reddit als Newsfeed",
    "text": "And now ‚Ä¶ you: Reddit als Newsfeed\nGroup activity: Scrape Reddit mit 4CAT\n\n\n\nZiel der Group Activity\n\n\nDurchsuchen Sie die Subreddits r/news und r/worldnews nach Posts zu einem bestimmten Thema/Begriff und analysieren Sie diese mit Hilfe von 4CAT\n\n\n\n\n\n√úberlegen Sie (in Gruppen), welches Thema Sie untersuchen wollen und mit welchen Begriffen Sie Beitr√§ge zu diesem Thema identifizieren k√∂nnten.\n\n\n\n\n√ñffnen Sie 4CAT ‚û°Ô∏èCreate dataset ‚û°Ô∏è Data source: Reddit\n\n\n\n\nGeben Sie news, worldness an beim Feld Subreddit(s)\n\n\n\n\nGeben Sie Ihre(n) Suchbegriff(e) im Feld Message search ein.\n\n\n\n\nW√§hlen Sie (maximal) die letzten zwei Wochen als Date range\n\n\n\n\nBenennen Sie ihrem Datensatz im Feld Dataset name\n\n\n\n\n\nOptional: Probieren Sie verschiedenen Analysem√∂glichkeiten aus"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#tools-2-analysen",
    "href": "content/06-api_access-reddit/slides/index.html#tools-2-analysen",
    "title": "API-Access ‚Äì Reddit",
    "section": "2 Tools, 2 Analysen",
    "text": "2 Tools, 2 Analysen\nBeispiele f√ºr Auswertung mit üêàüêà4CATüêàüêà &  RStudio\nZwei (einfache) Szenarien:\n\nVisualisierung der Anzahl der Beitr√§ge im Zeitverlauf\nErstellung einer Wordcloud mit den meistgenannten Named Entities"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#beitr√§ge-mit-keyword-musk-im-zeitverlauf",
    "href": "content/06-api_access-reddit/slides/index.html#beitr√§ge-mit-keyword-musk-im-zeitverlauf",
    "title": "API-Access ‚Äì Reddit",
    "section": "Beitr√§ge mit Keyword ‚Äúmusk‚Äù im Zeitverlauf",
    "text": "Beitr√§ge mit Keyword ‚Äúmusk‚Äù im Zeitverlauf\nVisualisierung mit üêàüêà4CATüêàüêà"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#beitr√§ge-im-zeitverlauf-nach-subreddit",
    "href": "content/06-api_access-reddit/slides/index.html#beitr√§ge-im-zeitverlauf-nach-subreddit",
    "title": "API-Access ‚Äì Reddit",
    "section": "Beitr√§ge im Zeitverlauf nach Subreddit",
    "text": "Beitr√§ge im Zeitverlauf nach Subreddit\nVisualisierung mit üêàüêà4CATüêàüêà"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#wordcloud-mit-named-entities",
    "href": "content/06-api_access-reddit/slides/index.html#wordcloud-mit-named-entities",
    "title": "API-Access ‚Äì Reddit",
    "section": "Wordcloud mit Named Entities",
    "text": "Wordcloud mit Named Entities\nVisualisierung mit üêàüêà4CATüêàüêà"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#back-to-fa-brands-r-project-rstudio",
    "href": "content/06-api_access-reddit/slides/index.html#back-to-fa-brands-r-project-rstudio",
    "title": "API-Access ‚Äì Reddit",
    "section": "Back to  RStudio",
    "text": "Back to  RStudio\nKurzer √úberblick √ºber die eingelesenen Datens√§tze\n\nmusk %>% glimpse()\n\nRows: 4,838\nColumns: 16\n$ thread_id      <chr> \"yugsz0\", \"yt59ku\", \"yulq2v\", \"yulq2v\", \"yulq2v\", \"yulq‚Ä¶\n$ id             <chr> \"iw9mhr7\", \"iw9tzrz\", \"iwa0egr\", \"iwa10h3\", \"iwa1gry\", ‚Ä¶\n$ timestamp      <dttm> 2022-11-14 00:13:59, 2022-11-14 01:11:53, 2022-11-14 0‚Ä¶\n$ body           <chr> \"Nick Cannon and Elon Musk need to put a damn condom on‚Ä¶\n$ subject        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ author         <chr> \"fbe0d753750a9f008871e6e829b727bf26cc2bdcdc71f340\", \"89‚Ä¶\n$ author_flair   <chr> \"aadb59c4da75af6c9fb8d5cb4c310ce59888aab7f96ffc15\", \"aa‚Ä¶\n$ post_flair     <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ domain         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ url            <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ image_file     <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ image_md5      <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ subreddit      <chr> \"worldnews\", \"news\", \"news\", \"news\", \"news\", \"news\", \"n‚Ä¶\n$ parent         <chr> \"t3_yugsz0\", \"t1_iw4y0aj\", \"t3_yulq2v\", \"t3_yulq2v\", \"t‚Ä¶\n$ score          <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n$ unix_timestamp <dbl> 1668384839, 1668388313, 1668391383, 1668391676, 1668391‚Ä¶\n\nmusk_entities %>% glimpse()\n\nRows: 3,633\nColumns: 3\n$ word   <chr> \"musk\", \"twitter\", \"twitter\", \"elon musk\", \"tesla\", \"trump\", \"t‚Ä¶\n$ entity <chr> \"PERSON\", \"PERSON\", \"PRODUCT\", \"PRODUCT\", \"ORG\", \"ORG\", \"GPE\", ‚Ä¶\n$ count  <dbl> 1147, 861, 479, 404, 345, 273, 222, 218, 205, 187, 154, 132, 13‚Ä¶"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#beitr√§ge-mit-keyword-musk-im-zeitverlauf-1",
    "href": "content/06-api_access-reddit/slides/index.html#beitr√§ge-mit-keyword-musk-im-zeitverlauf-1",
    "title": "API-Access ‚Äì Reddit",
    "section": "Beitr√§ge mit Keyword ‚Äúmusk‚Äù im Zeitverlauf",
    "text": "Beitr√§ge mit Keyword ‚Äúmusk‚Äù im Zeitverlauf\nBetrachtung von beiden Subreddits (news & worldnews )\n\nmusk %>% \n  mutate(date  = as.factor(date(timestamp))) %>%\n  plot_frq(date,\n           title = \"Post including 'musk' on Reddit\") +\n  labs(subtitle = \"Subreddits 'news' & 'worldnews' between 14-11 and 26-11-2022\")"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#beitr√§ge-mit-keyword-musk-im-zeitverlauf-2",
    "href": "content/06-api_access-reddit/slides/index.html#beitr√§ge-mit-keyword-musk-im-zeitverlauf-2",
    "title": "API-Access ‚Äì Reddit",
    "section": "Beitr√§ge mit Keyword ‚Äúmusk‚Äù im Zeitverlauf",
    "text": "Beitr√§ge mit Keyword ‚Äúmusk‚Äù im Zeitverlauf\nUnterschieden nach Subreddits (news & worldnews )\n\n\n\n\nmusk %>%\n  mutate(date  = as.factor(date(timestamp)),\n         across(subreddit, as.factor)) %$% \n  plot_grpfrq(date, subreddit,\n              title = \"Post including 'musk' on Reddit\") +\n  labs(subtitle = \"Between 14-11 and 26-11-2022\")"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "href": "content/06-api_access-reddit/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "title": "API-Access ‚Äì Reddit",
    "section": "Vielen Dank f√ºr Ihre Fragen!",
    "text": "Vielen Dank f√ºr Ihre Fragen!\n\n\nDie Reddit API erlaubt nur bis 500 Kommentare pro Post √ºber ein automatisches Tool zu ‚Äòextrahieren‚Äô. Manuell ist es jedoch m√∂glich √ºber diese Grenze hinaus zu gehen. Wie kann das sein? Das w√ºrde ja bedeuten, dass man die Regeln der Reddit API manuell umgehen kann?\n\n\n\n\nIn dem Paper wird darauf hingewiesen, dass die Verwendung der API von Reddit ein m√∂glicher Versto√ü gegen die Nutzungsvereinbarungen ist. Wann w√ºrde so ein Fall eintreten bzw. wann spricht man von einem Versto√ü und was w√§re dann die Bestrafung?\n\n\nWie kann es sein, dass Reddit eine kostenlose API zur verf√ºgung stellt, die Nutzung dieser dann aber teilweise nicht legal sein kann?\n\n\n\n\nEs wird erw√§hnt, dass viele Nutzer mehrere Accounts haben und dementsprechend Diskussionen in bestimmten Subreddits st√§rker beeinflussen k√∂nnen. Besteht die M√∂glichkeit solche Accounts zu erkennen und angemessen in der Studie zu ber√ºcksichtigen ohne die Datenschutzrichtlinien zu verletzen?"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#lets-discuss",
    "href": "content/06-api_access-reddit/slides/index.html#lets-discuss",
    "title": "API-Access ‚Äì Reddit",
    "section": "Let‚Äôs discuss",
    "text": "Let‚Äôs discuss\n\n\nViele Social Media Plattformen, wie Instagram, Facebook und Twitter beschr√§nken ihren API Zugang. Weshalb legt Reddit den API Zugang im Gegensatz zu den anderen Plattformen so offen dar?\n\n\n\n\nViele der Reddit-Daten basierenden Publikationen enthielten nur unvollst√§ndige oder zweideutige Beschreibungen ihrer Datens√§tze. Auch die Methoden der Datenerhebung bleiben teilweise verschleiert. Warum ist das so und welche ethischen Gr√ºnde liegen hier m√∂glicherweise zu Grunde?\n\n\n\n\nWie stark sind Reddit-Daten (evtl. auch im Vergleich zu Twitter) generalisierbar, wenn die Struktur von Reddit doch Diskussionen und Gespr√§che in gewisser Weise leitet (z.B. durch Sichtbarkeit von Themen)?"
  },
  {
    "objectID": "content/06-api_access-reddit/slides/index.html#literatur",
    "href": "content/06-api_access-reddit/slides/index.html#literatur",
    "title": "API-Access ‚Äì Reddit",
    "section": "Literatur",
    "text": "Literatur\n\n\nPeeters, S., & Hagen, S. (2022). The 4CAT Capture and Analysis Toolkit: A Modular Tool for Transparent and Traceable Social Media Research. Computational Communication Research, 4(2), 571‚Äì589. https://doi.org/10.5117/ccr2022.2.007.hage\n\n\n\n\n\nDigital Behavioral Data"
  },
  {
    "objectID": "content/07-webscraping-tiktok/07-exercise.html#background",
    "href": "content/07-webscraping-tiktok/07-exercise.html#background",
    "title": "Showcase",
    "section": "Background",
    "text": "Background\nThis showcase is intended to illustrate different analysis possibilities of  TikTok data downloaded with the Zeeschuimer browser extension.\nYou can also open this showcase in other interactive and executable environments:"
  },
  {
    "objectID": "content/07-webscraping-tiktok/07-exercise.html#data-analysis",
    "href": "content/07-webscraping-tiktok/07-exercise.html#data-analysis",
    "title": "Showcase",
    "section": "Data analysis",
    "text": "Data analysis\n\nTikToks that are tagged with the hashtag statistics\ncollected via Zeeschuimer with .csv export via üêàüêà 4CAT üêàüêà\n\n\nData import from \n\n# load packages\nlibrary(readr)\n\nstatistics <- read_csv(\n  here(\"content/07-webscraping-tiktok/data/tiktok-search-statistics.csv\"), \n  col_types = cols(author_followers = col_number()))\n\n# quick preview\nstatistics %>% glimpse()\n\nRows: 941\nColumns: 24\n$ id               <dbl> 6.813800e+18, 6.832737e+18, 6.845368e+18, 6.927122e+1‚Ä¶\n$ thread_id        <dbl> 6.813800e+18, 6.832737e+18, 6.845368e+18, 6.927122e+1‚Ä¶\n$ author           <chr> \"onlyjayus\", \"onlyjayus\", \"ryguy238\", \"mason.whaley\",‚Ä¶\n$ author_full      <chr> \"actuallyitsbella\", \"actuallyitsbella\", \"ryan p\", \"Ma‚Ä¶\n$ author_id        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶\n$ author_followers <dbl> 18500000, 18500000, 28500, 151500, 15700, 319500, 693‚Ä¶\n$ body             <chr> \"You‚Äôre sexy. The math proves it #fyp #love #dating #‚Ä¶\n$ timestamp        <dttm> 2020-04-09 19:44:39, 2020-05-30 20:28:05, 2020-07-03‚Ä¶\n$ unix_timestamp   <dbl> 1586461479, 1590870485, 1593811442, 1612846242, 16420‚Ä¶\n$ is_duet          <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS‚Ä¶\n$ music_name       <chr> \"SexyBack\", \"original sound\", \"original sound\", \"orig‚Ä¶\n$ music_id         <dbl> 6.696418e+18, 6.832737e+18, 6.845368e+18, 6.927122e+1‚Ä¶\n$ music_url        <chr> \"https://sf16-ies-music-va.tiktokcdn.com/obj/tos-usea‚Ä¶\n$ video_url        <chr> \"https://v16-webapp.tiktok.com/eac3d9cb4566d4ac017e3f‚Ä¶\n$ tiktok_url       <chr> \"https://tiktok.com/@onlyjayus/video/6813800162259897‚Ä¶\n$ thumbnail_url    <chr> \"https://p16-sign-va.tiktokcdn.com/tos-maliva-p-0068/‚Ä¶\n$ likes            <dbl> 1200000, 910000, 901000, 794300, 740300, 701400, 6490‚Ä¶\n$ comments         <dbl> 7746, 11900, 3020, 36900, 8179, 8150, 34800, 7592, 28‚Ä¶\n$ shares           <dbl> 23000, 16600, 1755, 64000, 6397, 1685, 93800, 51300, ‚Ä¶\n$ plays            <dbl> 6700000, 3300000, 5100000, 3800000, 2900000, 2500000,‚Ä¶\n$ hashtags         <chr> \"fyp,love,dating,romance,relationship,crush,people,po‚Ä¶\n$ stickers         <chr> NA, NA, NA, \"that one guy\", \"Ok‚Ä¶but I guess Timmy is ‚Ä¶\n$ effects          <chr> NA, NA, NA, NA, \"Greenscreen\", NA, \"Disco\", NA, \"TapT‚Ä¶\n$ warning          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶\n\n\n\n\nExploration\n\n\n\n\n\n\nTip\n\n\n\nThe following graphics (and especially their labels) may appear very small. To view the graphics in their original size, right-click on the images and select ‚ÄúOpen image/graphic in new tab‚Äù.\n\n\n\nPeriode in which the TikToks were posted\n\n# Load packages\nlibrary(lubridate)\nlibrary(sjPlot)\nlibrary(ggpubr)\n\n# Display \nstatistics %>% \n  mutate(date  = as.factor(year(timestamp))) %>% \n  plot_frq(date) +\n  theme_pubr()\n\n\n\n\n\n\nLocation parameters of different statistics\n\nstatistics %>% \n  select(likes:plays) %>% \n  descr()\n\n\n## Basic descriptive statistics\n\n      var    type    label   n NA.prc      mean        sd       se     md\n    likes numeric    likes 941      0  50412.33 110696.23  3608.59  16600\n comments numeric comments 941      0    980.51   2380.29    77.60    351\n   shares numeric   shares 941      0   1349.89   4755.66   155.03    262\n    plays numeric    plays 941      0 384388.52 750096.58 24452.45 153700\n   trimmed                   range    iqr  skew\n  26511.33  1395280 (4720-1400000)  37830  6.14\n    537.56         36900 (0-36900)    791  8.94\n    527.19         93796 (4-93800)    820 12.24\n 220367.46 7985100 (14900-8000000) 309300  5.44\n\n\n\n\nDistribution of likes\n\nstatistics %>% \n  plot_frq(likes, type = \"density\")\n\n\n\n\n\n\nWarning messages displayed\n\nlibrary(sjmisc)\n\nstatistics %>% \n  frq(warning)\n\nwarning <character> \n# total N=941 valid N=24 mean=1.88 sd=0.80\n\nValue                                                                                                    |   N | Raw % | Valid % | Cum. %\n-----------------------------------------------------------------------------------------------------------------------------------------\nLearn more about COVID-19 vaccines                                                                       |   9 |  0.96 |   37.50 |  37.50\nLearn the facts about COVID-19                                                                           |   9 |  0.96 |   37.50 |  75.00\nThe actions in this video are performed by professionals or supervised by professionals. Do not attempt. |   6 |  0.64 |   25.00 | 100.00\n<NA>                                                                                                     | 917 | 97.45 |    <NA> |   <NA>\n\n\n\n\n\nText analysis\n\nCorpus creation\n\n# Create corpus based on variable hashtags\ncrp <- corpus(\n  statistics, \n  docid_field = \"id\",\n  text_field = \"hashtags\")\n\n# Display\ncrp \n\nCorpus consisting of 941 documents and 22 docvars.\n6813800162259897344 :\n\"fyp,love,dating,romance,relationship,crush,people,population...\"\n\n6832736698938576896 :\n\"fyp,blacklivesmatter,tiktokpartner,learnontiktok,police,fact...\"\n\n6845368010048408576 :\n\"skittles,statistics,education,fyp,foryou\"\n\n6927121729257098240 :\n\"hotguy,itwasntme,turbotaxlivepick6,doritosflatlife,foryou,wa...\"\n\n7052705912317840384 :\n\"timotheechalamet,fyp,foryou,timothee,peach,callmebyyourname,...\"\n\n6909087873081905152 :\n\"stitch,statistics,staticstics,fyp,foryoupage,trending\"\n\n[ reached max_ndoc ... 935 more documents ]\n\n\n\n\nTokenization\n\n# Create tokens based on corpus\ntkn <- crp %>% \n  tokens(\n    remove_punct = TRUE,\n    remove_symbols = TRUE,\n    remove_url = TRUE,\n    remove_separators = TRUE)\n\n# Display\ntkn\n\nTokens consisting of 941 documents and 22 docvars.\n6813800162259897344 :\n [1] \"fyp\"          \"love\"         \"dating\"       \"romance\"      \"relationship\"\n [6] \"crush\"        \"people\"       \"population\"   \"world\"        \"math\"        \n[11] \"stats\"        \"statistics\"  \n\n6832736698938576896 :\n[1] \"fyp\"              \"blacklivesmatter\" \"tiktokpartner\"    \"learnontiktok\"   \n[5] \"police\"           \"facts\"            \"fact\"             \"statistics\"      \n[9] \"usa\"             \n\n6845368010048408576 :\n[1] \"skittles\"   \"statistics\" \"education\"  \"fyp\"        \"foryou\"    \n\n6927121729257098240 :\n [1] \"hotguy\"            \"itwasntme\"         \"turbotaxlivepick6\"\n [4] \"doritosflatlife\"   \"foryou\"            \"wap\"              \n [7] \"statistics\"        \"fyp\"               \"foryoupage\"       \n[10] \"wap\"              \n\n7052705912317840384 :\n[1] \"timotheechalamet\" \"fyp\"              \"foryou\"           \"timothee\"        \n[5] \"peach\"            \"callmebyyourname\" \"statistics\"      \n\n6909087873081905152 :\n[1] \"stitch\"      \"statistics\"  \"staticstics\" \"fyp\"         \"foryoupage\" \n[6] \"trending\"   \n\n[ reached max_ndoc ... 935 more documents ]\n\n\n\n\nCreate Document-Feature-Matrix (DFM)\n\n# Create dfm based on tokens\ndfm <- tkn %>% \n  dfm()\n\n# Display\ndfm\n\nDocument-feature matrix of: 941 documents, 2,941 features (99.71% sparse) and 22 docvars.\n                     features\ndocs                  fyp love dating romance relationship crush people\n  6813800162259897344   1    1      1       1            1     1      1\n  6832736698938576896   1    0      0       0            0     0      0\n  6845368010048408576   1    0      0       0            0     0      0\n  6927121729257098240   1    0      0       0            0     0      0\n  7052705912317840384   1    0      0       0            0     0      0\n  6909087873081905152   1    0      0       0            0     0      0\n                     features\ndocs                  population world math\n  6813800162259897344          1     1    1\n  6832736698938576896          0     0    0\n  6845368010048408576          0     0    0\n  6927121729257098240          0     0    0\n  7052705912317840384          0     0    0\n  6909087873081905152          0     0    0\n[ reached max_ndoc ... 935 more documents, reached max_nfeat ... 2,931 more features ]\n\n\n\n\nWordcloud\n\ndfm %>% \n  textplot_wordcloud(\n    min_size = 1,\n    max_size = 8,\n    max_words = 50,\n    rotation = 0\n  )\n\n\n\n\n\nwithout the searchterm statistics\n\ndfm %>% \n  dfm_remove(pattern = \"statistics\") %>% \n  textplot_wordcloud(\n    min_size = 1,\n    max_size = 8,\n    max_words = 50,\n    rotation = 0,\n    color = \"dodgerblue3\"\n  )"
  },
  {
    "objectID": "content/07-webscraping-tiktok/07-slides.html",
    "href": "content/07-webscraping-tiktok/07-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you find the slides for the seventh session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‚Äòe‚Äô button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "content/07-webscraping-tiktok/slides/index.html#seminarplan",
    "href": "content/07-webscraping-tiktok/slides/index.html#seminarplan",
    "title": "Web-Scraping ‚Äì TikTok",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einf√ºhrung und √úberblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nExkurs: DBD Analyse mit R\nChristoph Adrian\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n11.01.2023\nESM: m-path\nD√∂rr\n\n\n10\n18.01.2023\nData Donations\nHofmann & Wierzbicki\n\n\n11\n25.01.2023\nPUFFER\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n08.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian\n\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/07-webscraping-tiktok/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "href": "content/07-webscraping-tiktok/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "title": "Web-Scraping ‚Äì TikTok",
    "section": "Vielen Dank f√ºr Ihre Fragen!",
    "text": "Vielen Dank f√ºr Ihre Fragen!\n\n\nIn dem Paper wird dar√ºber berichtet, dass der einzige direkte Weg der Monetarisierung auf TikTok (und auf Douyin) die virtuelle W√§hrung bzw. die virtuellen Geschenke sind. In China ist diese Art des Gesch√§ftsmodell bereits eine sehr etablierte Form der Zahlung, bei uns jedoch noch nicht. Ist es denkbar, dass dieser Trend auch bei uns popul√§r wird?\n\n\n\n\nIn dem Paper wird berichtet, dass TikTok teilweise transparenter als andere nicht-asiatischen Plattformen ist. Was genau tut TikTok daf√ºr um diese transparenz zu schaffen?\n\n\n\n\nIn Indien ist TikTok bereits verboten. Auch die USA und Australien drohen mit Ma√ünahmen gegen TikTok. Was h√§tte dies f√ºr ByteDance zur Folge?\n\n\n\n\nIst die Walkthrough-Methode eine g√§ngige Methode der Datenerhebung auf TikTok und wie l√§uft diese genau ab? Gibt es andere Methoden, die vielleicht weniger aufw√§ndig sind?"
  },
  {
    "objectID": "content/07-webscraping-tiktok/slides/index.html#lets-discuss",
    "href": "content/07-webscraping-tiktok/slides/index.html#lets-discuss",
    "title": "Web-Scraping ‚Äì TikTok",
    "section": "Let‚Äôs discuss",
    "text": "Let‚Äôs discuss\n\n\nDurch die Ideologie (platform governance) einer Plattform kann es kritisch sein, wenn einzelne Plattformen besonders gro√ü werden. Gleichzeitig ist die Existenz von mehreren kleineren Plattformen ebenfalls kritisch, da sich Nischengruppen bilden w√ºrden, die nur eine einzelne Perspektive betrachten. (Vgl. CCP Propaganda )\nWas k√∂nnte eine L√∂sung f√ºr dieses Problem sein?\n\n\n\n\nLaut dem paper wird durch verschiedene video einstellungen von TikTok bereits content ‚Äúgeshaped‚Äù. Sind biases auf TikTok dadurch st√§rker als bei anderen Plattformen?"
  },
  {
    "objectID": "content/07-webscraping-tiktok/slides/index.html#what-is-it-who-made-it",
    "href": "content/07-webscraping-tiktok/slides/index.html#what-is-it-who-made-it",
    "title": "Web-Scraping ‚Äì TikTok",
    "section": "What is it & who made it?",
    "text": "What is it & who made it?\nHintergrundinformationen Zeeschuimer (Peeters, 2022)\n\n\n\nBrowsererweiterung, die w√§hrend des Besuchs einer Social-Media-Website Daten √ºber die Elemente sammelt, die in der Weboberfl√§che einer Plattform zu sehen sind\nDerzeit werden die folgenden Plattformen unterst√ºtzt:\n\n √ºber https://www.tiktok.com\n √ºber https://www.instagram.com\n\nErg√§nzung zu 4CAT (Peeters & Hagen, 2022)\n\n\n\n\n\n\n\n\n\n\n\nDie Zielgruppe sind Forscher, die systematisch Inhalte auf Social-Media-Plattformen untersuchen wollen, die sich dem herk√∂mmlichen Scraping oder der API-basierten Datenerfassung widersetzen.\n\nSie k√∂nnen z. B. TikTok durchsuchen und sp√§ter eine Liste aller Beitr√§ge in der Reihenfolge exportieren, in der Sie sie gesehen haben. Die Daten k√∂nnen als JSON-Datei exportiert oder zur Analyse und Speicherung in eine 4CAT-Instanz exportiert werden. Zeeschuimer ist in erster Linie als Erg√§nzung zu 4CAT gedacht, aber Sie k√∂nnen seine Ausgabe auch in Ihre eigene Analysepipeline integrieren.\nDie Plattformunterst√ºtzung erfordert regelm√§√üige Wartung, um mit den √Ñnderungen auf den Plattformen Schritt zu halten. Wenn etwas nicht funktioniert, freuen wir uns √ºber Probleme und Pull Request\nDie Erweiterung st√∂rt Sie nicht beim normalen Surfen und l√§dt niemals automatisch Daten hoch, sondern nur, wenn Sie sie ausdr√ºcklich dazu auffordern."
  },
  {
    "objectID": "content/07-webscraping-tiktok/slides/index.html#and-now-you-design-your-own-fa-brands-tiktok-research",
    "href": "content/07-webscraping-tiktok/slides/index.html#and-now-you-design-your-own-fa-brands-tiktok-research",
    "title": "Web-Scraping ‚Äì TikTok",
    "section": "And now ‚Ä¶ you: Design your own  research",
    "text": "And now ‚Ä¶ you: Design your own  research\nGroup activity: Fragestellung ‚û°Ô∏è Datenerhebung ‚û°Ô∏èVergleich\n\n\n\nZiel der Group Activity\n\n\n\nF√ºhren Sie in Zweiergruppen eine kleine Case Study durch\n√úberlegen Sie sich eine Fragestellung, f√ºr die Sie mit Hilfe von Zeeschuimer-Daten erheben und (potentiell) auswerten k√∂nnen\nPr√§sentieren Sie kurz Ihr Projekt mit Hilfe von maximal 2 Powerpoint-Slides\n\n\n\n\n\n\n√úberlegen Sie (in Gruppen), welches Thema Sie untersuchen wollen, d.h.\n\nwelchen Begriffen bzw. Hashtags Sie Beitr√§ge zu diesem Thema identifizieren k√∂nnten\noder von welchem Account Sie sich die Beitr√§ge anschauen wollen\n\n\n\n\n\nNutzen Sie die Zeeschuimer-Browsererweiterung und laden Sie (jede Person in der Gruppe) die f√ºr Ihre case study relevanten Daten herunter.\n\n\n\n\nErkunden Sie Ihren Datensatz und √ºberlegen Sie sich potentielle Auswertungsstrategien.\n\n\n\n\nPosten Sie eine maximal 2 Folien umfassende Powerpoint-Pr√§sentation auf MS Teams, mit\n\nIhrer Fragestellung\neiner kurzen Beschreibung Ihrer Erhebung\ndie n√§chsten (Analyse-)Schritte\n\n\n\n\nOptional: Vergleichen Sie die von Ihnen heruntergeladenen Datens√§tze.\n\nSind die gleichen Beitr√§ge enthalten?\nWie hoch ist die √úbereinstimmung (ungef√§hr)?"
  },
  {
    "objectID": "content/07-webscraping-tiktok/slides/index.html#ein-kurzer-√ºberblick",
    "href": "content/07-webscraping-tiktok/slides/index.html#ein-kurzer-√ºberblick",
    "title": "Web-Scraping ‚Äì TikTok",
    "section": "Ein kurzer √úberblick",
    "text": "Ein kurzer √úberblick\nStruktur des  TikTok-Datensatzes\n\nstatistics %>% glimpse()\n\nRows: 941\nColumns: 24\n$ id               <dbl> 6.813800e+18, 6.832737e+18, 6.845368e+18, 6.927122e+1‚Ä¶\n$ thread_id        <dbl> 6.813800e+18, 6.832737e+18, 6.845368e+18, 6.927122e+1‚Ä¶\n$ author           <chr> \"onlyjayus\", \"onlyjayus\", \"ryguy238\", \"mason.whaley\",‚Ä¶\n$ author_full      <chr> \"actuallyitsbella\", \"actuallyitsbella\", \"ryan p\", \"Ma‚Ä¶\n$ author_id        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶\n$ author_followers <dbl> 18500000, 18500000, 28500, 151500, 15700, 319500, 693‚Ä¶\n$ body             <chr> \"You‚Äôre sexy. The math proves it #fyp #love #dating #‚Ä¶\n$ timestamp        <dttm> 2020-04-09 19:44:39, 2020-05-30 20:28:05, 2020-07-03‚Ä¶\n$ unix_timestamp   <dbl> 1586461479, 1590870485, 1593811442, 1612846242, 16420‚Ä¶\n$ is_duet          <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS‚Ä¶\n$ music_name       <chr> \"SexyBack\", \"original sound\", \"original sound\", \"orig‚Ä¶\n$ music_id         <dbl> 6.696418e+18, 6.832737e+18, 6.845368e+18, 6.927122e+1‚Ä¶\n$ music_url        <chr> \"https://sf16-ies-music-va.tiktokcdn.com/obj/tos-usea‚Ä¶\n$ video_url        <chr> \"https://v16-webapp.tiktok.com/eac3d9cb4566d4ac017e3f‚Ä¶\n$ tiktok_url       <chr> \"https://tiktok.com/@onlyjayus/video/6813800162259897‚Ä¶\n$ thumbnail_url    <chr> \"https://p16-sign-va.tiktokcdn.com/tos-maliva-p-0068/‚Ä¶\n$ likes            <dbl> 1200000, 910000, 901000, 794300, 740300, 701400, 6490‚Ä¶\n$ comments         <dbl> 7746, 11900, 3020, 36900, 8179, 8150, 34800, 7592, 28‚Ä¶\n$ shares           <dbl> 23000, 16600, 1755, 64000, 6397, 1685, 93800, 51300, ‚Ä¶\n$ plays            <dbl> 6700000, 3300000, 5100000, 3800000, 2900000, 2500000,‚Ä¶\n$ hashtags         <chr> \"fyp,love,dating,romance,relationship,crush,people,po‚Ä¶\n$ stickers         <chr> NA, NA, NA, \"that one guy\", \"Ok‚Ä¶but I guess Timmy is ‚Ä¶\n$ effects          <chr> NA, NA, NA, NA, \"Greenscreen\", NA, \"Disco\", NA, \"TapT‚Ä¶\n$ warning          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N‚Ä¶"
  },
  {
    "objectID": "content/07-webscraping-tiktok/slides/index.html#erstellung-eines-korpus",
    "href": "content/07-webscraping-tiktok/slides/index.html#erstellung-eines-korpus",
    "title": "Web-Scraping ‚Äì TikTok",
    "section": "Erstellung eines Korpus",
    "text": "Erstellung eines Korpus\nTextverarbeitung mit quanteda (Benoit et al., 2018)\n\ncrp <- corpus(statistics, \n              docid_field = \"id\",\n              text_field = \"hashtags\")\ncrp\n\nCorpus consisting of 941 documents and 22 docvars.\n6813800162259897344 :\n\"fyp,love,dating,romance,relationship,crush,people,population...\"\n\n6832736698938576896 :\n\"fyp,blacklivesmatter,tiktokpartner,learnontiktok,police,fact...\"\n\n6845368010048408576 :\n\"skittles,statistics,education,fyp,foryou\"\n\n6927121729257098240 :\n\"hotguy,itwasntme,turbotaxlivepick6,doritosflatlife,foryou,wa...\"\n\n7052705912317840384 :\n\"timotheechalamet,fyp,foryou,timothee,peach,callmebyyourname,...\"\n\n6909087873081905152 :\n\"stitch,statistics,staticstics,fyp,foryoupage,trending\"\n\n[ reached max_ndoc ... 935 more documents ]"
  },
  {
    "objectID": "content/07-webscraping-tiktok/slides/index.html#tokenisierung",
    "href": "content/07-webscraping-tiktok/slides/index.html#tokenisierung",
    "title": "Web-Scraping ‚Äì TikTok",
    "section": "Tokenisierung",
    "text": "Tokenisierung\nTextverarbeitung mit quanteda (Benoit et al., 2018)\n\ntkn <- crp %>% \n  tokens(remove_punct = TRUE,\n         remove_symbols = TRUE,\n         remove_url = TRUE,\n         remove_separators = TRUE)\ntkn\n\nTokens consisting of 941 documents and 22 docvars.\n6813800162259897344 :\n [1] \"fyp\"          \"love\"         \"dating\"       \"romance\"      \"relationship\"\n [6] \"crush\"        \"people\"       \"population\"   \"world\"        \"math\"        \n[11] \"stats\"        \"statistics\"  \n\n6832736698938576896 :\n[1] \"fyp\"              \"blacklivesmatter\" \"tiktokpartner\"    \"learnontiktok\"   \n[5] \"police\"           \"facts\"            \"fact\"             \"statistics\"      \n[9] \"usa\"             \n\n6845368010048408576 :\n[1] \"skittles\"   \"statistics\" \"education\"  \"fyp\"        \"foryou\"    \n\n6927121729257098240 :\n [1] \"hotguy\"            \"itwasntme\"         \"turbotaxlivepick6\"\n [4] \"doritosflatlife\"   \"foryou\"            \"wap\"              \n [7] \"statistics\"        \"fyp\"               \"foryoupage\"       \n[10] \"wap\"              \n\n7052705912317840384 :\n[1] \"timotheechalamet\" \"fyp\"              \"foryou\"           \"timothee\"        \n[5] \"peach\"            \"callmebyyourname\" \"statistics\"      \n\n6909087873081905152 :\n[1] \"stitch\"      \"statistics\"  \"staticstics\" \"fyp\"         \"foryoupage\" \n[6] \"trending\"   \n\n[ reached max_ndoc ... 935 more documents ]"
  },
  {
    "objectID": "content/07-webscraping-tiktok/slides/index.html#erstellung-einer-document-feature-matrix-dfm",
    "href": "content/07-webscraping-tiktok/slides/index.html#erstellung-einer-document-feature-matrix-dfm",
    "title": "Web-Scraping ‚Äì TikTok",
    "section": "Erstellung einer Document-Feature-Matrix [DFM]",
    "text": "Erstellung einer Document-Feature-Matrix [DFM]\nTextverarbeitung mit quanteda (Benoit et al., 2018)\n\ndfm <- tkn %>%  dfm()\ndfm\n\nDocument-feature matrix of: 941 documents, 2,941 features (99.71% sparse) and 22 docvars.\n                     features\ndocs                  fyp love dating romance relationship crush people\n  6813800162259897344   1    1      1       1            1     1      1\n  6832736698938576896   1    0      0       0            0     0      0\n  6845368010048408576   1    0      0       0            0     0      0\n  6927121729257098240   1    0      0       0            0     0      0\n  7052705912317840384   1    0      0       0            0     0      0\n  6909087873081905152   1    0      0       0            0     0      0\n                     features\ndocs                  population world math\n  6813800162259897344          1     1    1\n  6832736698938576896          0     0    0\n  6845368010048408576          0     0    0\n  6927121729257098240          0     0    0\n  7052705912317840384          0     0    0\n  6909087873081905152          0     0    0\n[ reached max_ndoc ... 935 more documents, reached max_nfeat ... 2,931 more features ]"
  },
  {
    "objectID": "content/07-webscraping-tiktok/slides/index.html#welche-hashtags-werden-genutzt",
    "href": "content/07-webscraping-tiktok/slides/index.html#welche-hashtags-werden-genutzt",
    "title": "Web-Scraping ‚Äì TikTok",
    "section": "Welche Hashtags werden genutzt?",
    "text": "Welche Hashtags werden genutzt?\nTextvisualisierung mit quanteda.textplots\n\nlibrary(quanteda.textplots)\ndfm %>% textplot_wordcloud(\n  min_size = 1, max_size = 8, max_words = 50,\n  rotation = 0)"
  },
  {
    "objectID": "content/07-webscraping-tiktok/slides/index.html#literatur",
    "href": "content/07-webscraping-tiktok/slides/index.html#literatur",
    "title": "Web-Scraping ‚Äì TikTok",
    "section": "Literatur",
    "text": "Literatur\n\n\nBenoit, K., Watanabe, K., Wang, H., Nulty, P., Obeng, A., M√ºller, S., & Matsuo, A. (2018). Quanteda: An r package for the quantitative analysis of textual data. Journal of Open Source Software, 3(30), 774. https://doi.org/10.21105/joss.00774\n\n\nPeeters, S. (2022). Zeeschuimer. Zenodo. https://doi.org/10.5281/ZENODO.7016797\n\n\nPeeters, S., & Hagen, S. (2022). The 4CAT Capture and Analysis Toolkit: A Modular Tool for Transparent and Traceable Social Media Research. Computational Communication Research, 4(2), 571‚Äì589. https://doi.org/10.5117/ccr2022.2.007.hage\n\n\n\n\n\nDigital Behavioral Data"
  },
  {
    "objectID": "content/08-text_as_data/08-exercise.html#background",
    "href": "content/08-text_as_data/08-exercise.html#background",
    "title": "Showcase",
    "section": "Background",
    "text": "Background\n\nScraping Amazon Reviewss in R"
  },
  {
    "objectID": "content/08-text_as_data/08-exercise.html#scraping",
    "href": "content/08-text_as_data/08-exercise.html#scraping",
    "title": "Showcase",
    "section": "Scraping",
    "text": "Scraping\n\nCreate function\nbased on stackoverflow post.\n\nscrape_amazon <- function(page_num, review_url) {\n  url_reviews <- paste0(review_url, \"&pageNumber=\", page_num, \"&sortBy=recent\")\n  doc <- read_html(url_reviews)\n  map_dfr(doc %>% html_elements(\"[id^='customer_review']\"), ~ data.frame(\n    review_title = .x %>% html_element(\".review-title\") %>% html_text2(),\n    review_text = .x %>% html_element(\".review-text-content\") %>% html_text2(),\n    review_star = .x %>% html_element(\".review-rating\") %>% html_text2(),\n    date = .x %>% html_element(\".review-date\") %>% html_text2() %>% gsub(\".*vom \", \"\", .),\n    author = .x %>% html_element(\".a-profile-name\") %>% html_text2(),\n    page = page_num\n  )) %>%\n    as_tibble %>%\n    return()\n}\n\n\n\nDefine urls\n\nurl <- list(\n  p01 = \"https://www.amazon.de/LINEAVI-Eiwei%C3%9F-Shake-Kombination-Molkeneiwei%C3%9F-laktosefrei/product-reviews/B018IB02AU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n  p02 = \"https://www.amazon.de/Detoxkuren%E2%80%A2-Entw%C3%A4sserung-Entschlackung-Stoffwechsel-entschlacken/product-reviews/B072QW5ZN1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n  p03 = \"https://www.amazon.de/Saint-Nutrition%C2%AE-KETO-BURN-Appetitz%C3%BCgler/product-reviews/B08B67V8G5/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n  p04 = \"https://www.amazon.de/Yokebe-vegetarisch-Mahlzeitersatz-Gewichtsabnahme-hochwertigen/product-reviews/B08GYZ8LRB/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n  p05 = \"https://www.amazon.de/Vihado-Liquid-chlorophyll-drops-alfalfa/product-reviews/B093XNC8QH/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews\"\n)\n\n\np01 (Lineavi): 1.679 Gesamtbewertungen, 782 mit Rezensionen ‚Äì> 79 pages\np02 (DietySlim): 1.652 Gesamtbewertungen, 268 mit Rezensionen ‚Äì> 28 pages\np03 (Keto Burn): 3.341 Gesamtbewertungen, 540 mit Rezensionen ‚Äì> 55 pages\np04 (Yokebe): 1.586 Gesamtbewertungen, 156 mit Rezensionen ‚Äì> 16 pages\np05 (Vihado): 1.335 Gesamtbewertungen, 396 mit Rezensionen ‚Äì> 40 pages\n\n\n\nScrape data\n\namazon <- list()\n# p01 \nfor (i in 1:79) {\n  df <- scrape_amazon(page_num = i, review_url = url$p01)\n  amazon$raw$p01[[i]] <- df\n}\n# p02\nfor (i in 1:28) {\n  df <- scrape_amazon(page_num = i, review_url = url$p02)\n  amazon$raw$p02[[i]] <- df\n}\n# p03\nfor (i in 1:55) {\n  df <- scrape_amazon(page_num = i, review_url = url$p03)\n  amazon$raw$p03[[i]] <- df\n}\n# p04\nfor (i in 1:16) {\n  df <- scrape_amazon(page_num = i, review_url = url$p04)\n  amazon$raw$p04[[i]] <- df\n}\n# p05\nfor (i in 1:40) {\n  df <- scrape_amazon(page_num = i, review_url = url$p05)\n  amazon$raw$p05[[i]] <- df\n}\n\n\n\nBind rows\n\nproduct <- names(url)\n# bind rows for each product\nfor (i in product) {\n  amazon$data$raw[[i]] <- amazon$raw[[i]] %>% \n    bind_rows() %>% \n    rownames_to_column(\"id\") %>% \n    mutate(across(id, as.numeric))\n}\n# bind rows of all products\namazon$data$full <- amazon$data$raw %>% \n  bind_rows(.id = \"src\")\n\n\n\nSave data\n\nsaveRDS(\n  amazon,\n  file = here(\"data/08-text_as_data/reviews_only.RDS\"))"
  },
  {
    "objectID": "content/08-text_as_data/08-exercise.html#data-processing",
    "href": "content/08-text_as_data/08-exercise.html#data-processing",
    "title": "Showcase",
    "section": "Data processing",
    "text": "Data processing\n\namazon$data$clean <- amazon$data$full %>% \n  # create doc_id\n  rownames_to_column(., var = \"doc_id\") %>% \n  mutate(\n    # create unique ids (src_id, doc_id)\n    src_id = id, \n    id = paste(src, sprintf(\"%03d\", id), sep = \"_\"),\n    # convert to factor\n    across(c(id, src), as.factor),\n    across(doc_id, as.numeric),\n        # review body\n    review_body = paste(review_title, review_text),\n    body_trimmed = str_replace_all(review_body, \"[\\r\\n]\" , \"\"), # delete line breaks\n    lang_detect = fastText::language_identification(\n      body_trimmed,\n      system.file(\"language_identification/lid.176.ftz\", package = \"fastText\")),\n    lang = lang_detect$iso_lang_1,\n    lang_prob = lang_detect$prob_1,\n    # edit date variable\n    date_raw = date,\n    date_base = str_extract(date_raw, \"\\\\d{1,2}(.*)\\\\d{1,4}\"),\n    ## Change date format to DD.MM.YYYY\n    across(date_base, str_replace, \" Januar \", \"01.\"),\n    across(date_base, str_replace, \" Februar \", \"02.\"),\n    across(date_base, str_replace, \" M√§rz \", \"03.\"),\n    across(date_base, str_replace, \" April \", \"04.\"),\n    across(date_base, str_replace, \" Mai \", \"05.\"),\n    across(date_base, str_replace, \" Juni \", \"06.\"),\n    across(date_base, str_replace, \" Juli \", \"07.\"),\n    across(date_base, str_replace, \" August \", \"08.\"),\n    across(date_base, str_replace, \" September \", \"09.\"),\n    across(date_base, str_replace, \" Oktober \", \"10.\"),\n    across(date_base, str_replace, \" November \", \"11.\"),\n    across(date_base, str_replace, \" Dezember \", \"12.\"),\n    ## Convert to date\n    date = as.Date(date_base, format = \"%d.%m.%Y\"),\n    ## create date variables\n    year = as.factor(year(date)),\n    month = as.factor(month(date)),\n    day = as.factor(day(date)),\n    rating  = as.numeric(str_extract(review_star, \"\\\\d{1}(?=,)\")) \n    ) %>% \n  # relcoate variables\n  relocate(starts_with(\"src\"), .after = id) %>%\n  relocate(starts_with(\"date\"), .after = src_id) %>%\n  relocate(year,month,day, .before = review_title) %>%\n  relocate(starts_with(\"lang\"), .after = page) %>% \n  relocate(starts_with(\"review\"), .after = lang_prob) %>%\n  relocate(review_star, .after = body_trimmed)\n\n\nCheck language identification\n\nLanguages\n\namazon$data$clean %>% \n  frq(lang)\n\nlang <character> \n# total N=2142 valid N=2142 mean=2.67 sd=1.52\n\nValue |    N | Raw % | Valid % | Cum. %\n---------------------------------------\nals   |    1 |  0.05 |    0.05 |   0.05\nde    | 1736 | 81.05 |   81.05 |  81.09\nen    |   57 |  2.66 |    2.66 |  83.75\nes    |   39 |  1.82 |    1.82 |  85.57\nfr    |    1 |  0.05 |    0.05 |  85.62\nit    |  292 | 13.63 |   13.63 |  99.25\nnl    |    5 |  0.23 |    0.23 |  99.49\npl    |    1 |  0.05 |    0.05 |  99.53\npt    |    2 |  0.09 |    0.09 |  99.63\nsk    |    2 |  0.09 |    0.09 |  99.72\nsr    |    3 |  0.14 |    0.14 |  99.86\nsv    |    1 |  0.05 |    0.05 |  99.91\ntr    |    2 |  0.09 |    0.09 | 100.00\n<NA>  |    0 |  0.00 |    <NA> |   <NA>\n\n\n\n\nIdentification probability\n\namazon$data$clean %>% \n  group_by(lang) %>% \n  summarise(\n    n = n(), \n    prob = mean(lang_prob)\n  )\n\n# A tibble: 13 √ó 3\n   lang      n  prob\n   <chr> <int> <dbl>\n 1 als       1 0.861\n 2 de     1736 0.979\n 3 en       57 0.565\n 4 es       39 0.900\n 5 fr        1 0.930\n 6 it      292 0.963\n 7 nl        5 0.566\n 8 pl        1 0.999\n 9 pt        2 0.687\n10 sk        2 0.694\n11 sr        3 0.510\n12 sv        1 0.482\n13 tr        2 0.992\n\n\n\n\n\nSelect only german reviews\n\namazon$data$de <- amazon$data$clean %>% \n  filter(lang == \"de\")"
  },
  {
    "objectID": "content/08-text_as_data/08-exercise.html#exploratory-data-analysis",
    "href": "content/08-text_as_data/08-exercise.html#exploratory-data-analysis",
    "title": "Showcase",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nNumber of reviews by product\n\namazon$data$de %>% \n  frq(src)\n\nsrc <categorical> \n# total N=1736 valid N=1736 mean=2.88 sd=1.46\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\np01   | 438 | 25.23 |   25.23 |  25.23\np02   | 256 | 14.75 |   14.75 |  39.98\np03   | 509 | 29.32 |   29.32 |  69.30\np04   | 143 |  8.24 |    8.24 |  77.53\np05   | 390 | 22.47 |   22.47 | 100.00\n<NA>  |   0 |  0.00 |    <NA> |   <NA>\n\n\n\n\nReviews by year\n\namazon$data$de %>% \n  ggplot(aes(year, fill = src)) +\n  geom_bar() +\n  scale_fill_locuszoom() +\n  theme_pubr()\n\n\n\n\n\n\nRatings by product\n\namazon$data$de %>% \n  mutate(across(rating, as.factor)) %>% \n  ggplot(aes(src, fill = rating)) + \n  geom_bar() +\n  scale_fill_brewer(palette = \"RdYlGn\") +\n  theme_pubr()\namazon$data$de %>% \n  mutate(across(rating, as.factor)) %>% \n  ggplot(aes(src, fill = rating)) + \n  geom_bar(position = \"fill\") +\n  scale_fill_brewer(palette = \"RdYlGn\") +\n  theme_pubr()\n\n\n\n\n\n\nAbsolute\n\n\n\n\n\n\n\nRelative\n\n\n\n\n\n\nRating by product"
  },
  {
    "objectID": "content/08-text_as_data/08-exercise.html#sentiment-analysis",
    "href": "content/08-text_as_data/08-exercise.html#sentiment-analysis",
    "title": "Showcase",
    "section": "Sentiment analysis",
    "text": "Sentiment analysis\n\nCreate data (temporary corpora)\n\n\n\n\nLocation parameters\n\namazon$temp$crps_stats %>% \n  select(types, tokens, sentences) %>%\n  descr()\n\n\n## Basic descriptive statistics\n\n       var    type     label    n NA.prc  mean    sd   se md trimmed\n     types integer     types 1736      0 41.92 41.83 1.00 31   34.91\n    tokens integer    tokens 1736      0 56.16 74.06 1.78 36   42.78\n sentences integer sentences 1736      0  3.56  3.39 0.08  3    2.93\n         range iqr skew\n   459 (1-460)  37 3.38\n 1128 (2-1130)  48 5.56\n     37 (1-38)   4 3.39\n\n\n\n\nLength of reviews by source\n\n# add sample size\nsample_size <- amazon$temp$crps_stats %>% \n  group_by(src) %>% \n  summarise(n = n())\namazon$temp$crps_stats %>% \n  # Add sample size as label\n  left_join(sample_size) %>% \n  mutate(src_label = paste0(src, \"\\n\", \"(n = \", n, \")\")) %>% \n  ggboxplot(\"src_label\", \"tokens\", \n            color = \"src\", palette = \"startrek\",\n            orientation = \"horizontal\") +\n  labs(x = \"\", y = \"Number of tokens\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nJoin datasets\n\n\n\n\n\nPolarity by product\n\namazon$data$de_senti %>% \n  ggplot(aes(x = src, y = polarity)) + \n  ggdist::stat_halfeye(\n    aes(fill = src),\n    adjust = .5, \n    width = .6, \n    .width = 0, \n    justification = -.3, \n    point_colour = NA) + \n  geom_boxplot(\n    aes(color = src),\n    width = .25, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    aes(color = src),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter(\n      seed = 1, width = .1\n    )\n  ) + \n  coord_cartesian(xlim = c(1.2, NA), clip = \"off\") +\n  scale_color_startrek() +\n  scale_fill_startrek() +\n  theme_pubr()\n\n\n\n\n\n\nValence by product\n\namazon$data$de_senti %>% \n  ggplot(aes(x = src, y = valence)) + \n  ggdist::stat_halfeye(\n    aes(fill = src),\n    adjust = .5, \n    width = .6, \n    .width = 0, \n    justification = -.3, \n    point_colour = NA) + \n  geom_boxplot(\n    aes(color = src),\n    width = .25, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    aes(color = src),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter(\n      seed = 1, width = .1\n    )\n  ) + \n  coord_cartesian(xlim = c(1.2, NA), clip = \"off\") +\n  scale_color_startrek() +\n  scale_fill_startrek() +\n  theme_pubr()\n\n\n\n\n\n\nRatings by categorical valence\n\namazon$data$de_senti %>% \n  flat_table(rating, val_fct)\n\n       val_fct negativ neutral positiv\nrating                                \n1                  167      40     101\n2                   61      11      37\n3                   47      14      48\n4                   34      10     129\n5                  109      16     912"
  },
  {
    "objectID": "content/08-text_as_data/08-exercise.html#topic-modeling",
    "href": "content/08-text_as_data/08-exercise.html#topic-modeling",
    "title": "Showcase",
    "section": "Topic Modeling",
    "text": "Topic Modeling\n\nPreparation\n\nText Processing\n\n\n\n\n\nGet top features of dfm\n\ntextstat_frequency(\n  amazon$txt$dfm, n = 50)\n\n       feature frequency rank docfreq group\n1          gut       702    1     511   all\n2      produkt       609    2     476   all\n3    geschmack       516    3     419   all\n4     schmeckt       414    4     340   all\n5      tropfen       359    5     199   all\n6        schon       335    6     280   all\n7         dass       328    7     233   all\n8        super       296    8     249   all\n9         mehr       283    9     223   all\n10      wasser       261   10     210   all\n11         mal       257   11     199   all\n12     wirkung       243   12     195   all\n13      leider       232   13     187   all\n14         tag       228   14     174   all\n15       nehme       226   15     209   all\n16       shake       225   16     131   all\n17      wochen       219   17     179   all\n18        seit       210   18     190   all\n19    wirklich       208   19     169   all\n20     lineavi       207   20     127   all\n21     einfach       192   21     163   all\n22       sagen       186   22     171   all\n23   empfehlen       181   23     162   all\n24      besser       177   24     157   all\n25   zufrieden       170   25     155   all\n26       tagen       168   26     144   all\n27       immer       165   27     145   all\n28     kapseln       154   28     116   all\n29    abnehmen       151   29     132   all\n30  abgenommen       147   30     136   all\n31          kg       146   31     109   all\n32       woche       146   31     121   all\n33      shaker       142   33     104   all\n34 chlorophyll       141   34      99   all\n35        ganz       136   35     122   all\n36       f√ºhle       136   35     127   all\n37       finde       133   37     113   all\n38       sport       133   37     116   all\n39     schnell       133   37     121   all\n40      leicht       126   40     116   all\n41       hilft       123   41     106   all\n42       macht       122   42     108   all\n43        satt       119   43      98   all\n44   ern√§hrung       119   43     108   all\n45        kilo       117   45      89   all\n46     weniger       117   45      95   all\n47      ersten       111   47      89   all\n48       gutes       111   47     102   all\n49    bestellt       107   49     102   all\n50        zeit       106   50      98   all\n\n\n\n\nConvert dfm to stm\n\namazon$tpm$dfm <- convert(amazon$txt$dfm, to = \"stm\")\n\n\n\n\nChoose topic number\n\nk = 0\n\ntic(\"choose_k_free\")\namazon$tpm$nullmdl <- \n  stm(\n    documents = dfm_stm$documents,\n    vocab = dfm_stm$vocab, \n    prevalence =~ src,\n    K = 0, \n    seed = 42,\n    max.em.its = 1000,\n    data = dfm_stm$meta,\n    init.type = \"Spectral\",\n    verbose = FALSE\n  )\ntoc(log = TRUE)\n\n\namazon$tpm$nullmdl\n\nA topic model with 44 topics, 1730 documents and a 765 word dictionary.\n\n\n\n\nk = c(3:20)\n\ntopic_range <- c(3:20) # set topic range based on consistency statistics\n# Plan\nfuture::plan(future::multisession, workers = 6) # use multiple cores\n# Fit models\ntic(\"choose_k_intervall\")\namazon$tpm$stm <- tibble(k = topic_range) %>%\n  mutate(mdl = furrr::future_map(k, ~stm::stm(\n    documents = dfm_stm$documents,\n    vocab = dfm_stm$vocab, \n    prevalence =~ src,\n    K = ., \n    seed = 42,\n    max.em.its = 1000,\n    data = dfm_stm$meta,\n    init.type = \"Spectral\",\n    verbose = FALSE),\n    .options = furrr::furrr_options(seed = 42))\n  )\ntoc(log = TRUE)\n\n\n\n\nChoose model\n\n# Create heldout data\namazon$tpm$heldout <- make.heldout(\n  documents = amazon$tpm$dfm$documents,\n  vocab = amazon$tpm$dfm$vocab,\n  seed = 42)\n# create evaluation\namazon$tpm$model_scores <- amazon$tpm$stm %>% \n  mutate(\n    exclusivity = map(mdl, exclusivity),\n    semantic_coherence = map(mdl,semanticCoherence, amazon$tpm$dfm$documents),\n    eval_heldout = map(mdl, eval.heldout, amazon$tpm$heldout$missing),\n    residual = map(mdl, checkResiduals, amazon$tpm$dfm$documents),\n    bound =  map_dbl(mdl, function(x) max(x$convergence$bound)),\n    lfact = map_dbl(mdl, function(x) lfactorial(x$settings$dim$K)),\n    lbound = bound + lfact,\n    iterations = map_dbl(mdl, function(x) length(x$convergence$bound)))\n\n\namazon$tpm$model_scores %>% \n  transmute(\n    k,\n    `Lower bound` = lbound,\n    Residuals = map_dbl(residual, \"dispersion\"),\n    `Semantic coherence` = map_dbl(semantic_coherence, mean),\n    `Held-out likelihood` = map_dbl(eval_heldout, \"expected.heldout\")) %>% \n  tibble()\n\n# A tibble: 18 √ó 5\n       k `Lower bound` Residuals `Semantic coherence` `Held-out likelihood`\n   <int>         <dbl>     <dbl>                <dbl>                 <dbl>\n 1     3      -173925.      2.16                -79.2                 -5.77\n 2     4      -171930.      2.21                -85.6                 -5.72\n 3     5      -171599.      2.18                -87.0                 -5.67\n 4     6      -170066.      2.09                -92.3                 -5.53\n 5     7      -170113.      2.16                -96.4                 -5.55\n 6     8      -169722.      2.16               -102.                  -5.48\n 7     9      -169448.      2.06               -101.                  -5.41\n 8    10      -168686.      2.07               -103.                  -5.34\n 9    11      -168933.      1.98                -97.8                 -5.28\n10    12      -168887.      1.91               -108.                  -5.31\n11    13      -168528.      1.89               -109.                  -5.29\n12    14      -167971.      1.92               -110.                  -5.27\n13    15      -167892.      1.75               -114.                  -5.23\n14    16      -168070.      1.69               -115.                  -5.22\n15    17      -167441.      1.73               -113.                  -5.15\n16    18      -167422.      1.65               -116.                  -5.11\n17    19      -167440.      1.62               -123.                  -5.12\n18    20      -167250.      1.59               -119.                  -5.10\n\n\n\namazon$tpm$model_scores %>% \n  transmute(\n    k,\n    `Lower bound` = lbound,\n    Residuals = map_dbl(residual, \"dispersion\"),\n    `Semantic coherence` = map_dbl(semantic_coherence, mean),\n    `Held-out likelihood` = map_dbl(eval_heldout, \"expected.heldout\")) %>%   \n  pivot_longer(-k, names_to = \"Metric\", values_to = \"Value\") %>% \n  ggplot(\n    aes(k, Value, color = Metric)) +\n  geom_line(size = 1.5, alpha = 0.7, show.legend = FALSE) +\n  facet_wrap(~Metric, scales = \"free_y\") +\n  labs(x = \"K (number of topics)\",\n       y = NULL,\n       title = \"Model diagnostics by number of topics\")\n\n\n\n\n\nExclusivity by Coherence\n\namazon$tpm$model_scores %>%\n  select(k, exclusivity, semantic_coherence) %>%\n  filter(k %in% c(5, 7, 11)) %>%\n  unnest(cols = c(exclusivity, semantic_coherence)) %>%\n  mutate(k = as.factor(k)) %>%\n  ggplot(aes(semantic_coherence, exclusivity, color = k)) +\n  geom_point(size = 2, alpha = 0.7) +\n  labs(x = \"Semantic coherence\",\n       y = \"Exclusivity\",\n       title = \"Comparing exclusivity and semantic coherence\",\n       subtitle = \"Models with fewer topics have higher semantic coherence for more topics, but lower exclusivity\")"
  },
  {
    "objectID": "content/08-text_as_data/08-exercise.html#model-understanding",
    "href": "content/08-text_as_data/08-exercise.html#model-understanding",
    "title": "Showcase",
    "section": "Model understanding",
    "text": "Model understanding\n\nSelect model\n\namazon$stm$mdl <- amazon$tpm$stm %>% \n  filter(k == 5) %>% \n  pull(mdl) %>% \n  .[[1]]\n# Get stm statistics\namazon$stm$mdl\n\nA topic model with 5 topics, 1730 documents and a 765 word dictionary.\n\n\n\n\nInterpretation\n\namazon$stm$mdl %>% labelTopics()\n\nTopic 1 Top Words:\n     Highest Prob: tropfen, geschmack, chlorophyll, wasser, wirkung, schmeckt, schon \n     FREX: tropfen, chlorophyll, glas, gr√ºn, farbe, flasche, konnten \n     Lift: alfalfa, dosieren, farbe, frisch, geladen, glas, gr√ºne \n     Score: tropfen, chlorophyll, farbe, gr√ºn, geladen, medien, wirkung \nTopic 2 Top Words:\n     Highest Prob: produkt, super, nehme, seit, mehr, sagen, wirklich \n     FREX: nehme, gutes, begeistert, seit, wirkt, hilft, √ºberrascht \n     Lift: begeistert, detox, entgiften, entschlacken, gutes, pfirsich, teste \n     Score: produkt, seit, nehme, weiteren, super, gutes, hilft \nTopic 3 Top Words:\n     Highest Prob: gut, dass, tag, tagen, ganz, finde, besser \n     FREX: ganz, finde, m√∂chte, produkte, tagen, anfang, wenig \n     Lift: anfang, soweit, generell, produkte, komisch, versucht, m√∂chte \n     Score: gut, generell, finde, dass, ganz, tag, tagen \nTopic 4 Top Words:\n     Highest Prob: schmeckt, geschmack, shake, lineavi, shaker, pulver, lecker \n     FREX: shake, lineavi, shaker, pulver, lecker, shakes, almased \n     Lift: anleitung, dosen, ersetzt, aktivkost, almased, classic, di√§tshake \n     Score: lineavi, shaker, shake, almased, pulver, shakes, milch \nTopic 5 Top Words:\n     Highest Prob: schon, wochen, leider, kapseln, abgenommen, sport, abnehmen \n     FREX: kapseln, abgenommen, tabletten, geld, bringt, sport, schlucken \n     Lift: abgenommen, achten, burn, gebracht, gegenteil, geld, geldverschwendung \n     Score: kapseln, tabletten, keto, burn, abgenommen, sport, kilo \n\n\n\nHighest Prob\n\nlabelTopics(amazon$stm$mdl, n = 15)$prob %>%\n  t() %>% \n  as.data.frame() %>% \n  janitor::clean_names() %>% \n  tibble() %>% \n  rename_with(.fn = ~ stringr::str_replace(., \"v\", \"topic_\"), .cols = v1:v5) %>% \n  paged_table()\n\n\n\n  \n\n\n\n\nlabelTopics(amazon$stm$mdl, n = 15)$prob%>%\n  as.data.frame() %>% \n  janitor::clean_names() %>% \n  tibble() %>% \n  rownames_to_column(var = \"topic\") %>% \n  mutate(prob = paste(v1,v2,v3,v4,v5,v6,v7,v8,v9,v10,\n                      v11, v12, v13, v14, v15, \n                      sep = \"; \")) %>% \n  select(topic, prob) %>% \n  kbl() %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\n\n\n \n  \n    topic \n    prob \n  \n \n\n  \n    1 \n    tropfen; geschmack; chlorophyll; wasser; wirkung; schmeckt; schon; f√ºhle; glas; gut; fitter; einfach; flasche; gr√ºn; immer \n  \n  \n    2 \n    produkt; super; nehme; seit; mehr; sagen; wirklich; zufrieden; hilft; leicht; geschmack; gutes; wirkt; erst; k√∂rper \n  \n  \n    3 \n    gut; dass; tag; tagen; ganz; finde; besser; wasser; nehmen; macht; geht; trinke; wenig; allerdings; m√∂chte \n  \n  \n    4 \n    schmeckt; geschmack; shake; lineavi; shaker; pulver; lecker; shakes; satt; mal; immer; schon; almased; di√§t; einfach \n  \n  \n    5 \n    schon; wochen; leider; kapseln; abgenommen; sport; abnehmen; mal; wirkung; ern√§hrung; empfehlen; kg; kilo; tabletten; woche \n  \n\n\n\n\n\n\n\nFREX\n\nlabelTopics(amazon$stm$mdl, n =15)$frex %>%\n  t() %>% \n  as.data.frame() %>% \n  janitor::clean_names() %>% \n  tibble() %>% \n  rename_with(.fn = ~ stringr::str_replace(., \"v\", \"topic_\"), .cols = v1:v5) %>% \n  paged_table() \n\n\n\n  \n\n\n\n\nlabelTopics(amazon$stm$mdl, n =15)$prob %>%\n  as.data.frame() %>% \n  janitor::clean_names() %>% \n  tibble() %>% \n  rownames_to_column(var = \"topic\") %>% \n  mutate(prob = paste(v1,v2,v3,v4,v5,v6,v7,v8,v9,v10,\n                      v11, v12, v13, v14, v15, \n                      sep = \"; \")) %>% \n  select(topic, prob) %>% \n  kbl() %>% \n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\n\n\n \n  \n    topic \n    prob \n  \n \n\n  \n    1 \n    tropfen; geschmack; chlorophyll; wasser; wirkung; schmeckt; schon; f√ºhle; glas; gut; fitter; einfach; flasche; gr√ºn; immer \n  \n  \n    2 \n    produkt; super; nehme; seit; mehr; sagen; wirklich; zufrieden; hilft; leicht; geschmack; gutes; wirkt; erst; k√∂rper \n  \n  \n    3 \n    gut; dass; tag; tagen; ganz; finde; besser; wasser; nehmen; macht; geht; trinke; wenig; allerdings; m√∂chte \n  \n  \n    4 \n    schmeckt; geschmack; shake; lineavi; shaker; pulver; lecker; shakes; satt; mal; immer; schon; almased; di√§t; einfach \n  \n  \n    5 \n    schon; wochen; leider; kapseln; abgenommen; sport; abnehmen; mal; wirkung; ern√§hrung; empfehlen; kg; kilo; tabletten; woche \n  \n\n\n\n\n\n\n\nPrevalence\n\namazon$stm$preval <- list(\n  terms_beta = amazon$stm$mdl %>% tidy(),\n  doc_gamma = amazon$stm$mdl %>% tidy(\"gamma\")\n)\namazon$stm$preval$top_terms <- amazon$stm$preval$terms_beta %>% \n  arrange(., beta) %>%\n  group_by(topic) %>%\n  top_n(10, beta) %>%\n  arrange(-beta) %>%\n  select(topic, term) %>%\n  summarise(terms = list(term)) %>%\n  mutate(terms = map(terms, paste, collapse = \", \")) %>%\n  unnest(cols = c(terms))\n  \namazon$stm$preval$top_topics <- amazon$stm$preval$doc_gamma %>%\n  group_by(., topic) %>%\n  summarise(gamma = mean(gamma)) %>%\n  arrange(desc(gamma))\namazon$stm$preval$tgt <- amazon$stm$preval$top_topics %>% \n  left_join(amazon$stm$preval$top_terms, by = \"topic\") %>%\n  mutate(topic = paste0(\"Topic \", topic),\n         topic = reorder(topic, gamma))\n\n\nVisual\n\namazon$stm$preval$tgt  %>% \n  ggplot(aes(topic, gamma, label = terms, fill = topic)) +\n  geom_col(show.legend = FALSE) +\n  geom_text(hjust = 1.1, nudge_y = 0.0005, size = 3, color = \"white\") +\n  coord_flip() +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.35), labels = scales::percent) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank(),\n        panel.grid.major = element_blank()) +\n  labs(x = NULL, y = expression(gamma)) +\n  scale_fill_jama()"
  },
  {
    "objectID": "content/08-text_as_data/08-exercise.html#topic-analysis",
    "href": "content/08-text_as_data/08-exercise.html#topic-analysis",
    "title": "Showcase",
    "section": "Topic Analysis",
    "text": "Topic Analysis\n\nPreparation\n\nGet gamma statistics for the documents\n\namazon$stm$merge <- list(\n  doc_gamma_wide = amazon$stm$preval$doc_gamma %>% \n    group_by(document) %>% \n    pivot_wider(\n      id_cols = document,\n      names_from = \"topic\", \n      names_prefix = \"gamma_topic_\",\n      values_from = \"gamma\") %>% \n    rename(doc_id_gamma = document),\n  doc_gamma_top = amazon$stm$preval$doc_gamma %>%\n    group_by(document) %>% \n    slice_max(gamma) %>% \n    rename(\n      top_topic = topic,\n      top_gamma = gamma)\n  )\n\n\n\nJoin with original data set\n\namazon$data$tpm <- amazon$data$de_senti %>% \n  filter(\n    doc_id != 108 & doc_id != 790 &\n    doc_id != 914 & doc_id!= 1328 &\n    doc_id != 1349 & doc_id != 1706) %>% \n  bind_cols(amazon$stm$merge$doc_gamma_top) %>% \n  fastDummies::dummy_cols(., select_columns = c(\"top_topic\")) %>% \n  bind_cols(amazon$stm$merge$doc_gamma_wide) %>% \n  select(!doc_id_gamma) %>% \n  mutate(across(top_topic, as.factor))\n\n\n\n\n\n\n\nAnalysis\n\nTopic over years\n\namazon$data$tpm %>% \n  ggplot(aes(year, fill = top_topic)) +\n  geom_bar() +\n  scale_fill_locuszoom() +\n  theme_pubr()\n\n\n\n\n\n\nTopic by product\n\namazon$data$tpm %>% \n  flat_table(top_topic, src)\n\n          src p01 p02 p03 p04 p05\ntop_topic                        \n1               0   8   0   0 372\n2               3 164  28   0  14\n3               1  10   2   0   0\n4             407   0   0 128   0\n5              26  72 477  14   4\n\n\n\n\nTop reviews by topic\n\nPreparation\n\ntop_stories <- list()\nselect_topic <- paste0(\"_\", seq(from = 1, to = 5, by = 1))\nfor (i in select_topic) {\n  i_gamma <- paste0(\"gamma_topic\", i)\n  i_topic <- paste0(\"top_topic\", i)\n  \n  top_stories[[i_gamma]] <- \n    amazon$data$tpm[order(amazon$data$tpm[i_gamma], decreasing = TRUE),] |>\n    select(id, date, src, review_title, review_text, review_star,\n           valence, polarity, pol_fct, val_fct,\n           top_gamma, all_of(i_gamma),\n           top_topic, all_of(i_topic), review_body) |>\n    rename(\n      gamma = all_of(i_gamma),\n      top_topic_d = all_of(i_topic)\n      ) |>\n    dicho(gamma, dich.by = 0.49, suffix = \"_d\") |>\n    mutate(\n      across(top_topic_d, as.factor),\n      gamma_top  = case_when(top_topic_d == 1 ~ gamma, TRUE ~ NA_real_),\n      gamma_main = case_when(gamma_d == 1 ~ gamma, TRUE ~ NA_real_),\n    ) |>\n    relocate(review_body, .after = top_topic) \n  }\n\n\n\nCreate output\n\nlibrary(sjlabelled)\noutput <- list()\ngamma_topics <- amazon$data$tpm %>% \n  select(starts_with(\"gamma_topic_\")) %>% \n  colnames()\nfor (i in gamma_topics) {\n  # Create dataset\n  output[[i]]$data <- top_stories[[i]] |>\n    filter(top_topic_d == 1)\n  \n  # Create crosstable\n  ## top_topic_d == Dummy: Is i the top topic (== highest relative gamma) of the story\n  ## gamma_d     == Dummy: Is i higher than 0.5 (== highest absolute gamma) of the story\n  output[[i]]$crosstable <- top_stories[[i]] |>\n    select(top_topic_d, gamma_d) %>% \n    mutate(\n      across(everything(), add_labels, labels = c(\"No\" = 0, \"Yes\" = 1)),\n      across(top_topic_d, set_label, label = \"Highest realtive gamma\"),\n      across(gamma_d, set_label, label = \"Highest absolute gamma\")\n    ) |>\n    label_to_colnames() |>\n    flat_table()\n  # Create descriptive statistics: location parameters for different gammas\n  ## gamma_top = only articles where i is the top topic (== highest relative beta)\n  ## gamma_main = only articles where i is the main topic (== highest absolute beta)\n  output[[i]]$desc_gamma <- top_stories[[i]] |>\n     select(gamma_top, gamma_main) |>\n     mutate(\n       across(gamma_top, set_label, label = \"Highest realtive gamma\"),\n       across(gamma_main, set_label, label = \"Highest absolute gamma\")\n       ) |>\n       descr(show = c(\"label\", \"n\", \"NA.prc\", \"mean\", \"sd\", \"se\", \"md\", \"range\"))\n }\n\n\nprint_output_descriptives <- function(x) {\n  # Loop\n  for (i in x) {\n    # Headline\n    cat(paste(\"Results for\", i, \"\\n\"))\n    # Mutli-topic abstracts\n    glue(\"## Check for ambiguous topic assignment for review:\nComments: \n- Highest relative gamma: Is {i} the top topic of the abstract?\n- Highest absolute gamma: Is the gamme value for {i} higher than 0.5\n \\n\") |> print()\n    # Crosstable \n   output[[i]]$crosstable |> print()\n    # Location parameters\n   output[[i]]$desc_gamma |> print()\n  }\n}\nprint_output_abstracts <- function(x) {\n  # Loop\n  for (i in x) {\n    for (j in c(1:5)) {\n      glue(\"\n           ***************************************************\n           \n           ID: {output[[i]]$data$id[[j]]} \\n\n           Date: {output[[i]]$data$date[[j]]} \\n\n           Title: {output[[i]]$data$review_title[[j]]} \\n\n           Gamma: {round(output[[i]]$data$gamma[[j]],3)} \\n\n           Review: \\r\n           {output[[i]]$data$review_text[[j]]} \\n\n           Rating: {output[[i]]$data$review_star[[j]]} \\n\n           Valence: {output[[i]]$data$val_fct[[j]]} ({round(output[[i]]$data$valence[[j]],3)}) \\n\n           Polarity: {output[[i]]$data$pol_fct[[j]]} ({round(output[[i]]$data$polarity[[j]],3)}) \n           \\n\\n\") |> print() \n    }\n  }\n}\n\n\n\nOutput by topics\n\nTopic 1Topic 2Topic 3Topic 4Topic 5\n\n\n\nprint_output_descriptives(gamma_topics[1])\n\nResults for gamma_topic_1 \n## Check for ambiguous topic assignment for review:\nComments: \n- Highest relative gamma: Is gamma_topic_1 the top topic of the abstract?\n- Highest absolute gamma: Is the gamme value for gamma_topic_1 higher than 0.5\n \n                       Highest absolute gamma   No  Yes\nHighest realtive gamma                                 \nNo                                            1350    0\nYes                                             93  287\n\n## Basic descriptive statistics\n\n        var                  label   n NA.prc mean   sd se   md\n  gamma_top Highest realtive gamma 380  78.03 0.55 0.09  0 0.55\n gamma_main Highest absolute gamma 287  83.41 0.59 0.07  0 0.58\n            range\n 0.51 (0.27-0.79)\n  0.3 (0.49-0.79)\n\n\n\nprint_output_abstracts(gamma_topics[1])\n\nID: p05_218\nDate: 2021-07-17\nTitle: Ich liebe dieses Gr√ºn!!!\nGamma: 0.788\nReview: Die Medien konnten nicht geladen werden. Dass Chlorophyll sehr gesund ist und viele positive Wirkungen hat, ist bekannt. Zumindest in den Kreisen, die sich damit besch√§ftigen. Gr√ºner Grass-Saft wird als ein wahres Wundermittel angepriesen, nur leider schmeckt er den Wenigsten. Ich kann ihn auch immer nur phasenweise trinken oder mische ihn dann mit Fr√ºchten etc. Dauerhaft konnte ich ihn leider noch nicht in mein Leben integrieren. Anders, diese wunderbaren Tropfen. Ich tr√§ufle sie morgens in ein Glas Wasser und beobachte erstmal wie sich das intensive Gr√ºn verteilt und nach und nach das Wasser einf√§rbt. Das ist fast wie Meditation f√ºr mich, weil es so sch√∂n aussieht. Danach trinke ich das Wasser und ja, es schmeckt auch nach Gras, aber nur leicht und es ist √ºberhaupt kein Problem es zu trinken. Ich liebe diese Tropfen. Das wird meine zuk√ºnftige Art des Chlorophyll Konsums sein :-)\nRating: 5,0 von 5 Sternen\nValence: positiv (0.018)\nPolarity: positiv (1.099)\n\nID: p05_267\nDate: 2021-07-02\nTitle: Schmecken frisch-grasig\nGamma: 0.764\nReview: Ich habe die Tropfen als Produkttester gratis erhalten. Chlorophyll soll mehrere gesundheitliche Vorteile bringen, aber das kann ich nicht bewerten. Die Tropfen haben eine sehr dunkle, bl√§ulich-gr√ºne Farbe. In einem mittelgro√üen Glas Wasser schmeckt man den grasigen geschmack kaum raus. Pur schmecken sie auch nicht schlimm.\nRating: 5,0 von 5 Sternen\nValence: negativ (-0.046)\nPolarity: neutral (0)\n\nID: p05_237\nDate: 2021-07-11\nTitle: Schnelle Lieferung, geschmacklich sehr gut\nGamma: 0.76\nReview: Die Lieferung war sehr schnell. Die Amwendung ist sehr einfach. 20 Tropfen In ein Glas Wasser und trinken. Geschmacklich sehr gut und l√§sst sich daher problemlos einnehmen. Die Farbe ist ein intensives gr√ºn.\nRating: 5,0 von 5 Sternen\nValence: positiv (0.124)\nPolarity: positiv (2.833)\n\nID: p05_205\nDate: 2021-07-22\nTitle: F√ºhlt sich gut an!\nGamma: 0.757\nReview: Die Medien konnten nicht geladen werden. Der erste Eindruck der Flasche ist schon positiv: zum Schutz vor Licht/Sonnenstrahlung ist die Flasche aus braunen Glas gefertiggt; und zwar aus sch√∂nem dunklem braunen Glas, so dass der F√ºllungsgrad so grade noch erkennbar, daf√ºr die Schutzwirkung umso besser ist. Und die Pipette ist stabil und gut dosierbar. Geruch und Geschmack sind so, wie ich mir den Geschmack von Chlorophyll vorstelle: riecht und schmeckt sehr dezent nach frischem zwischen den Fingern zerriebenen Gras. Farbe ist wunderbar tief-gr√ºn, verteilt sich gut im Wasser und l√§sst sich von daher sehr gut trinken. Ich habe es mir zur Angewohnheit gemacht, morgens auf n√ºchteren Magen ein Glas Wasser mit der empfohlenen Menge von 20 Tropfen zu trinken (d.h. eine Flasche h√§lt dann ca. 2 bis 2,5 Monate). Den ersten Monat habe ich jetzt fast rum. Ich habe vorher schon ziemlich gesund gelebt ‚Ä¶ nun ist eine weitere kleine Steigerung sp√ºrbar: Verdauung/Stuhl f√ºhlt sich noch besser an, als vorher, und fitter/vitaler f√ºhle ich mich auch. Werde von daher die Tropfen aufbrauchen und eine weitere Flasche anschaffen. Sollten sich weitere Verbesserungen oder ggfs. Verschlechterungen ergeben, werde ich dies hier kommentieren.\nRating: 5,0 von 5 Sternen\nValence: positiv (0.09)\nPolarity: positiv (1.551)\n\nID: p05_091\nDate: 2022-01-13\nTitle: Natur in einer Flasche.\nGamma: 0.755\nReview: Die Medien konnten nicht geladen werden. Es schmeckt nach fast gar nichts und riecht bisschen nach Wald. Man sp√ªrt nach dem Trinken mit bisschen kalten Wasser eine sehr intensive Erfrischung. Kann ich jedem empfehlen\nRating: 5,0 von 5 Sternen\nValence: negativ (-0.001)\nPolarity: positiv (0.511)\n\n\n\n\nprint_output_descriptives(gamma_topics[2])\n\nResults for gamma_topic_2 \n## Check for ambiguous topic assignment for review:\nComments: \n- Highest relative gamma: Is gamma_topic_2 the top topic of the abstract?\n- Highest absolute gamma: Is the gamme value for gamma_topic_2 higher than 0.5\n \n                       Highest absolute gamma   No  Yes\nHighest realtive gamma                                 \nNo                                            1521    0\nYes                                            200    9\n\n## Basic descriptive statistics\n\n        var                  label   n NA.prc mean   sd   se   md\n  gamma_top Highest realtive gamma 209  87.92 0.38 0.07 0.00 0.37\n gamma_main Highest absolute gamma   9  99.48 0.53 0.04 0.01 0.51\n            range\n 0.37 (0.24-0.61)\n 0.12 (0.49-0.61)\n\n\n\nprint_output_abstracts(gamma_topics[2])\n\nID: p03_515\nDate: 2020-08-24\nTitle: Super\nGamma: 0.61\nReview: Ich nutze das Produkt aktuell seit 10 Tagen und bin vollends zufrieden. Der Geschmack ist sehr angenehm, so f√§llt ein die Einnahme einfacher.Werde das Produkt auf jeden Fall weiterempfehlen!\nRating: 5,0 von 5 Sternen\nValence: positiv (0.267)\nPolarity: positiv (2.565)\n\nID: p03_522\nDate: 2020-08-17\nTitle: gutes Produkt , der Effekt ist Sp√ºrbar\nGamma: 0.584\nReview: Ich habe dieses Produkt bestellt da ich momentan verschiedene Fat Burner teste und √§hnlich wie bei dem anderen Produkt was ich 30 Tage verwendet habe ist die Wirkung auf leerem Magen stark zu sp√ºren. Verst√§rktes schwitzen und aufgedreht sein geh√∂rt bei Fat burnern f√ºr mich dazu , da es eine ankurbelnde Wirkung auf den Metabolismus hat. Gutes Produkt :) Geschmack ist Neutral wie es sein muss.\nRating: 5,0 von 5 Sternen\nValence: positiv (0.145)\nPolarity: positiv (1.099)\n\nID: p03_330\nDate: 2021-02-12\nTitle: Mein Begleiter in der Keto-Di√§t\nGamma: 0.566\nReview: Ich besch√§ftige mich nun bereits eine Weile mit dem Ketogenen-Lifestyle und bin auf dieses Produkt gesto√üen. Dieses nehme ich nun bereits paar Tage zu mir und merke sp√ºrbar, wie es meine Fettverbrennung steigert. W√ºrde raten, dazu gen√ºgend Wasser zu trinken da man schon merklich mehr ins Schwitzen kommt. Kaufempfehlung!\nRating: 5,0 von 5 Sternen\nValence: positiv (0.037)\nPolarity: positiv (1.946)\n\nID: p03_270\nDate: 2021-04-21\nTitle: Ab der ersten Tablette wirksam\nGamma: 0.526\nReview: Ab der ersten Tablette hatte ich irgendwie schon kaum mehr ein Hungergef√ºhl, Hei√ühunger, s√º√ükram usw) auch ist mir aufgefallen das ich viel schneller satt bin als vorher 5 volle Sterne‚Ä¶.\nRating: 5,0 von 5 Sternen\nValence: positiv (0.159)\nPolarity: positiv (1.946)\n\nID: p03_466\nDate: 2020-09-29\nTitle: Empfehlungswert\nGamma: 0.511\nReview: Ich empfehle dieses Produkt weiter, da ich es seit Paar Tage benutze, und es wirkt wirklich sehr gut .\nRating: 5,0 von 5 Sternen\nValence: positiv (0.372)\nPolarity: positiv (1.099)\n\n\n\n\nprint_output_descriptives(gamma_topics[3])\n\nResults for gamma_topic_3 \n## Check for ambiguous topic assignment for review:\nComments: \n- Highest relative gamma: Is gamma_topic_3 the top topic of the abstract?\n- Highest absolute gamma: Is the gamme value for gamma_topic_3 higher than 0.5\n \n                       Highest absolute gamma   No  Yes\nHighest realtive gamma                                 \nNo                                            1717    0\nYes                                             13    0\n\n## Basic descriptive statistics\n\n        var                  label  n NA.prc mean   sd   se   md\n  gamma_top Highest realtive gamma 13  99.25 0.32 0.07 0.02 0.29\n gamma_main Highest absolute gamma  0 100.00  NaN   NA   NA   NA\n           range\n 0.2 (0.26-0.46)\n -Inf (Inf--Inf)\n\n\n\nprint_output_abstracts(gamma_topics[3])\n\nID: p03_055\nDate: 2022-02-11\nTitle: Gew√∂hnungseffekt\nGamma: 0.458\nReview: Nach ein paar Tagen gew√∂hnt man sich an die Kapseln/ der K√∂rper. Einen ‚Äù Leistungs Abfall‚Äù, merke ich Mittags nicht mehr ganz so stark, je nach Tag. Abgenommen habe ich nicht. Ern√§hre mich √ºberwiegend ausgewogen, jeden Tag Obst und Gem√ºse, ja auch mal was S√ºsses ( dies in Ma√üen, nicht in Massen). Der Effekt k√∂nnte funktionieren mich noch etwas positiver ausfallen, bzgl des abnehmens. Sport betreibe ich wenig, daf√ºr t√§glich. Daf√ºr laufe ich t√§glich mehrfach die Treppen in unserem Haus hoch u runter etc\nRating: 5,0 von 5 Sternen\nValence: negativ (-0.022)\nPolarity: positiv (0.588)\n\nID: p01_134\nDate: 2018-05-02\nTitle: Ja ich habe abgenommen‚Ä¶\nGamma: 0.426\nReview: Nach zwei Geburten und Stress durch Arbeit sowie Trennung von meinem Mann hatte ich mit 1,58 m mittlerweile 70 kg gewogen (hatte sehr viel ohne nachzudenken in mich reingefuttert, vorher war ich bei 55 kg) und fand mich absolut nicht sch√∂n und unwohl. Da bin ich auf die Suche nach einem Unterst√ºtzer f√ºr den Anfang einer Di√§t gewesen und nach lesen vieler Rezensionen verschiedenster Produkte bei LINEAVI gelandet (3-er Pack). Ich starte voller Tatendrang mit der Turbo-Di√§t. Ich habe mich strickt dran gehalten und auch nur Wasser dazu getrunken und Gem√ºsebr√ºhe gegessen. Allerdings hatte ich am dritten Tag mit dem Kreislauf zu tun und Kopfschmerzen, so dass ich sofort auf die 2er-Dosis pro Tag wechselte und t√§glich eine normale Mahlzeit zu mir nahm. Da ich noch nicht genau wusste, was darf ich in welchem Ma√üe essen, lud ich mir zus√§tzlich eine App herunter, womit ich meine Werte, haupts√§chlich die Kalorien, gut √ºberwachen kann (das mache ich jetzt auch weiter). Da ich eher von der 3-Shakes-Variante gewechselt habe zur 2-Shakes-Varinate habe ich diese bis zum Tag 12 durchgezogen, danach t√§glich ein Shake. Allerdings muss ich sagen, obwohl ich nie mehr als die vorgeschriebenen L√∂ffel genommen habe, reicht die Portion bei mir nur f√ºr 28 Mahlzeiten (ich habe auch keine Berge auf den L√∂ffel gegeben). Allerdings muss ich ganz ehrlich gestehen, ich habe sehr schnell ein Hungergef√ºhl bzw. Magenknurren bekommen, manchmal schon nach einer halben Stunde, manchmal nach zwei (man muss schon ganz sch√∂n sein Ziel wollen, um nicht nachzugeben). Ich habe es versucht mit viel Wasser und Tee zu stillen, aber das ist mir nicht recht gelungen, das Knurren blieb. Aber ich habe nicht nachgegeben. Vom Geschmack her muss ich sagen, am Anfang habe ich den Shake mit Sonnenblumen√∂l anger√ºht. Das ging gar nicht. Dann habe ich mir Walnuss√∂l besorgt und damit ging es vom Geschmack. Es schmeckt etwas wie roher Kuchenteig, naja muss man m√∂gen. Bisschen ungewohnt ist die Konsistenz. So und jetzt kommt das Ergebnis: Ja ich habe abgenommen, genau genommen 4 kg in bisschen √ºber 14 Tagen, da ich ja den Anfang gestreckt habe. Das finde ich pers√∂nlich sch√∂n. Allerdings werde ich jetzt nicht weiter das LINEAVI nehmen sondern lieber auf gesunde Ern√§hrung umsteigen und dies mit meiner App √ºberwachen, da diese Trinks doch nicht ganz meins sind. Allerdings f√ºr den Einstieg war es f√ºr mich sehr gut, aber nichts auf Dauer. Empfehlen kann ich es auf jeden Fall, aber ich bin der Meinung, man muss stark sein um durchzuhalten. Der Shaker der dabei war, ist sehr praktisch und ohne Probleme zu verwenden, fast immer hat sich bei mir alles aufgel√∂st. Falls ich, was ich jetzt nicht hoffe, wieder einmal mehr Kilos habe als gew√ºnscht, w√ºrde ich dieses Produkt zum Einstieg auch verwenden.\nRating: 4,0 von 5 Sternen\nValence: positiv (0.065)\nPolarity: positiv (1.017)\n\nID: p03_237\nDate: 2021-05-28\nTitle: Oke\nGamma: 0.425\nReview: Ich hab‚Äôs f√ºr eine Freundin gekauft und ich gehe jetzt einfach mal ihre Bewertung ab sie hat mir erz√§hlt dass sie nicht mehr so viel Hunger hat und so aber man wird dadurch nicht D√∂ner Mann nimmt nicht ab es passiert gar nichts meiner Meinung nach ist es eine Verschwendung des Geld daf√ºr auszugeben allerdings wenn du fress Attacken hast und Ern√§hrungserg√§nzungsmittel brauchst ist es gut aber dann kannst du dir auch im DM f√ºr 4,59 ‚Ç¨ ein Ern√§hrungserg√§nzungsmittel kaufen das meiner Meinung nach genauso gut ist\nRating: 3,0 von 5 Sternen\nValence: negativ (-0.02)\nPolarity: neutral (0)\n\nID: p02_216\nDate: 2020-06-19\nTitle: Hilft bei mir super gegen Bl√§hbauch und Cellulite\nGamma: 0.359\nReview: Ich bin jetzt in der 3. Woche und habe eine Flasche leergetrunken bzw. die zweite jetzt angefangen.Hier mein Zwischenbericht:Gekauft hatte ich Dietyslim nach dem Motto: klingt nicht schlecht.. mal gucken, ob‚Äôs was taugt.Dank dieser Larifari-Einstellung habe ich leider keine Fotos gemacht, mit denen ich die tollen Ergebnisse jetzt h√§tte vorzeigen k√∂nnen. Denn es gibt zwei auffallende Merkmale seit der Einnahme: die Cellulite an den Beinen und Po ist fast komplett weg und mein Bl√§hbauch ist deutlich reduziert. Es ist nicht so, dass ich extreme Cellulite hatte, aber es gab halt trotzdem unsch√∂ne Dellen hier und da, die nun fast vollst√§ndig (!) verschwunden sind. Ich glaube, ich hatte das letzte Mal solche glatten und makellosen Beine in meiner Jugend (bin jetzt 47).Mein Bl√§hbauch, der einem 6.Monat-Schwangerschaftsbauch Konkurrenz machte, ist deutlich kleiner geworden. Laut der Inhaltsangabe helfen Papayas bei Bl√§hungen und Verdauungsbeschwerden. Dank dieser Info werde ich dann Papaya-Enzym-Kapseln nochmal extra kaufen, um meinen Bl√§hbauch weiter gezielt zu minimieren.Es tut sich also was in meinem K√∂rper; √ºber weitere Wirkungen kann ich noch nicht berichten. Dass ich jetzt √∂fters auf Toilette muss, kann ich nicht behaupten. Meine Ern√§hrung habe ich nicht umgestellt. Wie sicher viele andere versuche ich m√∂glichst gesund zu essen, das klappt mehr und mehr weniger gut gut. Abgenommen habe ich minimal, die Hose sitzt etwas lockerer, ich sch√§tze mal, dass es 1-2 kg weniger sind.Den Geschmack fand ich am Anfang nicht so prickelnd. Ich mixe mir das ganze wie folgt: eine gro√üe Tasse (Kaffeebecher) zur H√§lfte mit kalten Wasser, ein halbes Schnapsglas Dietyslim rein und dann hei√ües Wasser aufgie√üen. Schmeckt dann also wie warmer Eistee. Meistens eine Tasse am Morgen und manchmal noch eine Tasse abends.Weil das ganze geschmacklich eine Eisteesorte w√§re, die mir nicht so sehr schmeckt, habe ich anfangs echten Eistee, den ich lecker finde, dazugemixt. So lie√ü sich das ganze ganz gut trinken. Sp√§ter habe ich den richtigen Eistee wieder nach und nach weggelassen, so dass ich jetzt nur noch Dietyslim (wie am Anfang) pur mit Wasser trinke, aber ich habe mich an den Geschmack gew√∂hnt habe und finde ihn nicht mehr schlimm.Wer sich gar nicht an den Geschmack gew√∂hnen kann, dem empfehle ich wirklich, einen Saft der Wahl etwas dazuzumixen.Sollten noch Ver√§nderungen eintreten, werde ich diese Rezession erg√§nzen.F√ºr mich hat sich Dietyslim definitiv gelohnt.\nRating: 5,0 von 5 Sternen\nValence: positiv (0.098)\nPolarity: positiv (1.099)\n\nID: p02_007\nDate: 2022-11-14\nTitle: Es geht so\nGamma: 0.301\nReview: Also das Produkt ist wenn man entw√§ssern m√∂chte sehr gut . Bei mir hat es extrem gewirkt musst soviel auf Toilette. Effekt sicherluch ganz gut. Geschmacklich nicht mein Ding k√∂nnte man verbessern und ansonsten gab es keine Abnehmerfolge dadurch zum entgiften vielleicht ok\nRating: 3,0 von 5 Sternen\nValence: positiv (0.249)\nPolarity: positiv (1.946)\n\n\n\n\nprint_output_descriptives(gamma_topics[4])\n\nResults for gamma_topic_4 \n## Check for ambiguous topic assignment for review:\nComments: \n- Highest relative gamma: Is gamma_topic_4 the top topic of the abstract?\n- Highest absolute gamma: Is the gamme value for gamma_topic_4 higher than 0.5\n \n                       Highest absolute gamma   No  Yes\nHighest realtive gamma                                 \nNo                                            1195    0\nYes                                            181  354\n\n## Basic descriptive statistics\n\n        var                  label   n NA.prc mean   sd se   md           range\n  gamma_top Highest realtive gamma 535  69.08 0.54 0.10  0 0.54 0.49 (0.3-0.79)\n gamma_main Highest absolute gamma 354  79.54 0.60 0.06  0 0.59 0.3 (0.49-0.79)\n\n\n\nprint_output_abstracts(gamma_topics[4])\n\nID: p01_390\nDate: 2016-06-09\nTitle: Lineavi - Die neue Wunderformel?\nGamma: 0.794\nReview: Im Verlauf der letzten 10 Jahre gelang es mir wiederholt, mein Gewicht unter Zurhilfenahme diverser ‚ÄúSchlankp√ºlverchen‚Äù um ca. 10-15kg zu reduzieren. Da ich es jedoch bis heute nicht hinbekomme, mein ‚ÄúTraumgewicht‚Äù zu halten, kann sich die Industrie auch weiterhin √ºber einen getreuen Abnehmer -im doppelten Wortsinn- freuen ;o). Um so sch√∂ner also, dass auch an der Eiweisspulverfront f√ºr reichlich Abwechslung gesorgt ist. Nach Slimfast, Layenberger und Almased nun also Lineavi.Was ist anders?Nun - zum einen w√§re da einmal der Geschmack. Da bei diesem Produkt auf die Zugabe von diversen Geschmacksstoffen wie Erdbeere, Aprikose u.s.w. verzichtet wurde, schmeckt Lineavi einfach anders. Eigentlich ein v√∂llig neuer Geschmack, der aber auch zugegebenerma√üen polarisiert. Am ehesten vergleichbar mit Almased; nur etwas s√º√üer. Zudem ist die dezente Note von Erbsen deutlich schmeckbar. √úberhaupt sind m.E. Parallelen zu Almased durchaus erkennbar. √Ñhnliche Bestandteile, √§hnliche Konzistenz nach der Zubereitung, u.s.w.. Auch haben beide Produkte unter dem Strich etwa den gleichen Brennwert (340/378 kcal), Lineavi s√§ttigt m.E. aber auf Grund des relativ hohen Kohlenhydratgehalts (23,4g/100g) gef√ºhlt etwas nachhaltiger.Wirkt es?Die Frage habe ich im Grunde ja eingangs bereits beantwortet: Ja, wenn man es sinvoll anwendet, kann man ohne gro√üe M√ºhe etwa 1kg pro Woche abnehmen. Das ist Fakt. Dies klappt zugegebenerma√üen aber nicht nur mit Lineavi. Mit etwas Disziplin, Bewegung (mu√ü kein Leistungssport sein, ich selbst bin ein absoluter Bewegungsmuffel), ist das wirklich kein Problem)Wem kann man Lineavi denn nun empfehlen?Grob gesagt jedem, der w√§rend einer Di√§t einen geeigneten Sattmacher zur Unterst√ºtzung ben√∂tigt und seinen K√∂rper in dieser Phase mit zus√§tzlichen Mineralstoffen und Vitaminen versorgen m√∂chte; ohne diesen dabei unn√∂tigerweise eine un√ºberschaubare Menge an Geschmacks-, Aroma- und S√º√üstoffen zu zuf√ºhren. Hier kann Lineavi ohne Frage punkten. Im Rahmen einer LowCarb Di√§t erscheinen mir 23,4g Zucker pro 100g allerdings nicht so ganz zielf√ºhrend.Werde ich es weiterhin verwenden?Ja, das werde ich ganz sicher. Zum einen weil‚Äôs mir schmeckt, zum anderen weil es mich doch √ºber einen Zeitraum von 4-5 Stunden s√§ttigt. Und obwohl, um die eingangs gestellte Frage zu beantworten, mit Lineavi das Rad sicher nicht neu erfunden wurde, ist es dennoch eine willkommene Abwechslung zu den √ºblichen Verd√§chtigen.\nRating: 4,0 von 5 Sternen\nValence: positiv (0.075)\nPolarity: positiv (1.196)\n\nID: p01_438\nDate: 2016-03-08\nTitle: S√º√ü, aber s√§ttigt\nGamma: 0.771\nReview: DIE REZENSION BEZIEHT SICH AUF: Lineavi Vitalkost ‚Äì Der gesunde Di√§t Shake f√ºr Ihr Abnehmprogramm + Shaker, 500g (Starterpaket)Rezension eines kostenfreien Testartikels.===FAZIT===Die Mahlzeiten sind ausgewogen und versorgen den K√∂rper mit allen N√§hrstoffen, Vitaminen und Spurenelementen. Das Beste ist, er macht wirklich anhaltend satt.Die Zusammensetzung hat mit ca. 25 % Kohlenhydraten (bezogen auf die trinkfertige Zubereitung), von den der √ºberwiegende Zucker ist, einen Anteil der mir f√ºr einen Di√§tdrink recht hoch erscheint, speziell am Abend.Der Shake enth√§lt laktosefreie Molke und kann daher aus von laktoseintoleranten Personen eingenommen werden.Der Lineavi Shake ist ungeeignet f√ºr Leute, die keine s√º√üen Sachen m√∂gen (1 Stern Abzug). Geschmacklich erinnert mich der Shake an √ºbers√º√ütes Brot, nicht unbedingt mein Favorit, aber trinkbar.Beim ersten √ñffnen ist eine Alu-Folie zu entfernen, die die einzelne Dose versiegelt. Beim Abziehen dieser Siegelfolie hat es einen Teil des sehr feinen Pulvers nach Au√üen gewirbelt und direkt Arbeitsplatte und Kleidung eingesaut‚Ä¶ (1 Stern Abzug).Der Shake l√§sst sich leider nicht in eine herzhafte Geschmacksrichtung abwandeln, aber mit Obst, Gem√ºse und sonstigen Zutaten zum Smoothie variieren.Kaufempfehlung: ja, f√ºr Freunde s√º√üen Geschmacks.3 Sterne===LIEFERUMFANG STARTERPAKET===Eine Dose mit 500 g Pulver (10 Portionen), Me√ül√∂ffel, Shake-Becher mit Siebeinsatz, Anweisung zur Zubereitung und zum Ablauf der Di√§t oder Entgiftung.===PRAXISTEST===Zun√§chst hab ich mich Belesen vornehmlich auf der Produktpage des Herstellers. Initial wird empfohlen 4-5 Shakes t√§glich zu konsumieren, je nach K√∂rpergr√∂√üe. Im Laufe der Di√§t werden immer mehr Shakes durch ausgewogene Mahlzeiten ersetzt, es sind einige Vorschl√§ge f√ºr Mahlzeiten im Begleitheft vorhanden, mehr finden sich auf der Herstellerseite.Die Viskosit√§t ist mit 5 Messl√∂ffeln sehr hoch, mit 4 Messl√∂ffeln finde ich es angenehmer zu trinken.Wem der Geschmack zu s√º√ü ist und das Getr√§nk nach einiger Zeit nicht mehr runterkriegt kann mal versuchen Crushed Ice unterzumischen. Das nimmt etwas der S√º√üe.Der Abnehmerfolg lag bei knapp 150 g/Tag in den ersten Tagen.\nRating: 3,0 von 5 Sternen\nValence: positiv (0.093)\nPolarity: positiv (1.718)\n\nID: p01_422\nDate: 2016-04-12\nTitle: Ablauf / Geschmack / Effekt\nGamma: 0.757\nReview: Da meine Freundin abnehmen m√∂chte, hat Sie den Shake (Starterpaket) ausprobiert und konnte nach ein paar Tagen bereits Erfolge sehen. Ich pers√∂nlich h√§tte nicht gedacht, dass das so gut klappt.### Ablauf:Im Lieferumfang ist eine wirklich sehr gute und verst√§ndlich Anleitung enthalten.Kurzfassung: In den ersten Tagen ersetzt man alle Mahlzeiten durch drei Shakes, danach wird die Menge des Shakes reduziert und man kann gewisse Sachen wieder Essen.Da die Menge des ben√∂tigen Pulvers von der K√∂rpergr√∂√üe abh√§ngt, reicht das Starterpaket f√ºr ca. 3-4 Tage. F√ºr die Turbo-Di√§t ben√∂tigt man min. 27-30 Shakes. Wenn einem der Shake schmeckt und man wei√ü man steht die Di√§t durch, sollte man daher rechtzeitig direkt ein 3er oder 6er Paket nachbestellen.### Geschmack:Mir pers√∂nlich hat der Shake gar nicht geschmeckt, meiner Freundin schon. In Worte l√§sst sich Geschmack immer sehr schlecht fassen. Vergleichbar ist dieser mit ‚ÄûYokebe Aktivkost Classic‚Äú.### Zubereitung:Die Zubereitung geht einfach und schnell. Einfach die empfohlene Menge Pulver in den im Lieferumfang enthaltenen Shaker + kaltes Wasser oder Milch hinzugeben und ordentlich shaken. Das Pulver l√∂st sich sehr gut und recht schnell auf. Sofern man Wasser verwendet, kann man auch einen 1TL Pflanzen√∂l dazugeben. Hier sollte man ausprobieren was einem am besten geschmeckt. Meine Freundin hat meistens Milch verwendet.### Effekt:Meine Freundin konnte bereits nach den ersten Tagen ein paar Erfolge sehen. Dies liegt vermutlich stark dran, das 3 Shakes nur 630 kcal haben und Ihr Grundbedarf deutlich h√∂her ist. Folge dessen hat Ihr K√∂rper mehr verbraucht als er aufgenommen hat. Da der Shake stark s√§ttigt, hatte Sie kein Hunger in diesen Tagen.Auf eine Angabe von kg verzichte ich hier bewusst, da die Gewichtsreduzierung stark vom K√∂rperbau des Anwenders abh√§ngt. Eine Person mit etwas mehr K√∂rpermasse wird in den ersten Tagen deutlich mehr Gewicht verlieren, als eine Person die bereits ein Normalgewicht hat.### Fazit:Wem der Shake schmeckt und somit die ersten Tage durchh√§lt, der wird auf Dauer sicher den gew√ºnschten Effekt der Gewichtsreduzierung erreichen. Die Kosten ab dem 10. Tag, sind mit ca. EUR 1,70 (beim 3er Paket) f√ºr 1 Shake aus meiner Sicht ok.‚ÄîIch hoffe meine Rezension ist hilfreich und konnte zur Kaufentscheidung beitragen.Fragen k√∂nnen mir gerne via Kommentar gestellt werden. Mehr √ºber mich in meinem Profil (Klick auf meinen Namen)\nRating: 5,0 von 5 Sternen\nValence: positiv (0.043)\nPolarity: positiv (1.099)\n\nID: p01_101\nDate: 2019-01-30\nTitle: +Schmeckt lecker/-Mogelpackung\nGamma: 0.746\nReview: Ein Shake der schmeckt, bei Bedarf p√ºrriere ich etwas Obst hinein f√ºr noch mehr Geschmack, ist aber kein muss!Die Dose ist allerdings eine ziemlich Mogelpackung nur zu 2/3 gef√ºllt und da man 50g Pulver pro Drink brauch wird sie auch schnell wieder leer sein!\nRating: 4,0 von 5 Sternen\nValence: positiv (0.032)\nPolarity: positiv (0.511)\n\nID: p01_408\nDate: 2016-05-29\nTitle: Geschmack √ºberzeugt\nGamma: 0.744\nReview: LINEAVI ist ein Mahlzeitersatz in Puderform, der mit Proteinen, Vitaminen, Minearalstoffen angereichert ist und versprich,, die Fettverbrannung anzuregen. Mit jeder empfohlenen Portion werden rund 200 Kcal aufgenommen, also in der Regel deutlich weniger, als bei einer g√§ngigen Mahlzeit. Im Zusammenhang mit einer Di√§t k√∂nnen 1-2 Mahlzeiten problemlos mit einer Portion des Di√§tprodukts ersetzt werden, ohne Mangelerscheinungen hervor zu rufen.LNEAVI schmeckt etwas fruchtig und etwas nach Vanille. Es enth√§lt Soja und eignet sich daher nicht f√ºr Menschen mit einer Sojaallergie.Wer vergleichbare Produkte wie z.B. Almased kennt, findet in diesem Produkt eine Alternative, die einem auch nach der ersten Dose noch schmeckt.Wunder bewirkt LINEAVI ebenso wenig wie die anderen Pulver, deren Zusammensetzung angeblich stets auf den neuesten medizinischen Erkenntnissen beruht. Dennoch ist es m√∂glich mit Hilfe dieses Mahlzeitersatzes gesundes Abnehmen zu unterst√ºtzen, wenn man sich bewegt und all das beherzigt, was man bei jeder Di√§t beherzigen sollte.\nRating: 3,0 von 5 Sternen\nValence: positiv (0.045)\nPolarity: positiv (1.946)\n\n\n\n\nprint_output_descriptives(gamma_topics[5])\n\nResults for gamma_topic_5 \n## Check for ambiguous topic assignment for review:\nComments: \n- Highest relative gamma: Is gamma_topic_5 the top topic of the abstract?\n- Highest absolute gamma: Is the gamme value for gamma_topic_5 higher than 0.5\n \n                       Highest absolute gamma   No  Yes\nHighest realtive gamma                                 \nNo                                            1137    0\nYes                                            151  442\n\n## Basic descriptive statistics\n\n        var                  label   n NA.prc mean   sd   se   md\n  gamma_top Highest realtive gamma 593  65.72 0.59 0.14 0.01 0.61\n gamma_main Highest absolute gamma 442  74.45 0.66 0.09 0.00 0.66\n            range\n  0.6 (0.26-0.86)\n 0.37 (0.49-0.86)\n\n\n\nprint_output_abstracts(gamma_topics[5])\n\nID: p03_239\nDate: 2021-05-27\nTitle: Geld Verschwendung\nGamma: 0.857\nReview: Ich habe es als Erg√§nzung zur Umstellung der Ern√§hrung um etwas abzunehmen. Leider gar keine Wirkung. Trotz gesunder Ern√§hrung habe ich kein Gramm verloren selbst nach zwei Monaten. Richtig entt√§uschend.\nRating: 1,0 von 5 Sternen\nValence: negativ (-0.052)\nPolarity: negativ (-0.251)\n\nID: p03_209\nDate: 2021-06-16\nTitle: Keine √Ñnderung eingetreten. Ohne Wirkung.\nGamma: 0.854\nReview: Bei mir hat sich gar keine Wirkung eingestellt. Normal gegessen und t√§gliche Bewegung auf dem Fahrrad. Nichts abgenommen, nichts zugenommen ausser die t√§glichen Schwankungen. Ist auch kein Appetitz√ºgler, Essen hat immer noch geschmeckt. Die W√ºnsche nach einer besseren Figur sind auch nicht eingetreten. Der Stoffwechsel hat nicht den Rest gemacht. Hier ist bei vielen wohl Einbildung im Spiel.\nRating: 3,0 von 5 Sternen\nValence: positiv (0.004)\nPolarity: positiv (1.099)\n\nID: p03_368\nDate: 2020-11-25\nTitle: KEINE WIRKUNG. ES IST NICHT ZU EMPFEHLEN. Voll entt√§uscht.\nGamma: 0.849\nReview: Eigentlich war ich von den vielen positiven Rezensionen √ºberzeugt.Rausgeworfenes Geld!Das Zeug hat keine Wirkung!Schauen sie Zweite Foto - steht hergestellt f√ºr TALLIN !Bei Allgemeine Produktinformationen steht:Netto-Gewicht 45 Grammund auf dem Verpackung F√ºllmenge: 28 Gramm geschrieben ‚Ä¶.Die Frage ist - ob die Inhaltszusammenfassung stimmt ?Hab die Tabletten eingenommen und nach 2 Wochen ist nichts passiert.NUR rausgeworfenes Geld!Schade ‚Ä¶\nRating: 1,0 von 5 Sternen\nValence: negativ (-0.105)\nPolarity: negativ (-0.511)\n\nID: p03_201\nDate: 2021-06-23\nTitle: Bringt nichts‚Ä¶Geldverschwendung\nGamma: 0.844\nReview: Ich habe das Produkt wegen der vielen positiven Bewertungen bestellt.Ich habe kein √úbergewicht, ich wollte lediglich zum Sommer einige Pfunde loswerden. Mein Stoffwechsel sollte angeregt werden, da ich Hashimoto habe. Ich ern√§hre mich ausgewogen und √ºberwiegend gesund.Meine Packung ist jetzt fast leer. Resonanz: keine Ver√§nderung.Ich werde sie auch noch aufbrauchen, aber erwarte nichts gro√ües.Es ist weder ein Fettburner noch ein Stoffwechsel anreger.Lediglich wird der Appetit ETWAS gez√ºgelt/ doch eher verschoben.Von mir definitiv KEINE Kaufempfehlung.F√ºr das geld habe ich definitiv mehr erwartet.\nRating: 1,0 von 5 Sternen\nValence: negativ (-0.006)\nPolarity: negativ (-0.847)\n\nID: p03_360\nDate: 2020-12-15\nTitle: Leider nix gebracht :-(\nGamma: 0.84\nReview: Habe nach zwei Wochen trotz Umstellen der Ern√§hrung keinen Erfolg gehabt, Gewicht ist gleich geblieben. Schade.\nRating: 1,0 von 5 Sternen\nValence: negativ (-0.036)\nPolarity: negativ (-0.847)"
  },
  {
    "objectID": "content/08-text_as_data/08-slides.html",
    "href": "content/08-text_as_data/08-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you find the slides for the eigth session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‚Äòe‚Äô button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#seminarplan",
    "href": "content/08-text_as_data/slides/index.html#seminarplan",
    "title": "Text as data",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einf√ºhrung und √úberblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nText as data\nChristoph Adrian\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n11.01.2023\nESM: m-path\nD√∂rr\n\n\n10\n18.01.2023\nData Donations\nHofmann & Wierzbicki\n\n\n11\n25.01.2023\nPUFFER\n\n\n\n12\n02.02.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n13\n08.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian\n\n\n\n\n‚ñ∂Ô∏è\n‚ö†Ô∏èTerminkonflikt"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#nicht-neu-aber-andere-dimension",
    "href": "content/08-text_as_data/slides/index.html#nicht-neu-aber-andere-dimension",
    "title": "Text as data",
    "section": "Nicht neu, aber andere Dimension",
    "text": "Nicht neu, aber andere Dimension\nDas Ph√§nomen Text as data\n\n\n\nLange Tradition der Text- und Inhaltsanalyse (besonders in der Kommunikationswissenschaft)\nNeue Chancen & Herausforderungen durch explosionsartige Vergr√∂√üerung des (Text-)Datenaufkommen in den letzten Jahren (Websites, Plattformen & Digitalisierung)\n\n\n\n\n\n\n\n(Salganik, 2018)"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#neue-quellen-neue-methoden-neue-m√∂glichkeiten",
    "href": "content/08-text_as_data/slides/index.html#neue-quellen-neue-methoden-neue-m√∂glichkeiten",
    "title": "Text as data",
    "section": "Neue Quellen, Neue Methoden, neue M√∂glichkeiten",
    "text": "Neue Quellen, Neue Methoden, neue M√∂glichkeiten\nVerschiedene Textgrundlagen als Beispiel"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#possibilities-over-possibilities",
    "href": "content/08-text_as_data/slides/index.html#possibilities-over-possibilities",
    "title": "Text as data",
    "section": "Possibilities over possibilities",
    "text": "Possibilities over possibilities\n√úberblick √ºber verschiedene Methoden der Textanalyse"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#im-fokus-di√§tpillen",
    "href": "content/08-text_as_data/slides/index.html#im-fokus-di√§tpillen",
    "title": "Text as data",
    "section": "Im Fokus: üíä Di√§tpillen",
    "text": "Im Fokus: üíä Di√§tpillen\nHintergrund\n\n\n\nReviews von f√ºnf ‚ÄúDi√§tpillen‚Äù\nAutomatisch Scraping via eigener R-Funktion\nDatensatz mit knapp √ºber 2000 Reviews (ohne Bereinigung)\nExemplarische Darstellung folgender Schritte:\n\nText-Processing\nSentiment-Analyse\nTopic Modeling\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAusf√ºhrliche Schritte im Google Colab & Showcase\nHier nur Ausz√ºge"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#quick-scraping-step-by-step",
    "href": "content/08-text_as_data/slides/index.html#quick-scraping-step-by-step",
    "title": "Text as data",
    "section": "Quick scraping step-by-step",
    "text": "Quick scraping step-by-step\n1Ô∏è‚É£ Custom function f√ºr Export der html-Elemente\n\nscrape_amazon <- function(page_num, review_url) {\n  url_reviews <- paste0(review_url, \"&pageNumber=\", page_num, \"&sortBy=recent\")\n  doc <- read_html(url_reviews)\n  map_dfr(doc %>% html_elements(\"[id^='customer_review']\"), ~ data.frame(\n    review_title = .x %>% html_element(\".review-title\") %>% html_text2(),\n    review_text = .x %>% html_element(\".review-text-content\") %>% html_text2(),\n    review_star = .x %>% html_element(\".review-rating\") %>% html_text2(),\n    date = .x %>% html_element(\".review-date\") %>% html_text2() %>% gsub(\".*vom \", \"\", .),\n    author = .x %>% html_element(\".a-profile-name\") %>% html_text2(),\n    page = page_num\n  )) %>%\n    as_tibble %>%\n    return()\n}"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#quick-scraping-step-by-step-1",
    "href": "content/08-text_as_data/slides/index.html#quick-scraping-step-by-step-1",
    "title": "Text as data",
    "section": "Quick scraping step-by-step",
    "text": "Quick scraping step-by-step\n2Ô∏è‚É£ Definition von Amazon Review URLs\n\nurl <- list(\n  p01 = \"https://www.amazon.de/LINEAVI-Eiwei%C3%9F-Shake-Kombination-Molkeneiwei%C3%9F-laktosefrei/product-reviews/B018IB02AU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n  p02 = \"https://www.amazon.de/Detoxkuren%E2%80%A2-Entw%C3%A4sserung-Entschlackung-Stoffwechsel-entschlacken/product-reviews/B072QW5ZN1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n  p03 = \"https://www.amazon.de/Saint-Nutrition%C2%AE-KETO-BURN-Appetitz%C3%BCgler/product-reviews/B08B67V8G5/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n  p04 = \"https://www.amazon.de/Yokebe-vegetarisch-Mahlzeitersatz-Gewichtsabnahme-hochwertigen/product-reviews/B08GYZ8LRB/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews\",\n  p05 = \"https://www.amazon.de/Vihado-Liquid-chlorophyll-drops-alfalfa/product-reviews/B093XNC8QH/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews\"\n)"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#quick-scraping-step-by-step-2",
    "href": "content/08-text_as_data/slides/index.html#quick-scraping-step-by-step-2",
    "title": "Text as data",
    "section": "Quick scraping step-by-step",
    "text": "Quick scraping step-by-step\n3Ô∏è‚É£ Scrape with for-loops\n\namazon <- list()\n# p01 \nfor (i in 1:79) {\n  df <- scrape_amazon(page_num = i, review_url = url$p01)\n  amazon$raw$p01[[i]] <- df\n}\n\n\n\nproduct <- names(url)\n# bind rows for each product\nfor (i in product) {\n  amazon$data$raw[[i]] <- amazon$raw[[i]] %>% \n    bind_rows() %>% \n    rownames_to_column(\"id\") %>% \n    mutate(across(id, as.numeric))\n}\n# bind rows of all products\namazon$data$full <- amazon$data$raw %>% \n  bind_rows(.id = \"src\")"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#quick-scraping-step-by-step-3",
    "href": "content/08-text_as_data/slides/index.html#quick-scraping-step-by-step-3",
    "title": "Text as data",
    "section": "Quick scraping step-by-step",
    "text": "Quick scraping step-by-step\n4Ô∏è‚É£ Endresultat\n\namazon$data$full %>% \n  glimpse()\n\nRows: 2,142\nColumns: 8\n$ src          <chr> \"p01\", \"p01\", \"p01\", \"p01\", \"p01\", \"p01\", \"p01\", \"p01\", \"‚Ä¶\n$ id           <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17‚Ä¶\n$ review_title <chr> \"Schmeckt wie ein angenehmer Milchshake\", \"Nicht zufriede‚Ä¶\n$ review_text  <chr> \"Wie ich damit abgenommen haben kann ich noch nicht sagen‚Ä¶\n$ review_star  <chr> \"4,0 von 5 Sternen\", \"2,0 von 5 Sternen\", \"5,0 von 5 Ster‚Ä¶\n$ date         <chr> \"Kundenrezension aus Deutschland üá©üá™ am 26. November 2022\"‚Ä¶\n$ author       <chr> \"Rayan Wehbi\", \"Motte\", \"V.K\", \"niw\", \"Murphy\", \"Julia\", ‚Ä¶\n$ page         <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, ‚Ä¶"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#anzahl-der-reviews-nach-produkt",
    "href": "content/08-text_as_data/slides/index.html#anzahl-der-reviews-nach-produkt",
    "title": "Text as data",
    "section": "Anzahl der Reviews nach Produkt",
    "text": "Anzahl der Reviews nach Produkt\nKennenlernen des Datensatzes\n\namazon$data$de %>% \n  frq(src)\n\nsrc <categorical> \n# total N=1736 valid N=1736 mean=2.88 sd=1.46\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\np01   | 438 | 25.23 |   25.23 |  25.23\np02   | 256 | 14.75 |   14.75 |  39.98\np03   | 509 | 29.32 |   29.32 |  69.30\np04   | 143 |  8.24 |    8.24 |  77.53\np05   | 390 | 22.47 |   22.47 | 100.00\n<NA>  |   0 |  0.00 |    <NA> |   <NA>"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#anzahl-der-reviews-nach-produkt-im-zeitverlauf",
    "href": "content/08-text_as_data/slides/index.html#anzahl-der-reviews-nach-produkt-im-zeitverlauf",
    "title": "Text as data",
    "section": "Anzahl der Reviews nach Produkt im Zeitverlauf",
    "text": "Anzahl der Reviews nach Produkt im Zeitverlauf\nKennenlernen des Datensatzes\n\namazon$data$de %>% \n  ggplot(aes(year, fill = src)) +\n  geom_bar() +\n  scale_fill_locuszoom() +\n  theme_pubr()"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#bewertungen-der-produkte-absolute-zahlen",
    "href": "content/08-text_as_data/slides/index.html#bewertungen-der-produkte-absolute-zahlen",
    "title": "Text as data",
    "section": "Bewertungen der Produkte: Absolute Zahlen",
    "text": "Bewertungen der Produkte: Absolute Zahlen\nKennenlernen des Datensatzes\n\namazon$data$de %>% \n  mutate(across(rating, as.factor)) %>% \n  ggplot(aes(src, fill = rating)) + \n  geom_bar() +\n  scale_fill_brewer(palette = \"RdYlGn\") +\n  theme_pubr()"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#bewertungen-der-produkte-kummulierte-anteile",
    "href": "content/08-text_as_data/slides/index.html#bewertungen-der-produkte-kummulierte-anteile",
    "title": "Text as data",
    "section": "Bewertungen der Produkte: Kummulierte Anteile",
    "text": "Bewertungen der Produkte: Kummulierte Anteile\nKennenlernen des Datensatzes\n\namazon$data$de %>% \n  mutate(across(rating, as.factor)) %>% \n  ggplot(aes(src, fill = rating)) + \n  geom_bar(position = \"fill\") +\n  scale_fill_brewer(palette = \"RdYlGn\") +\n  theme_pubr()"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#vom-korpus-bis-zum-model",
    "href": "content/08-text_as_data/slides/index.html#vom-korpus-bis-zum-model",
    "title": "Text as data",
    "section": "Vom Korpus bis zum Model",
    "text": "Vom Korpus bis zum Model\nProzess der Textverarbeitung"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#s√§tze-token-lemma-pos",
    "href": "content/08-text_as_data/slides/index.html#s√§tze-token-lemma-pos",
    "title": "Text as data",
    "section": "S√§tze ‚Äì Token ‚Äì Lemma ‚Äì POS",
    "text": "S√§tze ‚Äì Token ‚Äì Lemma ‚Äì POS\nVorverarbeitungsschritte f√ºr Textanalyse\n\n\n\n\n\n\n1. Satzerkennung\n\n\nWas gibt‚Äôs in New York zu sehen?\n\n\n\n\n\n\n\n\n\n2. Tokenisierung\n\n\nwas; gibt; `s; in; new; york; zu; sehen; ?\n\n\n\n\n\n\n\n\n\n3. Lemmatisierung\n\n\nwas; geben; `s; in; new; york; zu; sehen; ?\n\n\n\n\n\n\n\n\n\n4. Part-Of-Speech (POS) Tagging\n\n\n>Was/PWS >gibt/VVFIN >‚Äôs/PPER >in/APPR >New/NE >York/NE >zu/PTKZU >sehen/VVINF\n\n\n\n\nSatzerkennung: Aufl√∂sung der Satzstruktur; Aber: Probleme mit Datumsangaben, Uhrzeit, Abk√ºrzungen, URLS\nTokenisierung: Zerteilung in kleinste Einheiten, Abtrennung von Satzzeichen; Fragen: Umgang mit Zeichen, Symbolen, Zahlen, N-Gramme ‚Ä¶\nDefinition Lemmatisierung: Grundform eines Worters, als diejenige Form, unter dem an einen Begriff in einem Nachschlagewerk findet / R√ºckf√ºhrung auf die ‚ÄûVollfrom‚Äù\nDefinition POS: Zuordnung von W√∂rtern und Satzzeichen eines Textes zu Wortarten"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#von-bow-zu-dfm",
    "href": "content/08-text_as_data/slides/index.html#von-bow-zu-dfm",
    "title": "Text as data",
    "section": "Von BOW zu DFM",
    "text": "Von BOW zu DFM\nBag-of-words (BOW) und Document-Feature-Matrix (DFM)\n\n\nBag-of-Words-Modell: es z√§hlt lediglich die Worth√§ufigkeit je Dokument, die syntaktischen und grammatikalischen Zusammenh√§nge zwischen einzelnen W√∂rtern werden ignoriert."
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#the-good-the-bad-and-the-ugly",
    "href": "content/08-text_as_data/slides/index.html#the-good-the-bad-and-the-ugly",
    "title": "Text as data",
    "section": "The good, the bad and the ugly",
    "text": "The good, the bad and the ugly\nGrundidee & Ziele und der Sentimentanalyse\n\nAuf Basis von speziellen Wortlisten bzw. Lexika werden bestimmte Begriffe ausgez√§hlt, denen zuvor entweder ein numerischer Wert (Score) oder eine Kategorien (positiv oder negativ) zugeordnet wurden.\nZiel ist die Bestimmung der Polarit√§t (positive/negative Emotion) eines Textes\nAber: Wie gut ist die Klassifizierung?"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#grundlagen-f√ºr-die-analyse",
    "href": "content/08-text_as_data/slides/index.html#grundlagen-f√ºr-die-analyse",
    "title": "Text as data",
    "section": "Grundlagen f√ºr die Analyse",
    "text": "Grundlagen f√ºr die Analyse\nHintergrundinformationen zum Processing & Scoring\n\nDie Verarbeitung und Analyse der Daten erfolgt mit demquanteda bzw. quanteda.textstat Paket und basiert nur auf dem Korpus der deutschen Reviews\nAls Sentiment-Grundlage wird SentiWS genutzt\n\n√∂ffentlich verf√ºgbare deutschsprachige Ressource f√ºr die Sentiment Analyse, Opinion Mining und √§hnliche Zwecke\npositive und negative Polarit√§t im Intervall [-1; 1] f√ºr enthaltene W√∂rter die angegeben, sowie deren Wortart\nenth√§lt ungef√§hr 1.650 positive und 1.800 negative Grundformen\n\n\n\n\nund (falls anwendbar) Flexionsvarianten\nso dass, inklusive der verschiedenen Flexionsformen, insgesamt etwa 16.000 positive und 18.000 negative Wortformen enthalten sind. SentiWS enth√§lt nicht nur Adjektive und Adverbien, sondern auch Nomen und Verben die Tr√§ger von Sentiment sind"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#erste-ergebnisse",
    "href": "content/08-text_as_data/slides/index.html#erste-ergebnisse",
    "title": "Text as data",
    "section": "Erste Ergebnisse",
    "text": "Erste Ergebnisse\nBewertung der verschiedenen Di√§tpillen\n\namazon$data$de_senti %>% \n  ggplot(aes(x = src, y = valence)) + \n  ggdist::stat_halfeye(\n    aes(fill = src),\n    adjust = .5, \n    width = .6, \n    .width = 0, \n    justification = -.3, \n    point_colour = NA) + \n  geom_boxplot(\n    aes(color = src),\n    width = .25, \n    outlier.shape = NA\n  ) +\n  geom_point(\n    aes(color = src),\n    size = 1.3,\n    alpha = .3,\n    position = position_jitter(\n      seed = 1, width = .1\n    )\n  ) + \n  coord_cartesian(xlim = c(1.2, NA), clip = \"off\") +\n  scale_color_startrek() +\n  scale_fill_startrek() +\n  theme_pubr()\n\n\n\nValence = average valence of document, based on a dictionary whose values have numeric valence scores."
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#erste-ergebnisse-output",
    "href": "content/08-text_as_data/slides/index.html#erste-ergebnisse-output",
    "title": "Text as data",
    "section": "Erste Ergebnisse",
    "text": "Erste Ergebnisse"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#ein-gro√ües-aber",
    "href": "content/08-text_as_data/slides/index.html#ein-gro√ües-aber",
    "title": "Text as data",
    "section": "Ein gro√ües ‚Äú‚Ä¶ , ABER ‚Ä¶‚Äù",
    "text": "Ein gro√ües ‚Äú‚Ä¶ , ABER ‚Ä¶‚Äù\nKritische Anmerkungen zur Sentimentanalyse\n\n\n\namazon$data$de_senti %>% \n  flat_table(rating, val_fct)\n\n       val_fct negativ neutral positiv\nrating                                \n1                  167      40     101\n2                   61      11      37\n3                   47      14      48\n4                   34      10     129\n5                  109      16     912\n\n\n\n\nProbleme der ‚Äúdictionary method‚Äù mit Negationen (‚Äúnicht gut‚Äù) und ‚ÄúVerst√§rkern‚Äù (‚Äúsehr gut‚Äù)\nBesser: Codierung bzw. Klassifizierung mit Hilfe von √ºberwachtem maschinellem Lernen"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#grundidee",
    "href": "content/08-text_as_data/slides/index.html#grundidee",
    "title": "Text as data",
    "section": "Grundidee",
    "text": "Grundidee\nQuick Introduction to Topic Modeling\n\nVerfahren des un√ºberwachten maschinellen Lernens, das sich daher insbesondere zur Exploration und Deskription gro√üer Textmengen eignet\nThemen werden strikt auf Basis von Worth√§ufigkeiten in den einzelnen Dokumenten vermeintlich objektiv berechnet, ganz ohne subjektive Einsch√§tzungen und damit einhergehenden etwaigen Verzerrungen\nBekanntesten dieser Verfahren sind LDA (Latent Dirichlet Allocation) sowie die darauf aufbauenden CTM (Correlated Topic Models) und STM (Structural Topic Models)"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#annahmen",
    "href": "content/08-text_as_data/slides/index.html#annahmen",
    "title": "Text as data",
    "section": "Annahmen",
    "text": "Annahmen\nQuick Introduction to Topic Modeling\n\nEin Textkorpus besteht aus D Dokumenten und V W√∂rtern bzw. Terms\nEs wird nun angenommen, dass latente Themen K zu unterschiedlichen Anteilen in den Dokumenten D vorkommen und alle W√∂rter V mit unterschiedlicher Wahrscheinlichkeit zu den K Themen geh√∂ren.\nZiel der Verfahren ist die Berechnung zweier Matrizen D√óK und V√óK.\n\nDie erste Matrix D√óK enth√§lt f√ºr jedes einzelne Dokument d und jedes einzelne Thema k die Wahrscheinlichkeit, dass das Thema in diesem Dokument vorkommt (ùöπ).\nAnalog enth√§lt V√óK f√ºr jedes einzelne Wort w und jedes einzelne Thema k die Wahrscheinlichkeit, dass das jeweilige Wort in diesem Thema vorkommt (ùõÉ).\n\n\n\n\nMit Hilfe dieser Matrizen k√∂nnen die Themen dann beschrieben und interpretiert werden.\n\nSo k√∂nnen aus V√óK die wichtigsten W√∂rter je Thema (d.h., die W√∂rter mit der h√∂chsten konditionalen Wahrscheinlichkeit, zu einem bestimmten Thema kk zu geh√∂ren) abgelesen werden;\nmittels D√óK k√∂nnen Themen Dokumenten und umgekehrt zugeordnet werden, z. B. in dem f√ºr jedes Dokument dd das Thema kk mit der h√∂chsten konditionalen Wahrscheinlichkeit identifiziert wird.\n\nZur Berechnung dieser Matrizen wird sozusagen der umgekehrte Weg gegangen und die Erzeugung der Dokumente als statistischer Prozess beschrieben: ein Dokument wird demnach erzeugt, in dem zuf√§llig Themen aus der zum Dokument zugeh√∂rigen Themenverteilung und W√∂rter aus der den Themen zugeh√∂rigen Wortverteilungen gezogen werden. Hierzu wird das Topic Model zun√§chst mit zuf√§lligen Themen- und Wortverteilungen initialisiert und dann in einem iterativen, algorithmischen Verfahren nach und nach adaptiert, bis es m√∂glichst gut zu den Daten (dem Textkorpus) passt (d.h. die gemeinsame Likelihood der Themen- und Wortverteilungen maximiert wird).53"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#structual-topic-modeling-im-fokus",
    "href": "content/08-text_as_data/slides/index.html#structual-topic-modeling-im-fokus",
    "title": "Text as data",
    "section": "Structual Topic Modeling im Fokus",
    "text": "Structual Topic Modeling im Fokus\nIdee und Hintergrund von STM\n\n\nùõ¥ = Topic covariance\nx = Prevalende Metadata\ngamma = Metadata weights\nsmaller box = N = number of words in a document\nbigger box = M = number of documents in a corpus"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#welches-k",
    "href": "content/08-text_as_data/slides/index.html#welches-k",
    "title": "Text as data",
    "section": "Welches K?",
    "text": "Welches K?\nBestimmung der optimalen Themenanzahl\n\namazon$tpm$model_scores %>% \n  transmute(\n    k,\n    `Lower bound` = lbound,\n    Residuals = map_dbl(residual, \"dispersion\"),\n    `Semantic coherence` = map_dbl(semantic_coherence, mean),\n    `Held-out likelihood` = map_dbl(eval_heldout, \"expected.heldout\")) %>%   \n  pivot_longer(-k, names_to = \"Metric\", values_to = \"Value\") %>% \n  ggplot(\n    aes(k, Value, color = Metric)) +\n  geom_line(size = 1.5, alpha = 0.7, show.legend = FALSE) +\n  facet_wrap(~Metric, scales = \"free_y\") +\n  labs(x = \"K (number of topics)\",\n       y = NULL,\n       title = \"Model diagnostics by number of topics\")"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#welches-k-output",
    "href": "content/08-text_as_data/slides/index.html#welches-k-output",
    "title": "Text as data",
    "section": "Welches K?",
    "text": "Welches K?"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#kombination-aus-koh√§renz-exklusivit√§t",
    "href": "content/08-text_as_data/slides/index.html#kombination-aus-koh√§renz-exklusivit√§t",
    "title": "Text as data",
    "section": "Kombination aus Koh√§renz & Exklusivit√§t",
    "text": "Kombination aus Koh√§renz & Exklusivit√§t\nBestimmung der optimalen Themenanzahl\n\namazon$tpm$model_scores %>%\n  select(k, exclusivity, semantic_coherence) %>%\n  filter(k %in% c(5, 7, 11)) %>%\n  unnest(cols = c(exclusivity, semantic_coherence)) %>%\n  mutate(k = as.factor(k)) %>%\n  ggplot(aes(semantic_coherence, exclusivity, color = k)) +\n  geom_point(size = 2, alpha = 0.7) +\n  labs(x = \"Semantic coherence\",\n       y = \"Exclusivity\",\n       title = \"Comparing exclusivity and semantic coherence\",\n       subtitle = \"Models with fewer topics have higher semantic coherence for more topics, but lower exclusivity\")"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#kombination-aus-koh√§renz-exklusivit√§t-output",
    "href": "content/08-text_as_data/slides/index.html#kombination-aus-koh√§renz-exklusivit√§t-output",
    "title": "Text as data",
    "section": "Kombination aus Koh√§renz & Exklusivit√§t",
    "text": "Kombination aus Koh√§renz & Exklusivit√§t"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#top-features-der-themen",
    "href": "content/08-text_as_data/slides/index.html#top-features-der-themen",
    "title": "Text as data",
    "section": "Top Features der Themen",
    "text": "Top Features der Themen\nInterpretation des Models\n\namazon$stm$mdl %>% labelTopics()\n\nTopic 1 Top Words:\n     Highest Prob: tropfen, geschmack, chlorophyll, wasser, wirkung, schmeckt, schon \n     FREX: tropfen, chlorophyll, glas, gr√ºn, farbe, flasche, konnten \n     Lift: alfalfa, dosieren, farbe, frisch, geladen, glas, gr√ºne \n     Score: tropfen, chlorophyll, farbe, gr√ºn, geladen, medien, wirkung \nTopic 2 Top Words:\n     Highest Prob: produkt, super, nehme, seit, mehr, sagen, wirklich \n     FREX: nehme, gutes, begeistert, seit, wirkt, hilft, √ºberrascht \n     Lift: begeistert, detox, entgiften, entschlacken, gutes, pfirsich, teste \n     Score: produkt, seit, nehme, weiteren, super, gutes, hilft \nTopic 3 Top Words:\n     Highest Prob: gut, dass, tag, tagen, ganz, finde, besser \n     FREX: ganz, finde, m√∂chte, produkte, tagen, anfang, wenig \n     Lift: anfang, soweit, generell, produkte, komisch, versucht, m√∂chte \n     Score: gut, generell, finde, dass, ganz, tag, tagen \nTopic 4 Top Words:\n     Highest Prob: schmeckt, geschmack, shake, lineavi, shaker, pulver, lecker \n     FREX: shake, lineavi, shaker, pulver, lecker, shakes, almased \n     Lift: anleitung, dosen, ersetzt, aktivkost, almased, classic, di√§tshake \n     Score: lineavi, shaker, shake, almased, pulver, shakes, milch \nTopic 5 Top Words:\n     Highest Prob: schon, wochen, leider, kapseln, abgenommen, sport, abnehmen \n     FREX: kapseln, abgenommen, tabletten, geld, bringt, sport, schlucken \n     Lift: abgenommen, achten, burn, gebracht, gegenteil, geld, geldverschwendung \n     Score: kapseln, tabletten, keto, burn, abgenommen, sport, kilo"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#prevalence-der-themen",
    "href": "content/08-text_as_data/slides/index.html#prevalence-der-themen",
    "title": "Text as data",
    "section": "Prevalence der Themen",
    "text": "Prevalence der Themen\nInterpretation des Models\n\namazon$stm$preval$tgt  %>% \n  ggplot(aes(topic, gamma, label = terms, fill = topic)) +\n  geom_col(show.legend = FALSE) +\n  geom_text(hjust = 1.1, nudge_y = 0.0005, size = 3, color = \"white\") +\n  coord_flip() +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 0.35), labels = scales::percent) +\n  theme_bw() +\n  theme(panel.grid.minor = element_blank(),\n        panel.grid.major = element_blank()) +\n  labs(x = NULL, y = expression(gamma)) +\n  scale_fill_jama()"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#prevalence-der-themen-output",
    "href": "content/08-text_as_data/slides/index.html#prevalence-der-themen-output",
    "title": "Text as data",
    "section": "Prevalence der Themen",
    "text": "Prevalence der Themen"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#validieren-validieren-validieren",
    "href": "content/08-text_as_data/slides/index.html#validieren-validieren-validieren",
    "title": "Text as data",
    "section": "Validieren, Validieren, Validieren",
    "text": "Validieren, Validieren, Validieren\nKritisiche Anmerkungen zum Topic Modeling\n\nAutomated text analysis methods can substantially reduce the costs and time of analyzing massive collections of political texts. When applied to any one problem, however, the output of the models may be misleading or simply wrong. [‚Ä¶] What should be avoided, then, is the blind use of any method without a validation step (Grimmer & Stewart, 2013, S. 5).\n\n\nKlassifikationsmodell klassifiziert alle Dokumente, ein Diktion√§r spuckt f√ºr jedes Dokument ein Ergebnis aus, ein Topic Model findet immer die vorgegebene Anzahl an Themen.\nOb es sich dabei auch um inhaltlich sinnvolle Ergebnisse handelt, kann und muss durch manuelle Validierungen festgestellt werden.\nModerne Verfahren (z.B. BERT) potentiell besser geeignet f√ºr bestimmte Texte"
  },
  {
    "objectID": "content/08-text_as_data/slides/index.html#literatur",
    "href": "content/08-text_as_data/slides/index.html#literatur",
    "title": "Text as data",
    "section": "Literatur",
    "text": "Literatur\n\n\nSalganik, M. J. (2018). Bit by bit: Social research in the digital age. Princeton University Press.\n\n\n\n\n\nDigital Behavioral Data"
  },
  {
    "objectID": "content/09-esm-m_path/09-slides.html",
    "href": "content/09-esm-m_path/09-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you find the slides for the ninth session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‚Äòe‚Äô button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#seminarplan",
    "href": "content/09-esm-m_path/slides/index.html#seminarplan",
    "title": "Experience Sampling Method",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einf√ºhrung und √úberblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nText as data\nChristoph Adrian\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n11.01.2023\nESM: m-path\nD√∂rr\n\n\n10\n18.01.2023\nData Donations\nHofmann & Wierzbicki\n\n\n11\n25.01.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n12\n02.02.2023\nBring Your Own Research (Project)\nChristoph Adrian\n\n\n13\n08.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian\n\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "href": "content/09-esm-m_path/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "title": "Experience Sampling Method",
    "section": "Vielen Dank f√ºr Ihre Fragen!",
    "text": "Vielen Dank f√ºr Ihre Fragen!\n\n\nIch bin nicht sicher, ob ich es richtig verstanden habe, aber ESM ist ja gerade deswegen so besonders, weil es erm√∂glicht die Teilnehmer in verschiedensten Situationen zu erreichen. Wie wird das sichergestellt? Wenn man n√§mlich beispielsweise gerade in der U-Bahn ist und eine Frage auf dem Handy erh√§lt (allerdings nicht antworten kann/m√∂chte, weil man gleich aussteigen muss), k√∂nnte man sich die Frage ja einfach aufsparen und sie in einem ruhigen Moment Zuhause beantworten, wenn man etwas dar√ºber nachgedacht hat. Das w√ºrde allerdings die Vorteile und den Sinn hinter ESM reduzieren, oder?\n\n\n\n\nWas ist mit der √§lteren Generation, die teilweise keine Handys besitzen oder regelm√§√üig nutzen wenn eine Untersuchung durch ESM gest√ºtzt werden soll, die Informationen √§lterer und j√ºngerer Generationen ben√∂tigt?\n\n\n\n\nIn dem Paper wird berichtet, dass die Methode gut f√ºr Kommunikationswissenschaftliche Forschung geeignet ist. Warum wird sie hier dann noch so selten eingesetzt?"
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#lets-discuss",
    "href": "content/09-esm-m_path/slides/index.html#lets-discuss",
    "title": "Experience Sampling Method",
    "section": "Let‚Äôs discuss",
    "text": "Let‚Äôs discuss\n\n\nDurch die regelm√§√üige Befragung beim experience sampling kann sich das Verhalten der Probanden ver√§ndern/ anpassen (z.B. Befragung zum Medienkonsum > Proband stellt hohen Medienkonsum fest > beginnt Konsum zu reduzieren). In welchen F√§llen w√§re experience sampling und in welchen F√§llen w√§ren regul√§re Befragungen besser geeignet? (Diskussionsfrage)\n\n\n\n\nWie kann bei der t√§glichen Strichprobe der ESM sichergestellt werden, dass sich durch die au√üergew√∂hnlich hohe Auseinandersetzung mit pers√∂nlichen Faktoren, wie bspw. Gef√ºhlen, keine beeinflussten Ergebnisse entstehen.\n\n\nDie Reaktivit√§t der Teilnehmer vor allem beim zeitbasierten experience sampling f√ºhrt zur Verzerrung der Ergebnisse. Wie kann dieses Problem gel√∂st werden?\n\n\n\n\nLaut Paper erfordern ESM-Studien die Teilnahme √ºber einen l√§ngeren Zeitraum (1-2 Wochen) und senken dadurch die Bereitschaft der Teilnahme an solchen Studien. Wie k√∂nnte dieses Problem umgangen werden?"
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#neuer-termin-aktualisertes-thema",
    "href": "content/09-esm-m_path/slides/index.html#neuer-termin-aktualisertes-thema",
    "title": "Experience Sampling Method",
    "section": "Neuer Termin & ‚Äúaktualisertes‚Äù Thema",
    "text": "Neuer Termin & ‚Äúaktualisertes‚Äù Thema\nGastvortrag von Johannes Breuer zum Thema survey linking\n\n\nVerkn√ºpfung von digitalen Spurdaten & Umfragen ‚Äì Wieso, wie und was ist m√∂glich?‚Äù (Digital via Zoom)\nZur Person:\n\nsenior researcher in the team Survey Data Augmentation at GESIS - Leibniz Institute for the Social Sciences (Department Survey Data Curation) in Cologne, Germany\n(co-)lead the team Research Data & Methods at the Center for Advanced Internet Studies (CAIS) in Bochum, Germany.\n\n\n\n\n\n\n\n\n\n\n\nAdd socials"
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#bring-your-own-research-project",
    "href": "content/09-esm-m_path/slides/index.html#bring-your-own-research-project",
    "title": "Experience Sampling Method",
    "section": "Bring Your Own Research (Project)",
    "text": "Bring Your Own Research (Project)\nSitzung f√ºr offene Fragen & Anliegen\n\n\nGibt es Fragen oder den Wunsch nach weiterer Vertiefung zu\n\neinem Thema,\neiner Methode,\neiner Sitzung oder\neinem Showcase?\n\n\n\n\n\n\nHinweis auf Hausarbeit"
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#intensive-longitudinal-design-ild-im-fokus",
    "href": "content/09-esm-m_path/slides/index.html#intensive-longitudinal-design-ild-im-fokus",
    "title": "Experience Sampling Method",
    "section": "Intensive Longitudinal Design (ILD) im Fokus",
    "text": "Intensive Longitudinal Design (ILD) im Fokus\nQuick reminder\n\n‚Äúan intensive longitudinal design involves sequential measurements on five or more occasions during which a change process is expected to unfold within each subject (e.g., person or other sampling)‚Äù\n\n(Bolger & Laurenceau, 2013)"
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#messwiederholung-in-kurzen-abst√§nden",
    "href": "content/09-esm-m_path/slides/index.html#messwiederholung-in-kurzen-abst√§nden",
    "title": "Experience Sampling Method",
    "section": "Messwiederholung in kurzen Abst√§nden",
    "text": "Messwiederholung in kurzen Abst√§nden\nDefinitorischer Kern von ILD\n\n\nWie gro√ü oder klein die zeitlichen Abst√§nde Intervalle ) zwischen den Messungen sind , folgt heoretischen Annahmen √ºber Ph√§nomenfrequenz und Ver√§nderungsprozesse"
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#ebenen-√ºber-ebenen",
    "href": "content/09-esm-m_path/slides/index.html#ebenen-√ºber-ebenen",
    "title": "Experience Sampling Method",
    "section": "Ebenen √ºber Ebenen",
    "text": "Ebenen √ºber Ebenen\nILD: Sampling auf zwei geschalteten Ebenen"
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#verschiedene-varianten-des-situationssamplings",
    "href": "content/09-esm-m_path/slides/index.html#verschiedene-varianten-des-situationssamplings",
    "title": "Experience Sampling Method",
    "section": "Verschiedene Varianten des Situationssamplings",
    "text": "Verschiedene Varianten des Situationssamplings\nSystematisierung nach (Masur, 2019)"
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#personen--undoder-situationsebene",
    "href": "content/09-esm-m_path/slides/index.html#personen--undoder-situationsebene",
    "title": "Experience Sampling Method",
    "section": "Personen- und/oder Situationsebene?",
    "text": "Personen- und/oder Situationsebene?\nArten von Forschungsfragen & Beispiele\n\nFragen auf Personenebene (between-subject): Daten √ºber Messzeitpunkte aggregiert\n\nPersonenmittelwert: Wie ist das durchschnittliche Wohlbefinden (Y) in der Personenstichprobe?\nVarianz der Personenmittelwerte: Welche Unterschiede im durchschnittlichen Wohlbefinden (Y) gibt es zwischen Personen?\nKorrelation auf Personenebene: H√§ngen Unterschiede im Wohlbefinden (Y) mit Unterschieden in der durchschnittlichen sozialen Interaktion (X) zusammen?\nKausalzusammenhang: Erkl√§rt eine experimentelle Manipulation der sozialen Interaktion (X) die Unterschiede im Wohlbefinden (Y)?\n\nFragen auf Situationsebene (within-subject): Daten mehrerer Messzeitpunkte einer Person\n\nVarianz der Situationswerte: Wie stark weicht das situative Wohlbefinden (Y) vom Durchschnitt einer Person ab?\nKorrelation auf Situationsebene: H√§ngen diese Abweichungen im situativen Wohlbefinden (Y) mit situativen Unterschieden in der sozialen Interaktion (X) einer Person zusammen?\nGranger Kausalzusammenhang: Erkl√§rt die soziale Interaktion einer Person in der Mitte des Tages (X) die Unterschiede im Wohlbefinden dieser Person am Ende des Tages (Y)?"
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#design-your-own-research",
    "href": "content/09-esm-m_path/slides/index.html#design-your-own-research",
    "title": "Experience Sampling Method",
    "section": "Design your own research",
    "text": "Design your own research\nGruppenarbeit (ca 25 Min.) & Ergebnisvorstellung (ca. 15 Min)\n\nTeilen Sie sich in zwei bis drei Gruppen auf\nBearbeiten Sie folgende Aufgaben (ca. 30 Min).:\n\nFormulieren Sie drei unterschiedliche Forschungsfragen, die mit drei unterschiedlichen Kurzzeit-L√§ngsschnittdesigns (siehe Systematik von Masur) beantwortbar sind\nDie Fragen k√∂nnen gerne einen thematischen Bezug zum Marketing haben\nMindestens eine Frage auf Personenebene & mindestens eine Frage auf Situationsebene\nHalten Sie Ihre Fragen & Designideen auf einer PP-Folie fest\n\nErgebnisvorstellung (ca. 20 Min): Pr√§sentation der Fragen & dazugeh√∂rigem Design"
  },
  {
    "objectID": "content/09-esm-m_path/slides/index.html#literatur",
    "href": "content/09-esm-m_path/slides/index.html#literatur",
    "title": "Experience Sampling Method",
    "section": "Literatur",
    "text": "Literatur\n\n\nBolger, N., & Laurenceau, J.-P. (2013). Intensive longitudinal methods: An introduction to diary and experience sampling research. Guilford Press.\n\n\nMasur, P. K. (2019). Capturing situational dynamics: Strength and pitfalls of the experience sampling method (P. M√ºller, S. Gei√ü, T. K. Naab, & C. Peter, Eds.; Vol. 15). Herbert von Halem Verlag. https://doi.org/10.31219/osf.io/vx5ha\n\n\n\n\n\nDigital Behavioral Data"
  },
  {
    "objectID": "content/10-data_donations/10-slides.html",
    "href": "content/10-data_donations/10-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you find the slides for the tenth session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‚Äòe‚Äô button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "content/10-data_donations/slides/index.html#seminarplan",
    "href": "content/10-data_donations/slides/index.html#seminarplan",
    "title": "Data Donations",
    "section": "Seminarplan",
    "text": "Seminarplan\n\n\n\nSitzung\nDatum\nThema\nReferent*Innen\n\n\n\n\n1\n26.10.2022\nKick-Off Session\nChristoph Adrian\n\n\n2\n02.11.2022\nDBD: Einf√ºhrung und √úberblick\nChristoph Adrian\n\n\n3\n09.11.2022\nDBD: Datenerhebung\nChristoph Adrian\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\nFalk\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\nDenisov\n\n\n6\n30.11.2022\nAPI-Access (II): Reddit\nLandauer\n\n\n7\n07.12.2022\nWebscraping: TikTok\nBrand & Kocher\n\n\n8\n14.12.2022\nText as data\nChristoph Adrian\n\n\n\n\nWEIHNACHTSPAUSE\n\n\n\n9\n11.01.2023\nESM: m-path\nD√∂rr\n\n\n10\n18.01.2023\nData Donations\nHofmann & Wierzbicki\n\n\n11\n25.01.2023\nGuest Lecture: Linking DBD & Survey data\nJohannes Breuer\n\n\n12\n02.02.2023\nBring Your Own Research (Project)\nChristoph Adrian\n\n\n13\n08.02.2023\nSemesterabschluss & Evaluation\nChristoph Adrian\n\n\n\n\n‚ñ∂Ô∏è"
  },
  {
    "objectID": "content/10-data_donations/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "href": "content/10-data_donations/slides/index.html#vielen-dank-f√ºr-ihre-fragen",
    "title": "Data Donations",
    "section": "Vielen Dank f√ºr Ihre Fragen!",
    "text": "Vielen Dank f√ºr Ihre Fragen!\n\n\nWas kann unter dem Screenomics Ansatz verstanden werden und wie findet er aktuell Anwendung in der Forschung/Praxis?\n\n\n\n\nBei Data Donations steht die aktive Zustimmung zum Teilen pers√∂nlicher Daten im Vordergrund, was die Forschung in diesem Zusammenhang stark erschwert. Wie relevant und h√§ufig ist Forschung mit Data Donations demnach tats√§chlich in der Praxis?\n\n\n\n\nIm Paper wird dar√ºber gesprochen, dass bei den DDP‚Äôs der Prozess des Teiles vereinfacht werden sollte. Was w√§re ein m√∂glicher Weg, wie man dieses Problem l√∂sen k√∂nnte?\n\n\n\n\nIn welcher Form k√∂nnten Data Donations mit anderen Datenerhebungsmethoden kombiniert werden, um noch bessere und aussagekr√§ftigere Ergebnisse zu erlangen?"
  },
  {
    "objectID": "content/10-data_donations/slides/index.html#lets-discuss",
    "href": "content/10-data_donations/slides/index.html#lets-discuss",
    "title": "Data Donations",
    "section": "Let‚Äôs discuss",
    "text": "Let‚Äôs discuss\n\n\nData Donations findet zeitlich vor der Analyse der Daten und √ºber einen l√§ngeren Zeitraum statt. Ebenfalls √§ndern sich die Trends und auch die Apps oft sehr schnell. Besteht hier die Gefahr, dass die Daten bis zur Analyse ‚Äúveralten‚Äù?\n\n\n\n\nIst der Anonymisierungsprozess der Daten, hier auch als De-Identifizierung bezeichnet die ‚Äúperfekte‚Äù L√∂sung zur Gew√§hrleistung des Datenschutzes? Welche L√ºcken gibt es?\n\n\n\n\nDurch die gro√üe Menge an freigegebenen Daten (gesamte SM Aktivit√§t) im Vergleich zu z.B. einer Umfrage, m√ºsste der Bias durch die Selbstselektion der Teilnehmer doch sehr gro√ü sein? Die Belohnung f√ºr die Data Donation in der Studie waren 5 Euro. F√ºr welche Belohnung w√§rt ihr bereit eure gesamten Social-Media-Aktivit√§ten zur Verf√ºgung zu stellen?"
  },
  {
    "objectID": "content/10-data_donations/slides/index.html#nicht-neu-sondern-anders",
    "href": "content/10-data_donations/slides/index.html#nicht-neu-sondern-anders",
    "title": "Data Donations",
    "section": "Nicht neu, sondern anders",
    "text": "Nicht neu, sondern anders\nData donation of digital traces\n\n\n\n\n\nData donation\n\n\n‚Äúthe act of an individual actively consenting to donate their personal data for research‚Äù (Skatova & Goulding, 2019)\n\n\n\n\n\n\nDigital traces\n\n\n‚ÄúOne‚Äôs unique set of digital activities, actions, and communications that leave a data trace on the internet or on a computer or other digital device and can identify the particular user or device.‚Äù (Boeschoten, 2022)\n\n\n\n\n\n\n\n¬©Ô∏è https://myshadow.org/tracking-data-traces\n\n\n\n\n\n‚ÄúData donation‚Äù keine Neuheit ‚Äì> Vorher Umfragen oder Dokument"
  },
  {
    "objectID": "content/10-data_donations/slides/index.html#verf√ºgbarkeit-durch-ver√§nderte-rahmenbedingungen",
    "href": "content/10-data_donations/slides/index.html#verf√ºgbarkeit-durch-ver√§nderte-rahmenbedingungen",
    "title": "Data Donations",
    "section": "Verf√ºgbarkeit durch ver√§nderte Rahmenbedingungen",
    "text": "Verf√ºgbarkeit durch ver√§nderte Rahmenbedingungen\nGeneral Data Protection Regulation (GDPR)\n\n\n\n\n\n\nArticel 15 - Right of data access\n\n\n\n\n\n\nRight to obtain from a data controller:\n\nConfirmation whether personal data are being processed\nAccess to the personal data\nAccess to information regarding data recipients\nand sources and data derived from your personal data\n\n\n\n\n\n\n\n\n\n\n\n\nArticel 20 - Right of data portability\n\n\n\n\n\n\nGrants data subjects the right to\n\nreceive the personal data in a structured, commonly used and machine-readable format (‚ÄúData Download Package‚Äù)\ntransmit those data to another data controller"
  },
  {
    "objectID": "content/10-data_donations/slides/index.html#design-your-own-research",
    "href": "content/10-data_donations/slides/index.html#design-your-own-research",
    "title": "Data Donations",
    "section": "Design your own research",
    "text": "Design your own research\nGruppenarbeit (ca 25 Min.) & Ergebnisvorstellung (ca. 15 Min)\n\nTeilen Sie sich in zwei Gruppen auf\nBearbeiten Sie folgende Aufgaben (ca. 30 Min).:\n\nFormulieren Sie eine Forschungsfragen, die Sie mit Hilfe von Datenspenden (DDPS etc.) beantworten m√∂chten.\nBeschreiben Sie die Mechanismen, mit denen Sie eine hohe Compliance sicherstellen w√ºrden. Das k√∂nnen sowohl gezielte Ma√ünahmen (Hinweise bzw. ‚ÄúAufkl√§rung‚Äù) oder gr√∂√üere Konzepte (Data Donation Platform etc) sein.\nHalten Sie Ihre Fragen & Designideen auf einer PP-Folie fest\n\nErgebnisvorstellung (ca. 20 Min): Pr√§sentation der Fragen & dazugeh√∂rigem Design\n\n\nData Donations von Instagram DDP‚Äôs gibt detaillierteren Einblick in die Social-Media-Nutzung mehrerer Individuen, ist aber hinsichtlich der Analyse sehr komplex. Welche weiteren Anwendungsf√§lle gibt es f√ºr Data Donations noch? In welchem Rahmen lassen sich Data Donations skalieren?\nIch denke dabei beispielsweise an Teilen von Daten einer Smartwatch oder Aufzeichnung von Daten √ºber den Fahrstil f√ºr Versicherungen."
  },
  {
    "objectID": "content/10-data_donations/slides/index.html#google-slides-vorlagen",
    "href": "content/10-data_donations/slides/index.html#google-slides-vorlagen",
    "title": "Data Donations",
    "section": "Google Slides Vorlagen",
    "text": "Google Slides Vorlagen\nBitte nutzen Sie die Pr√§sentationsvorlagen\n\n\n\n\n\n\n\n\nGruppe A\n\n\n\n\n\n\nGruppe B"
  },
  {
    "objectID": "content/10-data_donations/slides/index.html#literatur",
    "href": "content/10-data_donations/slides/index.html#literatur",
    "title": "Data Donations",
    "section": "Literatur",
    "text": "Literatur\n\n\nBoeschoten, L. (2022). Data donation: What is it and why is it important? https://hds.sites.uu.nl/2022/01/15/data-donation-day/\n\n\nSkatova, A., & Goulding, J. (2019). Psychology of personal data donation. PLOS ONE, 14(11), e0224240. https://doi.org/10.1371/journal.pone.0224240\n\n\n\n\n\nDigital Behavioral Data"
  },
  {
    "objectID": "content/11-guest_lecture/11-slides.html",
    "href": "content/11-guest_lecture/11-slides.html",
    "title": "Slides",
    "section": "",
    "text": "Below you find the slides for the tenth session:\n\n\n\nIf you want to see the slides in full screen, you can click here. To download them as PDFs, hit the ‚Äòe‚Äô button when you got the presentation open and then Ctrl+P print to PDF. This will work best in Chrome."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Digital Behavioral Data",
    "section": "",
    "text": "In this seminar, students will be introduced to working with digital behavioral data (DBD). DBD refers to digital traces of human behavior that are knowingly or unknowingly left in online environments (e.g., social media, messengers, entertainment media, or digital collaboration tools). These rich data are increasingly available to social scientific research in the public interest but can also be used to derive strategic insights for business decisions. Students will learn how to work with DBD alongside the entire research process, from data collection, preprocessing and analysis, to reporting and provision (e.g., via open science tools). Students will first get a comprehensive overview of the ways in which DBD can be collected (e.g., API scraping, usage logging, mock-up virtual environments, or data donations), as well as the requirements for data protection, research ethics, and data quality. Afterwards, students will practice and apply their newly gained knowledge in small projects on use cases from media and communication research. In doing so, they learn about key computational methods via which large digital behavioral datasets (e.g., texts, images, usage behavior logs) can be processed and analyzed. By completing this module, participants will get an up-to-date overview and practical insights into how to harness the potential of observational data traces to better understand media users‚Äô behavior in digital environments."
  },
  {
    "objectID": "index.html#students-will",
    "href": "index.html#students-will",
    "title": "Digital Behavioral Data",
    "section": "Students will",
    "text": "Students will\n\noverview and understand central opportunities of DBD and accompanying challenges for data collection and preprocessing\nevaluate the strengths and weaknesses of different ways of collecting DBD\nget to know and understand central requirements for data protection, research ethics, and data quality\nget to know and overview key computational social science methods to analyze DBD\npractice and apply knowledge on DBD, statistics, and data analysis in small projects of their own"
  },
  {
    "objectID": "index.html#recommended-prerequisites",
    "href": "index.html#recommended-prerequisites",
    "title": "Digital Behavioral Data",
    "section": "Recommended prerequisites",
    "text": "Recommended prerequisites\n\nInterest in social scientific perspectives on media, communication, and digital technologies.\nBasic knowledge of working with statistical software such as Stata, R, Python, or SPSS is required.\nStudents are recommended, but not required, to also visit the lecture Data Science: Foundations, Tools, Applications in Socio-Economics and Marketing."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Digital Behavioral Data",
    "section": "Schedule",
    "text": "Schedule\nBelow is the scheudle for the current semester.\n\n\n\n\n\n\n\n\nSession\nDatum\nTopic\n\n\n\n\n1\n26.10.2022\nKick-Off Session\n\n\n2\n02.11.2022\nDBD: Introduction & Overview\n\n\n3\n09.11.2022\nDBD: Data collection process in focus\n\n\n4\n16.11.2022\nAPI-Access (I): Twitter\n\n\n5\n23.11.2022\nAPI-Access (II): YouTube\n\n\n6\n30.11.2022\nAPI-Access (III): Reddit\n\n\n7\n07.12.2022\nWebscraping: TikTok\n\n\n8\n14.12.2022\nExtra: Text as data\n\n\n-\n-\nCHRISTMAS BREAK\n\n\n9\n11.01.2023\nESM: m-path\n\n\n10\n18.01.2023\nData Donations\n\n\n11\n25.01.2023\nGuest Lecture: Linking DBD & Survey data\n\n\n12\n02.02.2023\nBring Your Own Research (Project)\n\n\n13\n08.02.2023\nClosing Session: Recap, Evaluation & Discussion"
  },
  {
    "objectID": "index.html#copyright",
    "href": "index.html#copyright",
    "title": "Digital Behavioral Data",
    "section": "Copyright",
    "text": "Copyright\nThis content is licensed under a GPL-3.0 License."
  }
]