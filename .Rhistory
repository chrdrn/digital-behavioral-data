start_tweets = "2020-11-11T00:00:00Z",
end_tweets = "2022-11-13T12:00:00Z",
file = "elonmusk",
data_path = "data/raw_elonmusk/",
n = 100000
)
tweets_musk <- bind_tweets(
data_path = here("content/04-api_access-twitter/data/raw_elonmusk"),
# data_path = "data/raw_karneval",
output_format = "tidy") %>%
mutate(
datetime = ymd_hms(created_at),
date = date(datetime),
hour = hour(datetime),
min  = minute(datetime),
hms  = hms::as_hms(datetime),
hm   = hms::parse_hm(hms)
)
tweets_musk <- bind_tweets(
data_path = here("content/04-api_access-twitter/data/raw_elonmusk"),
# data_path = "data/raw_karneval",
output_format = "tidy") %>%
mutate(
datetime = ymd_hms(created_at),
date = date(datetime),
hour = hour(datetime),
min  = minute(datetime),
hms  = hms::as_hms(datetime),
hm   = hms::parse_hm(hms)
)
tweets_musk %>% glimpse()
tweets_musk %>%
ggplot(aes(date)) +
geom_bar()
tweets_musk %>% frq(user_location)
tweets_musk %>%
filter(user_username == "elonmusk",
is.na(sourcetweet_type)) %>%
arrange(-like_count) %>%
select(text, created_at, like_count) %>%
head(10)
tweets_musk %>%
ggplot(aes(date)) +
geom_bar() +
theme_fivethirtyeight()
tweet_musk %>%
frq(sourcetweet_type)
tweets_musk %>%
frq(sourcetweet_type)
tweets_musk %>%
filter(is.na(sourcetweet_type)) %>%
arrange(-like_count) %>%
select(text, created_at, like_count) %>%
head(10)
tweets_musk %>%
filter(is.na(sourcetweet_type)) %>%
arrange(-retweet_count) %>%
select(text, created_at, retweet_count) %>%
head(10)
tweets_musk$lang %>% frq()
tweets_musk %>%
frq(sourcetweet_type)
tweets_musk %>%
frq(lang)
tweets_musk_en <- tweets %>%
filter(lang == "en",
is.na(sourcetweet_type)) %>%
select(tweet_id, text, user_username) %>%
mutate(across(text, str_remove_all, remove_html))
tweets_musk_en <- tweets_musk %>%
filter(lang == "en",
is.na(sourcetweet_type)) %>%
select(tweet_id, text, user_username) %>%
mutate(across(text, str_remove_all, remove_html))
remove_html <- "&amp;|&lt;|&gt;"
tweets_musk_en <- tweets_musk %>%
filter(lang == "en",
is.na(sourcetweet_type)) %>%
select(tweet_id, text, user_username) %>%
mutate(text = str_remove_all(text, remove_html))
table(tweets_musk_en$user_username)
rm(tweets_musk_en
)
remove_html <- "&amp;|&lt;|&gt;"
tweets_en <- tweets_musk %>%
filter(lang == "en",
is.na(sourcetweet_type)) %>%
select(tweet_id, text, user_username) %>%
mutate(text = str_remove_all(text, remove_html))
tweets_en_corpus <- corpus(tweets_en,
docid_field = "tweet_id",
text_field = "text")
tweets_en_tokens <-
tokens(tweets_en_corpus,
remove_punct = TRUE,
remove_numbers = TRUE,
remove_symbols = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("english"))
tweets_en_dfm <- dfm(tweets_en_tokens)
tag_dfm <- dfm_select(tweets_en_dfm, pattern = "#*")
toptag <- names(topfeatures(tag_dfm, 50))
head(toptag, 10)
toptag
?tokens()
head(topuser, 10)
user_dfm <- dfm_select(tweets_en_dfm, pattern = "@*")
topuser <- names(topfeatures(user_dfm, 50))
head(topuser, 10)
tweets_en_tokens <-
tokens(tweets_en_corpus,
remove_punct = TRUE,
remove_numbers = TRUE,
#remove_symbols = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("english"))
tweets_en_dfm <- dfm(tweets_en_tokens)
tag_dfm <- dfm_select(tweets_en_dfm, pattern = "#*")
toptag <- names(topfeatures(tag_dfm, 50))
head(toptag, 10)
remove_html <- "&amp;|&lt;|&gt;"
tweets_en <- tweets_musk %>%
filter(lang == "en",
is.na(sourcetweet_type)) %>%
select(tweet_id, text, user_username) %>%
mutate(text = str_remove_all(text, remove_html))
tweets_en
topuser
tweets_en_clean <- tweets_en_dfm %>%
dfm_remove(pattern = "@*") %>%
dfm_remove(pattern = "#*")
head(term_freq_en, n = 10)
term_freq_en <- textstat_frequency(tweets_en_clean)
head(term_freq_en, n = 10)
textplot_wordcloud(tweets_en_clean, max_words = 50)
install.packages("glue", dependencies = T)
#| echo: false
# Load packages
library(academictwitteR) # Collecting the data
library(tidyverse) # Preparation of the data
library(quanteda) # Text mining
library(quanteda.textstats) # Text statistics
library(quanteda.textplots) # Visualisation of text data
library(here)
library(sjmisc)
library(lubridate)
library(ggthemes)
library(ggpubr)
# Load data
tweets_karneval <- bind_tweets(
data_path = here("content/04-api_access-twitter/data/raw_karneval"),
# data_path = "data/raw_karneval",
output_format = "tidy") %>%
mutate(
datetime = ymd_hms(created_at),
date = date(datetime),
hour = hour(datetime),
min  = minute(datetime),
hms  = hms::as_hms(datetime),
hm   = hms::parse_hm(hms)
)
tweets_karneval %>%
frq(hm,
sort.frq = "desc",
min.frq = 10)
tweets_karneval %>%
filter(user_username == "Gun17170309") %$%
glue(text) %>%
head()
tweets_karneval %>%
filter(user_username == "Gun17170309") %$%
glue::glue(text) %>%
head()
tweets_karneval %>%
filter(user_username == "Gun17170309") %$%
glue::glue("{text}") %>%
head()
Inhalt: {{text} ") %>%
head()
tweets_karneval %>%
filter(user_username == "Gun17170309") %$%
tweets_karneval %>%
filter(user_username == "Gun17170309") %$%
glue::glue("Tweet-ID: {tweet_id} \n
Inhalt: {{text} ") %>%
head()
tweets_karneval %>%
filter(user_username == "Gun17170309") %$%
glue::glue("Tweet-ID: {tweet_id} \n     Inhalt: {text} ") %>%
head()
tweets_karneval %>%
filter(user_username == "Gun17170309") %$%
glue::glue("Tweet-ID: {tweet_id} \n Inhalt: {text}\n\n") %>%
head()
install.packages("languageserver")
install.packages("languageserver", dependencies = TRUE)
install.packages("httpgd")
R#
# Load packages
library(readr)
library(tidyverse)
# Import data
channel_list <- read_csv(
"https://raw.githubusercontent.com/chrdrn/dbd_binder/main/data/05-youtube/channelsearch_channels50_2022_11_17-09_54_22.csv")
# Preview data
channel_list %>% glimpse()
df <- read_csv(
"content/07-webscraping-tiktok/data/tiktok-search-statistics.csv",
col_types = cols(author_followers = col_number()))
# load packages
library(readr)
df <- read_csv(
"content/07-webscraping-tiktok/data/tiktok-search-statistics.csv",
col_types = cols(author_followers = col_number()))
df <- read_csv(
"content/07-webscraping-tiktok/data/tiktok-search-statistics.csv",
col_types = cols(author_followers = col_number()))
library(here)
here()
df <- read_csv(
here("content/07-webscraping-tiktok/data/tiktok-search-statistics.csv"),
col_types = cols(author_followers = col_number()))
df %>% glimpse()
#| echo: false
library(tidyverse)
library(here)
df %>% glimpse()
View(df)
statistics <- read_csv(
here("content/07-webscraping-tiktok/data/tiktok-search-statistics.csv"),
col_types = cols(author_followers = col_number()))
# quick preview
statistics %>% glimpse()
# load packages
library(readr)
statistics <- read_csv(
here("content/07-webscraping-tiktok/data/tiktok-search-statistics.csv"),
col_types = cols(author_followers = col_number()))
# quick preview
statistics %>% glimpse()
# load packages
library(readr)
statistics <- read_csv(
here("content/07-webscraping-tiktok/data/tiktok-search-statistics.csv"),
col_types = cols(author_followers = col_number()))
# quick preview
statistics %>% glimpse()
glimpse(df)
glimpse(statistics)
statistics %>% glimpse()
# Display
statistics %>%
mutate(date  = as.factor(date(timestamp))) %>%
plot_frq(date)
#| fig-width: 16
#| fig-height: 9
library(lubridate)
library(sjPlot)
# Display
statistics %>%
mutate(date  = as.factor(date(timestamp))) %>%
plot_frq(date)
# Display
statistics %>%
mutate(date  = as.factor(year(timestamp))) %>%
plot_frq(date)
statistics %>%
plot_frq(likes, type = "density")
statistics %>%
plot_frq(comments, type = "density")
statistics %>%
plot_frq(likes, type = "density")
statistics %>%
ggdensity("likes")
library(ggpubr)
statistics %>%
ggdensity("likes")
statistics %>%
ggdensity("comments")
statistics %>%
ggdensity("shares")
statistics %>%
ggdensity("plays")
statistics %>%
frq(effects)
library(sjmisc)
statistics %>%
frq(effects)
# Display
statistics %>%
mutate(date  = as.factor(year(timestamp))) %>%
plot_frq(date) +
theme_pubr()
statistics %>% glimpse
statistics %>%
select(likes:plays) %>%
descr()
#| echo: false
pacman::p_load(
here, fs, # file management
sjmisc, magrittr, lubridate, janitor, # data processing
sjPlot, # analysis
tidyverse  # last to resolve masking issues
)
#| fig-width: 16
#| fig-height: 9
# Load packages
library(lubridate)
library(sjPlot)
library(ggpubr)
# Display
statistics %>%
mutate(date  = as.factor(year(timestamp))) %>%
plot_frq(date) +
theme_pubr()
statistics %>%
select(likes:plays) %>%
descr()
statistics %>%
ggplot(aes(likes)) +
geom_boxplot()
statistics %>%
plot_frq(likes, type = "density")
options(scipen = 999)
pacman::p_load(
here, fs, # file management
sjmisc, magrittr, lubridate, janitor, # data processing
sjPlot, # analysis
tidyverse  # last to resolve masking issues
)
statistics %>%
plot_frq(likes, type = "density")
statistics %>%
frq(warning)
pacman::p_load(
here, fs, # file management
sjmisc, magrittr, lubridate, janitor, # data processing
sjPlot, # analysis
quanteda, # text processing
tidyverse  # last to resolve masking issues
)
# Create corpus based on variable hashtags
crp <- corpus(
statistics,
docid_field = "id",
text_field = "hashtags")
crp_stats <- summary(crp)
crp_stats
tkn <- crp %>%
tokens(
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_separators = TRUE)
dfm <- tkn %>%
dfm(tkn)
dfm <- tkn %>%
dfm()
# Create corpus based on variable hashtags
crp <- corpus(
statistics,
docid_field = "id",
text_field = "hashtags")
crp
tkn <- crp %>%
tokens(
remove_punct = TRUE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_separators = TRUE)
tkn
dfm <- tkn %>%
dfm()
dfm
textplot_wordcloud(dfm)
pacman::p_load(
here, fs, # file management
sjmisc, magrittr, lubridate, janitor, # data processing
sjPlot, # analysis
quanteda, quanteda.textplots, # text processing
tidyverse  # last to resolve masking issues
)
textplot_wordcloud(dfm)
dfm %>%
textplot_wordcloud()
dfm %>%
textplot_wordcloud(
max_words = 100
)
dfm %>%
textplot_wordcloud(
max_words = 50
)
dfm %>%
dfm_remove("statistiscs") %>%
textplot_wordcloud(
max_words = 50
)
?dfm_remove
dfm %>%
dfm_remove(pattern = "statistiscs") %>%
textplot_wordcloud(
max_words = 50
)
dfm %>%
dfm_remove(pattern = "statistics") %>%
textplot_wordcloud(
max_words = 50
)
dfm %>%
textplot_wordcloud(
max_words = 50,
rotation = 0
)
dfm %>%
textplot_wordcloud(
min_size = 1
max_words = 50,
dfm %>%
textplot_wordcloud(
min_size = 1,
max_words = 50,
rotation = 0
)
dfm %>%
textplot_wordcloud(
min_size = 1,
max_size = 5
max_words = 50,
dfm %>%
textplot_wordcloud(
min_size = 2,
max_size = 6,
max_words = 50,
rotation = 0
)
dfm %>%
textplot_wordcloud(
min_size = 1,
max_size = 5,
max_words = 50,
rotation = 0
)
dfm %>%
dfm_remove(pattern = "statistics") %>%
textplot_wordcloud(
min_size = 1,
max_size = 8,
max_words = 50
)
dfm %>%
textplot_wordcloud(
min_size = 1,
max_size = 8,
max_words = 50,
rotation = 0
)
dfm %>%
dfm_remove(pattern = "statistics") %>%
textplot_wordcloud(
min_size = 1,
max_size = 8,
max_words = 50,
rotation = 0
)
dfm %>%
dfm_remove(pattern = "statistics") %>%
textplot_wordcloud(
min_size = 1,
max_size = 8,
max_words = 50,
rotation = 0,
color = "blue"
)
dfm %>%
dfm_remove(pattern = "statistics") %>%
textplot_wordcloud(
min_size = 1,
max_size = 8,
max_words = 50,
rotation = 0,
color = "deepskyblue4"
)
dfm %>%
dfm_remove(pattern = "statistics") %>%
textplot_wordcloud(
min_size = 1,
max_size = 8,
max_words = 50,
rotation = 0,
color = "dodgerblue"
)
dfm %>%
dfm_remove(pattern = "statistics") %>%
textplot_wordcloud(
min_size = 1,
max_size = 8,
max_words = 50,
rotation = 0,
color = "dodgerblue4"
)
dfm %>%
dfm_remove(pattern = "statistics") %>%
textplot_wordcloud(
min_size = 1,
max_size = 8,
max_words = 50,
rotation = 0,
color = "dodgerblue3"
)
